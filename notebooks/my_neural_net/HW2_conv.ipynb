{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy, os, gc, tqdm\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "from time import time, sleep\n",
    "\n",
    "from IPython import display\n",
    "from collections import Counter\n",
    "from itertools import product, chain, combinations\n",
    "\n",
    "\n",
    "#matplotlib\n",
    "import matplotlib\n",
    "import matplotlib as mp\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.collections import PolyCollection\n",
    "from matplotlib.colors import colorConverter\n",
    "%matplotlib inline\n",
    "\n",
    "#https://matplotlib.org/users/customizing.html\n",
    "matplotlib.rcParams['legend.markerscale'] = 1.5     # the relative size of legend markers vs. original\n",
    "matplotlib.rcParams['legend.handletextpad'] = 0.01\n",
    "matplotlib.rcParams['legend.labelspacing'] = 0.4    # the vertical space between the legend entries in fraction of fontsize\n",
    "matplotlib.rcParams['legend.borderpad'] = 0.5       # border whitespace in fontsize units\n",
    "matplotlib.rcParams['font.size'] = 14\n",
    "matplotlib.rcParams['font.family'] = 'serif'\n",
    "matplotlib.rcParams['font.serif'] = 'Times New Roman'\n",
    "matplotlib.rcParams['axes.labelsize'] = 20\n",
    "matplotlib.rcParams['axes.titlesize'] = 20\n",
    "# Configuring latex fonts\n",
    "matplotlib.rc('font', **{'family':'serif'})\n",
    "matplotlib.rc('text', usetex=True)\n",
    "matplotlib.rc('text.latex', unicode=True)\n",
    "matplotlib.rc('text.latex', preamble=r'\\usepackage[utf8]{inputenc}')\n",
    "matplotlib.rc('text.latex', preamble=r'\\usepackage[english]{babel}')\n",
    "matplotlib.rc('text.latex', preamble=r'\\usepackage{amsmath}')\n",
    "\n",
    "\n",
    "import sys\n",
    "library_path = '../../'\n",
    "if library_path not in sys.path:\n",
    "    sys.path.append(library_path)\n",
    "\n",
    "CIFAR10_DIR = library_path + 'datasets/CIFAR10'\n",
    "MNIST_DIR   = library_path + 'datasets/MNIST'\n",
    "\n",
    "from ml.utils import get_CIFAR10_data, get_MNIST_data\n",
    "from ml.neural_network import Layer, Sequential, Model, Solver\n",
    "from ml.neural_network.layers import Dense, Dropout, SoftMax, BatchNormalization\n",
    "from ml.neural_network.nonlinearities import Tanh, ReLU, LeakyReLU, ELU, SoftPlus\n",
    "from ml.neural_network.criterions import MSECriterion, MulticlassLogLoss\n",
    "from ml.neural_network.regularizers import *\n",
    "from ml.neural_network.initializers import *\n",
    "from ml.neural_network.optimizers import *\n",
    "from ml.neural_network.decorators import *\n",
    "from ml.neural_network.gradients import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_solver_history(history, axarr=None, figsize=(10, 14), colors=None, markers=None):\n",
    "    if axarr is None:\n",
    "        _, axarr = plt.subplots(3, 1, figsize=figsize)\n",
    "    plot_kwargs = {'markeredgecolor': 'k', 'ms': 5, 'alpha': 0.7}\n",
    "    if colors is None: \n",
    "        colors = {'train': 'r', 'val': 'b'}\n",
    "    if markers is None:\n",
    "        markers = {'train': 'o', 'val': '^'}\n",
    "        \n",
    "    ax = axarr[0]  \n",
    "    ax.plot(history['loss_history'], color=colors['train'])\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_xlabel('iteration')\n",
    "    ax.set_ylabel('loss')\n",
    "    ax.set_title('Training loss vs iteration')\n",
    "    ax.grid(linestyle='--', alpha=0.5)\n",
    "\n",
    "    ax = axarr[1]\n",
    "    for label in ['train', 'val']:\n",
    "        data = history['{}_loss_history'.format(label)]\n",
    "        ax.plot(data, marker=markers[label], color=colors[label], label=label, **plot_kwargs)\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_xlabel('epoch')\n",
    "    ax.set_ylabel('loss')\n",
    "    ax.set_title('Loss vs epoch')\n",
    "    ax.grid(linestyle='--', alpha=0.5)\n",
    "    ax.legend(loc='upper right', fontsize=16)\n",
    "\n",
    "    ax = axarr[2]\n",
    "    for label in ['train', 'val']:\n",
    "        data = history['{}_acc_history'.format(label)]\n",
    "        ax.plot(data, marker=markers[label], color=colors[label], label=label, **plot_kwargs)\n",
    "    ax.set_xlabel('epoch')\n",
    "    ax.set_ylabel('training loss')\n",
    "    ax.set_title('Accuracy vs epoch')\n",
    "    ax.grid(linestyle='--', alpha=0.5)\n",
    "    ax.legend(loc='lower right', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return axarr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='toc'></a>\n",
    "# Table of Contents\n",
    "* [2. Convolutional Networks](#cnn)\n",
    "    * [2.1 Convolution](#cnn_conv)\n",
    "        * [2.1.1 Convolution: Naive forward pass](#cnn_conv_forw)\n",
    "        * [2.1.2 Aside: Image processing via convolutions](#cnn_conv_aside)\n",
    "        * [2.1.3 Convolution: Naive backward pass](#cnn_conv_back)\n",
    "    * [2.2 Max pooling](#max_pooling)\n",
    "        * [2.2.1 Max pooling: Naive forward](#cnn_max_pooling_forw)\n",
    "        * [2.2.2 Max pooling: Naive backward](#cnn_max_pooling_back)\n",
    "    * [2.3 Fast layers](#cnn_fast)\n",
    "    * [2.4 Convolutional \"sandwich\" layers](#cnn_sand)\n",
    "    * [2.5 Spatial Batch Normalization](#cnn_spatial)\n",
    "        * [2.5.1 Spatial batch normalization: forward](#cnn_spatial_forw)\n",
    "        * [2.5.2 Spatial batch normalization: backward](#cnn_spatial_back)\n",
    "    * [2.6 Three Layer ConvNet](#cnn_three)\n",
    "        * [2.6.1 Sanity check loss](#cnn_three_sanity)\n",
    "        * [2.6.2 Gradient check](#cnn_three_grad)\n",
    "        * [2.6.3 Overfit small data](#cnn_three_overfit)\n",
    "        * [2.6.4 Train net](#cnn_three_train)\n",
    "        * [2.6.5 Visualize filters](#cnn_three_visualize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='cnn'></a>\n",
    "# X. Convolutional Networks  [[toc](#toc)]\n",
    "So far we have worked with deep fully-connected networks, using them to explore different optimization strategies and network architectures. Fully-connected networks are a good testbed for experimentation because they are very computationally efficient, but in practice all state-of-the-art results use convolutional networks instead.\n",
    "\n",
    "First you will implement several layer types that are used in convolutional networks. You will then use these layers to train a convolutional network on the CIFAR-10 dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='cnn_conv'></a>\n",
    "## X.X Convolution [[toc](#toc)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'seed': 1, 'grad_clip': inf, 'names': {'Dense': 1}, 'debug': False, 'dtype': <class 'numpy.float64'>, 'input_shape': (10, 3)}\n",
      "Dense(2->3)\n",
      "[[ 0.44112583 -0.3463194  -0.01227563]\n",
      " [ 0.71643002  0.50088484 -1.14158192]]\n",
      "[[ 0.  0.  0.]\n",
      " [ 0.  0.  0.]]\n",
      "[ 0.  0.  0.]\n",
      "[ 0.  0.  0.]\n",
      "grad_Dense0:W error = 3.612133055137527e-12\n",
      "grad_Dense0:b error = 3.0713911555640427e-12\n",
      "grad_X error = 3.545303923963912e-10\n"
     ]
    }
   ],
   "source": [
    "dense = Dense(3)\n",
    "print(dense.initialize({'input_shape': (10, 2)}))\n",
    "print(dense)\n",
    "print(dense.W)\n",
    "print(dense.grad_W)\n",
    "print(dense.b)\n",
    "print(dense.grad_b)\n",
    "\n",
    "grad_checker = GradientsChecker()\n",
    "grad_checker.eval_gradients(dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_1d_padding(array_size, filter_size, stride):\n",
    "    \"\"\"\n",
    "    This function finds padding for 1D arrays.\n",
    "    \n",
    "    Inputs:\n",
    "    - array_size:   size of the provided array\n",
    "    - filter_size:  size of filter\n",
    "    - stride:       stride used for convolution (cross correlation)\n",
    "    \n",
    "    Returns a tuple of:\n",
    "    - padding (left_pad, right_pad): tuple of ints\n",
    "        - left_pad:  left padding for the array\n",
    "        - right_pad: right padding for the array\n",
    "    - output_size: int; the output size of convolution in case of the found padding equals\n",
    "            (array_size + left_pad + right_pad - filter_size) / stride + 1\n",
    "    \"\"\"\n",
    "    assert array_size > 0\n",
    "    assert filter_size > 0\n",
    "    assert stride > 0\n",
    "    \n",
    "    # It is possible that array_size < filter_size. In that case array first needs to be padded\n",
    "    init_left_pad = init_right_pad = 0\n",
    "    if filter_size > array_size:\n",
    "        dif = filter_size - array_size\n",
    "        init_left_pad  = (dif + 1) // 2\n",
    "        init_right_pad = dif - init_left_pad\n",
    "        assert init_left_pad >= init_right_pad\n",
    "        array_size += init_left_pad + init_right_pad\n",
    "\n",
    "    for left_pad in range(filter_size):\n",
    "        for right_pad in range(left_pad + 1):\n",
    "            if check_padding(array_size, filter_size, stride, (left_pad, right_pad)):\n",
    "                output_size = 1 + (array_size + left_pad + right_pad - filter_size) // stride\n",
    "                return (init_left_pad + left_pad, init_right_pad + right_pad), output_size\n",
    "    assert False, 'Appropriate padding not found'\n",
    "\n",
    "\n",
    "def find_2d_padding(image_size, filter_size, stride):\n",
    "    \"\"\"\n",
    "    This function finds padding for 2D arrays. For that it finds padding along height and width.\n",
    "    \n",
    "    Inputs:\n",
    "    - image_size:   tuple (H, W) of image height and width\n",
    "    - filter_size:  tuple (HH, WW) of filter height and width\n",
    "    - stride:       int, equals for both height and width\n",
    "    \n",
    "    Returns a tuple of:\n",
    "    - (H_pad, W_pad): tuple of ints\n",
    "        - H_pad is a tuple (upp_pad, low_pad) for height paddding\n",
    "        - W_pad is a tuple (left_pad, right_pad) for width padding\n",
    "    - (H_output, W_output): tuple of ints\n",
    "        - H_output is the output height of convolution\n",
    "        - W_output is the output width of convolution\n",
    "    \"\"\"\n",
    "    if isinstance(image_size, numbers.Number):\n",
    "        image_size = (image_size, image_size)\n",
    "    if isinstance(filter_size, numbers.Number):\n",
    "        filter_size = (filter_size, filter_size)\n",
    "    if isinstance(stride, numbers.Number):\n",
    "        stride = (stride, stride)\n",
    "    input_h, input_w   = image_size\n",
    "    filter_h, filter_w = filter_size\n",
    "    stride_h, stride_w = stride\n",
    "    pad_u_pad_l, output_h = find_1d_padding(input_h, filter_h, stride_h)\n",
    "    pad_l_pad_r, output_w = find_1d_padding(input_w, filter_w, stride_w)\n",
    "    return (pad_u_pad_l, pad_l_pad_r), (output_h, output_w)\n",
    "\n",
    "def parse_padding(padding):\n",
    "    \"\"\"Accepts a sequence of padding values and turns them into standard format\"\"\"\n",
    "    if isinstance(padding, int):\n",
    "        padding = [padding]\n",
    "    elif isinstance(padding, tuple):\n",
    "        assert len(padding) == 2\n",
    "        padding = [padding]\n",
    "    assert isinstance(padding, list), 'Padding must be provided in a list.'\n",
    "    parsed = []\n",
    "    for value in padding:\n",
    "        if isinstance(value, int):\n",
    "            parsed.append((value, value))\n",
    "        elif isinstance(value, tuple):\n",
    "            assert len(value) == 2\n",
    "            parsed.append(value)\n",
    "        else:\n",
    "            assert False, 'Unknown padding type \"{}\"'.format(type(value).__name__)\n",
    "    return parsed\n",
    "  \n",
    "def check_padding(array_size, filter_size, stride, pad):\n",
    "    \"\"\"\n",
    "    This function checks that given array padding is correct.\n",
    "    \n",
    "    Inputs:\n",
    "    - array_size: int; array size\n",
    "    - filter_size: int; size of filter\n",
    "    - stride: int; stride of convolution (cross-correlation)\n",
    "    - pad: int or tuple of 2 ints; int the first case left and right padding are the same, in the second case\n",
    "        they equal the values in the tuple respectively.\n",
    "        \n",
    "    Returns True if padding is correct. Otherwise returns False.\n",
    "    \"\"\"\n",
    "    pad = parse_padding(pad)\n",
    "    assert len(pad) == 1\n",
    "    left_pad, right_pad = pad[0]\n",
    "    if (array_size + left_pad + right_pad - filter_size) % stride == 0:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((0, 0), 2)\n",
      "(((1, 0), (1, 0)), (3, 3))\n"
     ]
    }
   ],
   "source": [
    "print(find_1d_padding(5, 3, 2))\n",
    "print(find_2d_padding((5, 5), (2, 2), (2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Layer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-f8a3ee78a784>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumbers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mConvolution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     def __init__(self, n_filters, filter_size=(3, 3), stride=(1, 1), padding=None, use_bias=True,  \n\u001b[1;32m      5\u001b[0m                  W_init=None, b_init=None, W_reg=None, b_reg=None, name=None):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Layer' is not defined"
     ]
    }
   ],
   "source": [
    "import numbers\n",
    "\n",
    "class Convolution(Layer):\n",
    "    def __init__(self, n_filters, filter_size=(3, 3), stride=(1, 1), padding=None, use_bias=True,  \n",
    "                 W_init=None, b_init=None, W_reg=None, b_reg=None, name=None):\n",
    "        super().__init__(name=name)\n",
    "        assert isinstance(n_filters, numbers.Number)\n",
    "        self.n_filters = n_filters\n",
    "        if isinstance(filter_size, numbers.Number): \n",
    "            filter_size = (filter_size, filter_size)\n",
    "        if isinstance(stride, number.Number): \n",
    "            stride = (stride, stride)\n",
    "        self.filter_size = filter_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.W_init = W_init\n",
    "        self.b_init = b_init\n",
    "        self.W_reg = W_reg\n",
    "        self.b_reg = b_reg\n",
    "        \n",
    "    def _initialize_seed(self, params):\n",
    "        self.seed = params.setdefault('seed', 0)\n",
    "        self.generator = np.random.RandomState(self.seed)\n",
    "        params['seed'] += 1\n",
    "        return params\n",
    "    \n",
    "    def _initialize_input_shape(self, params):\n",
    "        assert 'input_shape' in params\n",
    "        input_shape = params['input_shape']\n",
    "        assert len(input_shape) == 4\n",
    "        self.input_shape = input_shape\n",
    "    \n",
    "    def _initialize_params(self, params):\n",
    "        self._initialize_W(self, params)\n",
    "        self._initialize_b(self, params)\n",
    "        self._initialize_padding(self, params) # Это костыль\n",
    "        return params\n",
    "    def _initialize_W(self, params):\n",
    "        n_samples, n_channels, input_h, input_w = self.input_shape\n",
    "        filter_h, filter_w = self.filter_size\n",
    "        W_shape = (self.n_filters, n_channels, filter_h, filter_w)\n",
    "        self.W_initializer = get_kernel_initializer(init=self.W_init, generator=self.generator, dtype=self.dtype)\n",
    "        self.W = self.W_initializer(W_shape)\n",
    "        return params\n",
    "    def _initialize_b(self, params):\n",
    "        self.b_initializer = get_bias_initializer(init=self.b_init, dtype=self.dtype)\n",
    "        self.b = self.b_initializer((self.n_filters,))\n",
    "        return params\n",
    "    def _initialize_padding(self, params):\n",
    "        _, _, input_h, input_w = self.input_shape\n",
    "        stride_h, stride_w = self.stride\n",
    "        filter_h, filter_w = self.filter_size\n",
    "        if self.padding is None:\n",
    "            self.padding, _ = find_2d_padding((input_h, input_w), self.filter_size, self.stride)\n",
    "        (upp_pad, low_pad), (left_pad, right_pad) = self.padding\n",
    "        assert (input_h + upp_pad + low_pad - filter_h) % stride_h == 0\n",
    "        assert (input_w + left_pad + right_pad - filter_w) % stride_w == 0\n",
    "        return params\n",
    "\n",
    "    def _initialize_output_shape(self, params):\n",
    "        n_samples, n_channels, input_h, input_w = self.input_shape\n",
    "        stride_h, stride_w = self.stride\n",
    "        filter_h, filter_w = self.filter_size\n",
    "        (upp_pad, low_pad), (left_pad, right_pad) = self.padding\n",
    "        output_h = (input_h + upp_pad + low_pad - filter_h) // stride_h + 1\n",
    "        output_w = (input_w + left_pad + right_pad - filter_w) // stride_w + 1 \n",
    "        self.output_shape = (n_samples, self.n_filters, output_h, output_w)\n",
    "        return params\n",
    "    \n",
    "    def update_output(self, input):\n",
    "        pass\n",
    "    def update_grad_input(self, input, grad_output):\n",
    "        pass\n",
    "    def update_grad_params(self, input, grad_output):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='cnn_conv_forw'></a>\n",
    "### X.X.X Convolution: forward pass  [[toc](#toc)]\n",
    "The core of a convolutional network is the convolution operation. In the file `ml/neural_network/cs231n/second/conv_layers_naive.py`, implement the forward pass for the convolution layer in the function `conv_forward_naive`. \n",
    "\n",
    "You don't have to worry too much about efficiency at this point; just write the code in whatever way you find most clear.\n",
    "\n",
    "You can test your implementation by running the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_shape = (2, 3, 4, 4)\n",
    "w_shape = (3, 3, 4, 4)\n",
    "x = np.linspace(-0.1, 0.5, num=np.prod(x_shape)).reshape(x_shape)\n",
    "w = np.linspace(-0.2, 0.3, num=np.prod(w_shape)).reshape(w_shape)\n",
    "b = np.linspace(-0.1, 0.2, num=3)\n",
    "\n",
    "conv_param = {'stride': 2, 'pad': 1}\n",
    "out, _ = conv_forward(x, w, b, conv_param, method='2d')\n",
    "out, _ = conv_forward_naive(x, w, b, conv_param)\n",
    "correct_out = np.array([[[[-0.08759809, -0.10987781],\n",
    "                           [-0.18387192, -0.2109216 ]],\n",
    "                          [[ 0.21027089,  0.21661097],\n",
    "                           [ 0.22847626,  0.23004637]],\n",
    "                          [[ 0.50813986,  0.54309974],\n",
    "                           [ 0.64082444,  0.67101435]]],\n",
    "                         [[[-0.98053589, -1.03143541],\n",
    "                           [-1.19128892, -1.24695841]],\n",
    "                          [[ 0.69108355,  0.66880383],\n",
    "                           [ 0.59480972,  0.56776003]],\n",
    "                          [[ 2.36270298,  2.36904306],\n",
    "                           [ 2.38090835,  2.38247847]]]])\n",
    "\n",
    "# Compare your output to ours; difference should be around 2e-8\n",
    "print('Testing conv_forward_naive')\n",
    "print('difference: ', rel_error(out, correct_out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='cnn_conv_aside'></a>\n",
    "### 2.1.2 Aside: Image processing via convolutions [[toc](#toc)]\n",
    "As fun way to both check your implementation and gain a better understanding of the type of operation that convolutional layers can perform, we will set up an input containing two images and manually set up filters that perform common image processing operations (grayscale conversion and edge detection). The convolution forward pass will apply these operations to each of the input images. We can then visualize the results as a sanity check. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.misc import imread, imresize\n",
    "\n",
    "kitten, puppy = imread('kitten.jpg'), imread('puppy.jpg')\n",
    "# kitten is wide, and puppy is already square\n",
    "d = kitten.shape[1] - kitten.shape[0]\n",
    "kitten_cropped = kitten[:, d//2:-d//2, :]\n",
    "\n",
    "img_size = 200   # Make this smaller if it runs too slow\n",
    "x = np.zeros((2, 3, img_size, img_size))\n",
    "x[0, :, :, :] = imresize(puppy, (img_size, img_size)).transpose((2, 0, 1))\n",
    "x[1, :, :, :] = imresize(kitten_cropped, (img_size, img_size)).transpose((2, 0, 1))\n",
    "\n",
    "# Set up a convolutional weights holding 2 filters, each 3x3\n",
    "w = np.zeros((2, 3, 3, 3))\n",
    "\n",
    "# The first filter converts the image to grayscale.\n",
    "# Set up the red, green, and blue channels of the filter.\n",
    "w[0, 0, :, :] = [[0, 0, 0], [0, 0.3, 0], [0, 0, 0]]\n",
    "w[0, 1, :, :] = [[0, 0, 0], [0, 0.6, 0], [0, 0, 0]]\n",
    "w[0, 2, :, :] = [[0, 0, 0], [0, 0.1, 0], [0, 0, 0]]\n",
    "\n",
    "# Second filter detects horizontal edges in the blue channel.\n",
    "w[1, 2, :, :] = [[1, 2, 1], [0, 0, 0], [-1, -2, -1]]\n",
    "\n",
    "# Vector of biases. We don't need any bias for the grayscale\n",
    "# filter, but for the edge detection filter we want to add 128\n",
    "# to each output so that nothing is negative.\n",
    "b = np.array([0, 128])\n",
    "\n",
    "# Compute the result of convolving each input in x with each filter in w,\n",
    "# offsetting by b, and storing the results in out.\n",
    "out, _ = conv_forward_naive(x, w, b, {'stride': 1, 'pad': 1})\n",
    "\n",
    "def imshow_noax(img, normalize=True):\n",
    "    \"\"\" Tiny helper to show images as uint8 and remove axis labels \"\"\"\n",
    "    if normalize:\n",
    "        img_max, img_min = np.max(img), np.min(img)\n",
    "        img = 255.0 * (img - img_min) / (img_max - img_min)\n",
    "    plt.imshow(img.astype('uint8'))\n",
    "    plt.gca().axis('off')\n",
    "\n",
    "# Show the original images and the results of the conv operation\n",
    "plt.subplot(2, 3, 1)\n",
    "imshow_noax(puppy, normalize=False)\n",
    "plt.title('Original image')\n",
    "plt.subplot(2, 3, 2)\n",
    "imshow_noax(out[0, 0])\n",
    "plt.title('Grayscale')\n",
    "plt.subplot(2, 3, 3)\n",
    "imshow_noax(out[0, 1])\n",
    "plt.title('Edges')\n",
    "plt.subplot(2, 3, 4)\n",
    "imshow_noax(kitten_cropped, normalize=False)\n",
    "plt.subplot(2, 3, 5)\n",
    "imshow_noax(out[1, 0])\n",
    "plt.subplot(2, 3, 6)\n",
    "imshow_noax(out[1, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<a id='cnn_conv_back'></a>\n",
    "### 2.1.3 Convolution: Naive backward pass [[toc](#toc)]\n",
    "Implement the backward pass for the convolution operation in the function `conv_backward_naive` in the file `cs231n/layers.py`. Again, you don't need to worry too much about computational efficiency.\n",
    "\n",
    "When you are done, run the following to check your backward pass with a numeric gradient check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(231)\n",
    "x = np.random.randn(4, 3, 5, 5)\n",
    "w = np.random.randn(2, 3, 3, 3)\n",
    "b = np.random.randn(2,)\n",
    "dout = np.random.randn(4, 2, 5, 5)\n",
    "conv_param = {'stride': 1, 'pad': 1}\n",
    "\n",
    "dx_num = eval_numerical_gradient_array(lambda x: conv_forward_naive(x, w, b, conv_param)[0], x, dout)\n",
    "dw_num = eval_numerical_gradient_array(lambda w: conv_forward_naive(x, w, b, conv_param)[0], w, dout)\n",
    "db_num = eval_numerical_gradient_array(lambda b: conv_forward_naive(x, w, b, conv_param)[0], b, dout)\n",
    "\n",
    "out, cache = conv_forward_naive(x, w, b, conv_param)\n",
    "dx, dw, db = conv_backward_naive(dout, cache)\n",
    "\n",
    "# Your errors should be around 1e-8'\n",
    "print('Testing conv_backward_naive function')\n",
    "print('dx error: ', rel_error(dx, dx_num))\n",
    "print('dw error: ', rel_error(dw, dw_num))\n",
    "print('db error: ', rel_error(db, db_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
