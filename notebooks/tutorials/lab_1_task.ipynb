{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Лабораторная работа 1. Обучение без учителя\n",
    "\n",
    "Результат лабораторной работы − отчет. Мы предпочитаем принимать отчеты в формате ноутбуков IPython (ipynb-файл). Постарайтесь сделать ваш отчет интересным рассказом, последовательно отвечающим на вопросы из заданий. Помимо ответов на вопросы, в отчете также должен быть код, однако чем меньше кода, тем лучше всем: нам − меньше проверять, вам — проще найти ошибку или дополнить эксперимент. При проверке оценивается четкость ответов на вопросы, аккуратность отчета и кода.\n",
    "\n",
    "### Оценивание и штрафы\n",
    "Каждая из задач имеет определенную «стоимость» (указана в скобках около задачи). Максимально допустимая оценка за работу — 10 баллов. Сдавать задание после указанного срока сдачи нельзя. «Похожие» решения считаются плагиатом и все задействованные студенты (в том числе те, у кого списали) не могут получить за него больше 0 баллов и понижают карму (подробнее о плагиате см. на странице курса). Если вы нашли решение какого-то из заданий в открытом источнике, необходимо прислать ссылку на этот источник (скорее всего вы будете не единственным, кто это нашел, поэтому чтобы исключить подозрение в плагиате, нам необходима ссылка на источник).\n",
    "\n",
    "### Правила сдачи\n",
    "Выполненную работу следует отправить в систему Anytask. Более подробно о системе можно почитать на странице курса. Название отправляемого файла должно иметь следующий формат: Surname_Name_Group_NN.ipynb, где NN — номер лабораторной работы. Например, Kozlova_Anna_CS_01.ipynb."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Кластеризация\n",
    "\n",
    "![Digits](https://www.dropbox.com/s/nrjiahdbpswd63y/digits.png?dl=1)\n",
    "\n",
    "Задача [кластеризации](https://en.wikipedia.org/wiki/Cluster_analysis) данных является одним из примеров задач обучения \"без учителя\". Она заключается в разбиении множества объектов на заданное число кластеров, при этом предполагается, что внутри одного кластера будут находиться похожие между собой объекты. Одним из примеров методов кластеризации является алгоритм [KMeans](https://en.wikipedia.org/wiki/K-means_clustering).\n",
    "\n",
    "### Выбор числа кластеров\n",
    "\n",
    "Для некоторых алгоритмов кластеризации число кластеров является гиперпараметром (например, в случае KMeans). Поэтому для выбора количества кластеров может быть испоьзован следующий подход: при фиксированной метрики качества для разного числа кластеров вычисляют кластеризацию и выбирают то значение, начиная с которого качество \"стабилизируется\".\n",
    "\n",
    "### Метрики качества\n",
    "\n",
    "Оценивание качества построенной кластеризации не всегда тривиальная задача, так как следует учитывать такие факты как:\n",
    " - объекты одного класса должны быть более похоже, чем объекты других кластеров, относительно некоторой заданной метрики похожести\n",
    " - метрика не должна учитывать абсолютные значения меток объектов, попавших в кластер (в случае, если истинные метоки известны)\n",
    "\n",
    "При выполнении задания для оценки качества получившейся кластеризации воспользуемся следующими метриками:\n",
    " - [Homogeneity и Completeness](http://scikit-learn.org/stable/modules/clustering.html#homogeneity-completeness-and-v-measure) \n",
    " - [Adjusted Rand index](http://scikit-learn.org/stable/modules/clustering.html#adjusted-rand-index) \n",
    " - [Silhouette Coefficient](http://scikit-learn.org/stable/modules/clustering.html#silhouette-coefficient)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузите набор данных [digits](http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_digits.html). Перед применением алгоритмов не забудьте перемешать изображения в случайном порядке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(0.5 балла)** Кластеризуйте изображения при помощи алгоритма [KMeans](http://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html), подобрав число кластеров для некоторой фиксированной метрики из указанных выше. Рассмотрите различные способы выбора начального приближения (параметр *init*). Оцените качество получившейся кластеризации используя все описанные выше метрики. Визуализируйте изображения, соответствующие центроидам лучшей кластеризации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Не всегда бывает удобно работать с полной матрицей объект-признак, например, для случая визуализации данных. В одной из предыдущих лабораторных работ был рассмотрен метод уменьшения размерности *PCA*. Вот [здесь](http://scikit-learn.org/stable/auto_examples/manifold/plot_lle_digits.html#example-manifold-plot-lle-digits-py) было показано сравнение различных способов сжатия размерности для проекции на плоскость. На изображениях видно, что некоторые преобразования дают неплохую картину и одинаковые цифры расположены близко друг к другу. Посмотрим, поможет ли это на практике.\n",
    " \n",
    "**(1 балл)** Примените преобразования [PCA](http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html) и [tSNE](http://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html) (для числа компонент 2 и 10) и сравните результаты с предыдущими. Нашелся ли метод кластеризации, превосходящий другие по всем метрикам? Являются ли все три метрики согласованными? Можете ли вы объяснить почему?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(0.5 балла)** Визуализируйте несколько изображений, которые во всех случаях были отнесены к неправильному кластеру (объект назовем ошибочно отнесенным, если он имеет иную метку класса, нежели большая часть объектов в кластере). Можете ли вы пояснить почему так произошло?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Разделение изображения на семантические компоненты\n",
    "\n",
    "![RedPanda](http://imgur.com/6Aa52Lm.png)\n",
    "\n",
    "Алгоритмы кластеризации могут применяться в самых разных задачах. Например, в анализе изображений есть задача разделения изображения на семантические компоненты, которую можно решать в том числе с помощью алгоритмов кластеризации. \n",
    "\n",
    "Загрузите [изображения](https://www.dropbox.com/s/ybnvkemeus9wupe/images.zip?dl=0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для каждого изображения, используя кластеризацию KMeans, выделите компоненты, охарактеризовав каждый пиксель следующим образом: $\\psi_i = [\\lambda x_i, \\lambda y_i, r_i, g_i, b_i]$, где \n",
    "$x_i$ и $y_i$ — координаты пикселя, $r_i, g_i, b_i$ — его цвет, $\\lambda$ — параметр, выражающий важность пространственной связности перед цветовой похожестью."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуйте выделить сегменты при помощи [спектральной кластеризации](http://scikit-learn.org/stable/modules/clustering.html#spectral-clustering). Обратите внимание на [пример в sklearn](http://scikit-learn.org/0.16/auto_examples/cluster/plot_lena_segmentation.html). Для ускорения работы алгоритма рекомендуется привести изображение к серому цвету. При необходимости можно сжать изображения в 2 раза."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(1 балл)** Визуализируйте результаты сегментации (аналогично рисунку выше) для обоих методов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(1 балл)** Поэкспериментируйте с параметрами алгоритмов. Сравните два подхода и сегментации, к которым они приводят.\n",
    "Для всех ли изображений в результате сегментации хорошо видны контуры объектов?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Измерять качество сегментации в этом пункте не нужно, в результате ожидаются только картинки и выводы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Рекомендации к выполнению\n",
    "Для работы с изображениями удобно использовать библиотеку [Scikit-Image](http://scikit-image.org). \n",
    "Установите [PIL](http://www.pythonware.com/products/pil/) для возможности чтения формата JPG.\n",
    "\n",
    "Пример чтения изображения в матрицу:\n",
    "\n",
    "    from skimage.io import imread\n",
    "    I = imread('http://www.birdsgallery.net/gallery/parrots/parrots_4.jpg')\n",
    "\n",
    "    figure(figsize=(15, 5))\n",
    "        for i in xrange(3):\n",
    "        subplot(1, 3, i)\n",
    "        imshow(I[:,:,i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тематическое моделирование\n",
    "\n",
    "![](http://imgur.com/S8WgwBp.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тематическое моделирование является популярным инструментом анализа текстов. Задача заключается в поиске тем $T$, которые хорошо бы описывали документы $D$ со словарём $W$. Большинство тематических моделей оперирует данными в формате \"мешка слов\", т.е. учитывают только частоты слов в документах, а не их порядок. Одной из простейших тематических моделей является [PLSA](https://en.wikipedia.org/wiki/Probabilistic_latent_semantic_analysis), которая приводит к задаче стохастического матричного разложения: \n",
    "\n",
    "$$F \\approx \\Phi \\times \\Theta$$\n",
    "где\n",
    "- $F_{W \\times D}$— матрица распределений слов в документах (нормированные частоты)\n",
    "- $\\Phi_{W \\times T}$ — матрица распределений слов в темах (модель)\n",
    "- $\\Theta_{T \\times D}$ — матрица распределений тем в документах (результат применения модели к обучающим данным)\n",
    "\n",
    "Можно сказать, что алгоритмы тематического моделирования производят мягкую бикластеризацию данных:\n",
    " - *мягкую*, так как объекты относятся не строго к одному кластеру, а к нескольким с разными вероятностями\n",
    " - *бикластеризацию*, так как модель одновременно кластеризует слова по темам и темы по документам."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EM-алгоритм\n",
    "\n",
    "![](http://imgur.com/EeIuI1T.png)\n",
    "\n",
    "С вероятностной точки зрения, задача обучения модели PLSA ставится как максимизация неполного правдоподобия по параметам $\\Phi$ и $\\Theta$. ЕМ-алгоритм для модели PLSA заключается в повторении двух шагов:\n",
    "\n",
    "- **Е-шаг** — оценка распределений тем для каждого слова в каждом документе по параметрам $\\Phi$ и $\\Theta$ (шаг 6);\n",
    "- **М-шаг** — обновление параметров $\\Phi$ и $\\Theta$ на основе полученных оценок (шаги 7 и 9).\n",
    "\n",
    "Существуют различные модификации итерационного процесса, позволяющие снизить расходы по памяти. В данном случае, мы избегаем хранения трехмерной матрицы $p_{tdw}$, сразу пересчитывая $\\Theta$ для текущего документа и аккумулируя счетчики $n_{wt}$ для последующего пересчета $\\Phi$.\n",
    "\n",
    "Псевдокод алгритма записывается следующим образом:\n",
    "\n",
    "1. Инициализировать $\\phi_{wt}^0$ для всех $w \\in W$, $t \\in T$ и $\\theta_{td}^0$ для всех $t \\in T$, $d \\in D$\n",
    "2. Внешний цикл по итерациям $i = 1 ... max\\_iter$:\n",
    "3. $\\quad$ $n_{wt}^i := 0$, $n_t^i := 0$ для всех $w \\in W$ и $t \\in T$ \n",
    "4. $\\quad$ Внутренний цикл по документам $d \\in D$  \n",
    "5. $\\qquad$ $Z_w := \\sum_{t \\in T} \\phi_{wt}^{i-1}\\theta_{td}^{i-1}$ для всех $w \\in d$ $\\cfrac{}{}$\n",
    "6. $\\qquad$ $p_{tdw} := \\cfrac{ \\phi_{wt}^{i-1}\\theta_{td}^{i-1} }{ Z_w }$ (**E-шаг**)\n",
    "7. $\\qquad$ $\\theta_{td}^{i} := \\cfrac{ \\sum_{w \\in d} n_{dw} p_{tdw} }{ n_d }$ для всех $t \\in T$ (**M-шаг**)\n",
    "8. $\\qquad$ Увеличить $n_{wt}^i$ и $n_t^i$ на $n_{dw} p_{tdw}$ для всех $w \\in W$ и $t \\in T$\n",
    "9. $\\quad \\phi_{wt}^i := \\cfrac{n_{wt}^i}{n_t^i}$ для всех $w \\in W$ и $t \\in T$ (**M-шаг**)\n",
    "\n",
    "Обозначения:\n",
    " - $p_{tdw}$ — вероятность темы $t$ для слова $w$ в документе $d$\n",
    " - $\\phi_{wt}$ — элемент матрицы $\\Phi$, соответствующий вероятности слова $w$ в теме $t$\n",
    " - $\\theta_{td}$ — элемент матрицы $\\Theta$, соответствующий вероятности темы $t$ в документе $d$\n",
    " - $n_{wt}$ — элемент матрицы счётчиков отнесения слова $w$ к теме $t$ (путем нормирования этой матрицы получается матрица $\\Phi$)\n",
    " - $Z_w$ — элемент вектора вспомогательных переменных, соответствующий слову $w$\n",
    " - $n_t$ — вектор нормировочных констант для матрицы $n_{wt}$\n",
    " - $n_d$ — вектор нормировочных констант для матрицы $n_{dw}$\n",
    " - $n$ — суммарное число слов в коллекции\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Оценка качества\n",
    "\n",
    "Для оценивания качества построенной модели и контроля сходимости процесса обучения обычно используют [перплексию](http://www.machinelearning.ru/wiki/images/8/88/Voron-iip9-talk.pdf):\n",
    "\n",
    "$$\\mathcal{P} = \\exp\\bigg(- \\frac{\\mathcal{L}}{n} \\bigg) = \\exp\\bigg(- \\cfrac{1}{n}\\sum_{d \\in D}\\sum_{w \\in d} n_{dw} \\ln \\big(\\sum_{t \\in T}\\phi_{wt}\\theta_{td} \\big)\\bigg)$$\n",
    "\n",
    "Это традиционная мера качества в тематическом моделировании, которая основана на правдоподобии модели $\\mathcal{L}$. Число итераций $max\\_iter$ в алгоритме обучения следует выбирать достаточным для того, чтобы перплексия перестала существенно убывать. Однако известно, что перплексия плохо отражает интерпретируемость найденных тем, поэтому помимо нее обычно используются дополнительные меры или экспертные оценки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузите [коллекцию писем Х. Клинтон](https://www.kaggle.com/kaggle/hillary-clinton-emails/downloads/hillary-clinton-emails-release-2015-09-11-01-39-01.zip) с kaggle. Для скачивания может потребоваться регистрация."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Извлеките полные тексты писем из файла *Emails.csv* и подготовьте данные в формате \"мешка слов\" с помощью функции  [CountVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) пакета sklearn. Рекомендуется произвести фильтрацию слов по частотности для удаления слишком редких и стоп-слов (рекомендованный нижний порог в пределах 10 и верхний 400-600)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуйте описанный выше ЕМ-алгоритм для модели $PLSA$ и добавьте в вашу реализацию подсчёт перплексии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(3 балла)** Примените ваш алгоритм к подготовленным данным, рассмотрите число тем T = 5. Постройте график значения перплексии в зависимости от итерации (убедитесь в корректности реализации: график перплексии должен быть невозрастающим). Выведите для каждой темы топ-20 наиболее вероятных слов. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(0.5 балл)** Рассмотрите число тем T = 10, 20. Сравните между собой топ-20 наиболее вероятных слов в каждой теме (а также для модели, полученной ранее). Можно ли сказать, что конкретность каждой темы изменяется с ростом их числа?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(0.5 балл)** Протестируйте модель для разных начальных приближений. Что можно сказать об устойчивости алгоритма (идентичны ли топовые слова в соответствующих темах моделей)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Рекомендации к выполнению\n",
    "- ЕМ-алгоритм стоит реализовывать с использованием векторных операций. Для проверки корректности реализации сперва можно написать скалярную версию, после чего векторизовать её, удостоверившись, что обе реализации дают одинаковый результат. Невекторизованный алгоритм может работать в сотни раз медленнее векторизованного, и его использование может привести к невозможности выполнения задания.\n",
    "- Итерационный процесс следует начинать, инициализировав матрицы $\\Phi$ и $\\Theta$. Инициализация может быть случайной, важно не забыть отнормировать столбцы матриц.\n",
    "- Неэффективная реализация перплексии может в разы замедлить работу алгоритма."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Модель LDA и визуализация\n",
    "\n",
    "Модель [LDA](https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation) является наиболее популярной тематической моделью. Единственное отличие от модели PLSA заключается в введении априорных распределений Дирихле на столбцы матриц $\\Phi$ и $\\Theta$, которое может способствовать дополнительному сглаживанию или разреживанию параметров.\n",
    "\n",
    "В этом задании предлагается воспользоваться реализацией модели [LdaModel](https://radimrehurek.com/gensim/models/ldamodel.html), обучение которой основано на вариационном байесовском выводе."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для выполнения задания вам потребуется установить пакеты [gensim](https://radimrehurek.com/gensim/install.html) и [pyldavis 2.0](https://pyldavis.readthedocs.io/en/latest/readme.html#installation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подготовьте данные в формате, подходящем для *gensim* (полное API gensim можно найти [здесь](https://radimrehurek.com/gensim/apiref.html)). Пример обработки вывода *CountVectorizer* для gensim можно найти [здесь](https://gist.github.com/aronwc/8248457)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(1 балл)** Примените [LdaModel](https://radimrehurek.com/gensim/models/ldamodel.html) к подготовленным данным (рекомендуется задать заведомо большое число итераций в параметре *passes*, например, 30). Визуально сравните полученные темы по топ-20 наиболее вероятным словам с темами, полученными вашей реализацией ЕМ-алгоритма. У какой из моделей получились более интерпретируемые темы?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(1 балл)** Визуализируйте модель из gensim с помощью ldavis (описание API LDAvis для работы с gensim есть [здесь](http://pyldavis.readthedocs.io/en/latest/modules/API.html)), пример — [здесь](https://github.com/bmabey/pyLDAvis/blob/master/notebooks/pyLDAvis_overview.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Рекомендации к выполнению\n",
    "Для обучения *LdaModel* и её последующей визуализации потребуется словарь формата gensim, который можно получить следующей командой\n",
    "\n",
    "    dictionary = gensim.corpora.Dictionary.from_corpus(corpora, vocab_dict)\n",
    "\n",
    "где *corpora* содержит полученное с помощью gensim представление коллекции, а *vocab_dict* — это dict, полученный после работы CountVectorizer, ставящий в соответствие каждому номеру строки в матрице данных само слово в виде строки."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
