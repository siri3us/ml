{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\newcommand{\\Sum}{\\sum\\limits}$\n",
    "$\\newcommand{\\Prod}{\\prod\\limits}$\n",
    "$\\newcommand{\\Max}{\\max\\limits}$\n",
    "$\\newcommand{\\Min}{\\min\\limits}$\n",
    "$\\newcommand{\\Int}{\\int\\limits}$\n",
    "$\\newcommand{\\Exp}{\\mathbb{E}}$\n",
    "$\\newcommand{\\Var}{\\mathbb{V}}$\n",
    "$\\newcommand{\\Energy}{\\mathcal{E}}$\n",
    "$\\newcommand{\\Prob}{\\mathcal{P}}$\n",
    "$\\newcommand{\\N}{\\mathcal{N}}$\n",
    "\n",
    "$\\newcommand{\\LogLike}{\\mathcal{L}}$\n",
    "$\\newcommand{\\Like}{\\ell}$\n",
    "\n",
    "$\\newcommand{\\bolda}{\\boldsymbol{a}}$\n",
    "$\\newcommand{\\boldA}{\\boldsymbol{A}}$\n",
    "$\\newcommand{\\ba}{\\bolda}$\n",
    "$\\newcommand{\\bA}{\\boldA}$\n",
    "\n",
    "$\\newcommand{\\boldb}{\\boldsymbol{b}}$\n",
    "$\\newcommand{\\boldB}{\\boldsymbol{B}}$\n",
    "$\\newcommand{\\bb}{\\boldb}$\n",
    "$\\newcommand{\\bB}{\\boldB}$\n",
    "\n",
    "$\\newcommand{\\boldd}{\\boldsymbol{d}}$\n",
    "$\\newcommand{\\boldD}{\\boldsymbol{D}}$\n",
    "$\\newcommand{\\bd}{\\boldd}$\n",
    "$\\newcommand{\\bD}{\\boldED}$\n",
    "$\\newcommand{\\bolde}{\\boldsymbol{e}}$\n",
    "$\\newcommand{\\boldE}{\\boldsymbol{E}}$\n",
    "$\\newcommand{\\be}{\\bolde}$\n",
    "$\\newcommand{\\bE}{\\boldE}$\n",
    "$\\newcommand{\\boldf}{\\boldsymbol{f}}$\n",
    "$\\newcommand{\\boldF}{\\boldsymbol{F}}$\n",
    "$\\newcommand{\\bf}{\\boldf}$\n",
    "$\\newcommand{\\bF}{\\boldF}$\n",
    "$\\newcommand{\\bolds}{\\boldsymbol{s}}$\n",
    "$\\newcommand{\\boldS}{\\boldsymbol{S}}$\n",
    "$\\newcommand{\\bs}{\\boldsymbol{\\bolds}}$\n",
    "$\\newcommand{\\bS}{\\boldsymbol{\\boldS}}$\n",
    "$\\newcommand{\\boldt}{\\boldsymbol{s}}$\n",
    "$\\newcommand{\\boldT}{\\boldsymbol{S}}$\n",
    "$\\newcommand{\\bt}{\\boldsymbol{\\boldt}}$\n",
    "$\\newcommand{\\bT}{\\boldsymbol{\\boldT}}$\n",
    "\n",
    "$\\newcommand{\\boldu}{\\boldsymbol{u}}$\n",
    "$\\newcommand{\\boldU}{\\boldsymbol{U}}$\n",
    "$\\newcommand{\\bu}{\\boldu}$\n",
    "$\\newcommand{\\bU}{\\boldU}$\n",
    "$\\newcommand{\\boldv}{\\boldsymbol{v}}$\n",
    "$\\newcommand{\\boldV}{\\boldsymbol{V}}$\n",
    "$\\newcommand{\\bv}{\\boldv}$\n",
    "$\\newcommand{\\bV}{\\boldV}$\n",
    "$\\newcommand{\\boldx}{\\boldsymbol{x}}$\n",
    "$\\newcommand{\\boldX}{\\boldsymbol{X}}$\n",
    "$\\newcommand{\\bx}{\\boldx}$\n",
    "$\\newcommand{\\bX}{\\boldX}$\n",
    "$\\newcommand{\\boldY}{\\boldsymbol{Y}}$\n",
    "$\\newcommand{\\boldy}{\\boldsymbol{y}}$\n",
    "$\\newcommand{\\bY}{\\boldY}$\n",
    "$\\newcommand{\\by}{\\boldy}$\n",
    "$\\newcommand{\\boldZ}{\\boldsymbol{Z}}$\n",
    "$\\newcommand{\\boldz}{\\boldsymbol{z}}$\n",
    "$\\newcommand{\\bZ}{\\boldZ}$\n",
    "$\\newcommand{\\bz}{\\boldz}$\n",
    "\n",
    "$\\newcommand{\\boldTheta}{\\boldsymbol{\\Theta}}$\n",
    "$\\newcommand{\\boldtheta}{\\boldsymbol{\\theta}}$\n",
    "$\\newcommand{\\bTheta}{\\boldTheta}$\n",
    "$\\newcommand{\\btheta}{\\boldtheta}$\n",
    "\n",
    "$\\newcommand{\\RR}{\\mathbb{R}}$\n",
    "$\\newcommand{\\diag}{\\text{diag}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='toc'></a>\n",
    "# Содержание\n",
    "* [Теория](#theory)\n",
    "    * [PCA (Principal Component Analysis)](#pca)\n",
    "    * [Probabilistic PCA](#probabilistic)\n",
    "* [Методы нахождения собственных векторов](#methods)\n",
    "* [Применение](#application)\n",
    "* []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Теория"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Хотим выбрать плоскость такую, что в перпендикулярном ей направлении дисперсия значений проекций точек максимальна. Пусть $u$ --- перпендикуляр к плоскости. Пусть $F(\\boldu;\\boldX)$ --- среднее значение квадрата проекций точек на направление $\\boldu$:\n",
    "\\begin{gather}\n",
    "F(\\boldu;\\boldX) = \\frac{1}{N}\\Sum_{i=1}^N \\left\\|\\frac{(\\boldx_i - \\bar{\\boldx}, \\boldu)}{(\\boldu, \\boldu)} \\boldu\\right\\|^2_2 = \n",
    "\\frac{1}{N}\\frac{\\Sum_{i=1}^N (\\boldx_i - \\bar{\\boldx}, \\boldu)^2}{(\\boldu, \\boldu)} \\rightarrow \\max_{\\boldu \\in \\mathbb{R}^N} \n",
    "\\end{gather}\n",
    "Пусть вектор $\\boldu$ нормирован. Тогда приходим к задаче оптимизации\n",
    "\\begin{gather}\n",
    "F(\\boldu;\\boldX)  = \\frac{1}{N}\\Sum_{i=1}^N (\\boldx_i - \\bar{\\boldx}, \\boldu)^2 \\rightarrow \\max_{\\|\\boldu\\|^2_2 = 1} \n",
    "\\end{gather}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лагранжиан имеет вид\n",
    "\\begin{gather}\n",
    "L(\\boldu,\\lambda) = \\frac{1}{N}\\Sum_{i=1}^N (\\boldx_i - \\bar{\\boldx}, \\boldu)^2 - \\frac{\\lambda}{2} (\\|\\boldu\\|_2^2 - 1)\n",
    "\\end{gather}\n",
    "Дифференцируя $L(\\boldu, \\lambda)$ по $\\boldu$, получаем\n",
    "\\begin{gather}\n",
    "\\frac{\\partial L(\\boldu, \\lambda)}{\\partial \\lambda} = \\frac{2}{N}(\\boldx_i - \\bar{\\boldx}, \\boldu) \\cdot (\\boldx_i - \\bar{\\boldx}) - 2\\lambda \\boldu \\\\\n",
    "\\frac{\\partial L(\\boldu, \\lambda)}{\\partial \\lambda}  = 0 \\Leftrightarrow \\lambda \\boldu = \\frac{1}{N}\\Sum_{i=1}^N (\\boldx_i - \\bar{\\boldx}) \\cdot (\\boldx_i - \\bar{\\boldx}, \\boldu) = \\frac{1}{N}\\Sum_{i=1}^N (\\boldx_i - \\bar{\\boldx}) (\\boldx_i - \\bar{\\boldx})^T \\cdot \\boldu\n",
    "\\end{gather}\n",
    "Здесь появляется матрица ковариации $\\boldS$:\n",
    "\\begin{gather}\n",
    "\\boldS = \\frac{1}{N}\\Sum_{i=1}^N (\\boldx_i - \\bar{\\boldx}) (\\boldx_i - \\bar{\\boldx})^T\n",
    "\\end{gather}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом, искомое направление задается собственный вектором матрицы ковариаций $\\boldS$. При этом среднее значение квадратов длин проекций равно собственному значению.\n",
    "\\begin{gather}\n",
    "F(\\boldu;\\boldX) = \\frac{1}{N}\\Sum_{i=1}^N (\\boldx_i - \\bar{\\boldx}, \\boldu)^2 = \\frac{1}{N}\\Sum_{i=1}^N \\boldu^T (\\boldx_i - \\bar{\\boldx})(\\boldx_i - \\bar{\\boldx})^T \\boldu = \\boldu^T \\boldS \\boldu = \\lambda \\|\\boldu\\|_2^2 = \\lambda.\n",
    "\\end{gather}\n",
    "Выбрав собственный вектор $\\boldu_1$, которому соответствует максимальное собственное значение $\\lambda_1$ матрицы ковариаций $\\boldS$, получим искомое направление."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Итеративная процедура нахождения направлений максимальной дисперсии"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пусть $\\lambda_1, \\lambda_2, \\dots, \\lambda_D$ --- собственные векторы матрицы $S$, в порядке убывания, а $\\boldu_1, \\boldu_2, \\dots, \\boldu_D$ --- соответствующие им собственные значения. Докажем, что описанная выше процедура итеративного нахождения направлений наибольшей дисперсии приведт в конечном счете к векторам  $\\boldu_1, \\boldu_2, \\dots, \\boldu_D$.\n",
    "\n",
    "На первом этапе $\\boldS_1 = \\boldS$ получили вектор направления $\\boldu_1$ с собственным значением $\\lambda_1$. Теперь найдем следующий вектор. Выясним, как будет выглядеть матрица ковариаций на второй итерации $\\boldS_2$. \n",
    "\n",
    "Вычтем из каждого вектора $\\boldx_i$ его проекцию на $\\boldu_1$ и для полученных векторов найдем матрицу ковариации.\n",
    "\\begin{gather}\n",
    "\\boldS_2 = \\frac{1}{N}\\Sum_{i=1}^N\\left(\\boldx_i - (\\boldx_i, \\boldu_1)\\boldu_1 - (\\bar{\\boldx} - (\\bar{\\boldx}, \\boldu_1)\\boldu_1)\\right)\\left(\\boldx_i - (\\boldx_i, \\boldu_1)\\boldu_1 - (\\bar{\\boldx} - (\\bar{\\boldx}, \\boldu_1)\\boldu_1)\\right)^T = \\\\ = \\frac{1}{N}\\Sum_{i=1}^N\\left(\\boldx_i - \\bar{\\boldx} - (\\boldx_i - \\bar{\\boldx}, \\boldu_1)\\boldu_1 \\right) \\left(\\boldx_i - \\bar{\\boldx} - (\\boldx_i - \\bar{\\boldx}, \\boldu_1)\\boldu_1 \\right)^T = \\\\ =\\frac{1}{N} \\Sum_{i=1}^N \\left\\{(\\boldx_i - \\bar{\\boldx})(\\boldx_i - \\bar{\\boldx})^T - 2 (\\boldx_i - \\bar{\\boldx}) \\cdot (\\boldx_i - \\bar{\\boldx}, \\boldu_1)  \\cdot \\boldu_1^T + \\boldu_1 \\boldu_1^T (\\boldx_i - \\bar{\\boldx}, \\boldu_1)^2 \\right\\} = \\\\ =  \\frac{1}{N}\\Sum_{i=1}^N \\left\\{(\\boldx_i - \\bar{\\boldx})(\\boldx_i - \\bar{\\boldx})^T - \\boldu_1\\boldu_1^T (\\boldx_i - \\bar{\\boldx})(\\boldx_i - \\bar{\\boldx})^T \\right\\} = \\boldS_1(\\boldE - \\boldu_1\\boldu_1^T) = (\\boldE - \\boldu_1\\boldu_1^T) \\boldS_1.\n",
    "\\end{gather}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заметим, что собственные значения $\\lambda_2 \\ge \\dots \\ge \\lambda_D \\ge 0$ матрицы $\\boldS$ являются также собственными значениями матрицы ковариаций $\\boldS_2$. Действительно,\n",
    "$$\n",
    "\\boldS_2 \\boldu_2 = (\\boldE - \\boldu_1\\boldu_1^T) \\boldS_1 \\boldu_2 = \\lambda_2(\\boldE - \\boldu_1\\boldu_1^T) \\boldu_2 =  \\lambda_2\\boldu_2 - \\boldu_1\\boldu_1^T \\boldu_2 = \\lambda_2\\boldu_2.\n",
    "$$\n",
    "Здесь учтено, что векторы $\\boldu_1, \\dots, \\boldu_D$ ортогональны.\n",
    "\n",
    "Заметим что $\\lambda_2, \\dots, \\lambda_D$ --- это первые $D-1$ собственных значений. Последнее дополнительное собственное значение $\\boldS_2$ равно нулю. Ему соответствует собственный вектор $\\boldu_1$:\n",
    "$$\n",
    "S_2\\boldu_1 = (1-\\boldu_1\\boldu_1^T)\\boldS_1 \\boldu_1 = \\lambda_1 (1-\\boldu_1\\boldu_1^T) \\boldu_1 = \\lambda_1(\\boldu_1 - \\boldu_1) = 0.\n",
    "$$\n",
    "\n",
    "Таким образом, на втором этапе итеративной процедуры будет выбрано направление $\\boldu_2$, так как ему соответствует максимальная дисперсия $\\lambda_2$. В общем случае на $i$-ом этапе будет выбран вектор $\\boldu_i$ с дисперсией $\\lambda_i$. Что и требовалось доказать."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Смылс доказанного выше сводится к тому, что в итеративной процедуре как таковой нет смысла: достаточно найти собственные вектора и собственные значения для исходной матрицы ковариаций.\n",
    "\n",
    "#### Смысл проекции\n",
    "* Собственные значения --- дисперсия точек вдоль направления соответствующего собственного вектора\n",
    "* Если $M > 0$ собственных значений равны нулю или близки к нему, то данные сосредоточены в подпространстве размерности $D - M$\n",
    "* Достаточно выбрать только первые $K$ собственных векторов, соответствующих максимальным собственным значениям."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='methods'></a>\n",
    "# Методы нахождения собственных значений<sup>[toc](#toc)</sup>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Пусть дана матрица $X \\in \\RR^{n\\times m}$. Хотим найти $k$-мерное подпространство, минимизирующее квадрат сумму квадратов длин проекций векторов из $X$ на это подпространство. \n",
    "\n",
    "Для всякой матрицы $X \\in \\RR^{n\\times m}$ существует сингулярное разложение:\n",
    "$$\n",
    "X = U \\Sigma V^T,\n",
    "$$\n",
    "где $U \\in \\RR^{n\\times n}$, $U \\in \\RR^{n\\times n}$, $\\Sigma = \\text{diag}^*_{m,n}[\\sigma_1, \\dots, \\sigma_{\\min(m,n)}] \\in \\RR^{m\\times n}$. Матрицы $U$ и $V$ --- ортогональные матрицы, матрица $\\Sigma$ --- псевдоортогональная. \n",
    "\n",
    "* Матрица $U = [\\boldu_m, \\dots, \\boldu_m]$ --- матрица собственных векторов отображения $XX^T$:\n",
    "\\begin{gather}\n",
    "XX^T = U\\Sigma V^T \\cdot V \\Sigma^T U^T = U\\Sigma \\Sigma^T U^T = U ~ \\diag[\\sigma_1^2, \\dots, \\sigma_r^2, 0, \\dots, 0]U^T \n",
    "\\end{gather}\n",
    "* Матрица $V = [\\boldv_1, \\dots, \\boldv_n]$ --- матрица собственных векторов отображения $X^TX$:\n",
    "\\begin{gather}\n",
    "X^TX = V\\Sigma^T U^T \\cdot U \\Sigma V^T = U\\Sigma \\Sigma^T U^T = U ~ \\diag[\\sigma_1^2, \\dots, \\sigma_r^2, 0, \\dots, 0]U^T \n",
    "\\end{gather}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='application'></a>\n",
    "# Применение PCA<sup>[toc](#toc)</sup>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='app_images'></a>\n",
    "## Применение к сжатию изображений<sup>[toc](#toc)</sup>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='app_recover'></a>\n",
    "## Задача восстановления профиля крыла<sup>[toc](#toc)</sup>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
