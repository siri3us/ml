{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='toc'></a>\n",
    "* [1. FeatureBase](#feature_base)\n",
    "    * [1.2 Tests](#fb_tests)\n",
    "* [2. NumericalFeature](#numerical_feature)\n",
    "* [3. AggregatedFeature](#aggregated_feature)\n",
    "* [4. CategoricalFeature](#categorical_feature)\n",
    "* [5. CategoricalCombiner](#categorical_combiner)\n",
    "* [6. FeaturesStorage](#features_storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "_add_to_path = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if _add_to_path:\n",
    "    sys.path.append('../')\n",
    "from ml.feature import *\n",
    "\n",
    "FEATURE_PREFIXES = \\\n",
    "{'CAT': '',\n",
    " 'NUM': '',\n",
    " 'LE' : '',    # LabelEncoded feature\n",
    " 'OHE': 'Ohe', # OneHotEncoded feature\n",
    " 'CTR': 'Ctr', # Counter feature\n",
    " 'LOO': 'Loo', # LeaveOneOut feature\n",
    " 'FIL': 'Fil'}\n",
    "\n",
    "def print_columns(*args):\n",
    "    all_labels = []\n",
    "    all_values = []\n",
    "    v_length = 0\n",
    "    m_length = 0\n",
    "    for label, values in args:\n",
    "        m_length = max(m_length, len(label))\n",
    "        all_labels.append(label)\n",
    "        all_values.append(values)\n",
    "        v_length = max(v_length, max([len(str(v)) for v in values]))\n",
    "    for label, values in args:\n",
    "        s = []\n",
    "        if m_length > 0:\n",
    "            s.append(label.ljust(m_length) + ':')\n",
    "        for v in values:\n",
    "            s.append(str(v).ljust(v_length))\n",
    "        print(' '.join(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    FeatureKernel - класс, реализующий общий функционал класса FeatureBase. \n",
      "    Является одним из аттрибутов экземпляров класса FeatureBase (SparseFeatureBase и DenseFeatureBase).\n",
      "    Реализуемые операции включают в себя: \n",
      "        1) проверку корректности значений признака \n",
      "        2) вывод сообщений о некорректности значений\n",
      "        3) предобработку и постобработку признаков\n",
      "        4) получение характеристик признаков (размера, формата и т.п.)\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(FeatureKernel.__doc__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='feature_base'></a>\n",
    "## 1. FeatureBase [[toc](#toc)] [[up](#toc)] [[down](#fb_tests)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.019s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "%run test_feature_base.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='fb_tests'></a>\n",
    "### 1.2 Tests<sup>[toc](#toc)</sup>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPARSE = True\n",
      "str(feature) = [FeatureBase: f, (1, 15)]\n",
      "feature.values.shape = (15, 1)\n",
      "feature.values =   (1, 0)\t1.0\n",
      "  (5, 0)\t1.0\n",
      "  (6, 0)\t1.1\n",
      "  (7, 0)\t1.0\n",
      "  (9, 0)\t4.0\n",
      "  (10, 0)\t1.0\n",
      "  (11, 0)\t7.0\n",
      "feature._values.shape = (1, 15)\n",
      "feature._values =   (0, 1)\t1.0\n",
      "  (0, 5)\t1.0\n",
      "  (0, 6)\t1.1\n",
      "  (0, 7)\t1.0\n",
      "  (0, 9)\t4.0\n",
      "  (0, 10)\t1.0\n",
      "  (0, 11)\t7.0\n",
      "[Dense ]: [[ 0.   1.   0.   0.   0.   1.   1.1  1.   0.   4.   1.   7.   0.   0.   0. ]]\n",
      "[Sparse]:   (1, 0)\t1.0\n",
      "  (5, 0)\t1.0\n",
      "  (6, 0)\t1.1\n",
      "  (7, 0)\t1.0\n",
      "  (9, 0)\t4.0\n",
      "  (10, 0)\t1.0\n",
      "  (11, 0)\t7.0\n",
      "feature.shape = (1, 15), feature.name = f\n",
      "is_numeric =  True\n",
      "\n",
      "\n",
      "\n",
      "SPARSE = False\n",
      "str(feature) = [FeatureBase: f, (15,)]\n",
      "feature.values.shape = (15, 1)\n",
      "feature.values = [ 0.   1.   0.   0.   0.   1.   1.1  1.   0.   4.   1.   7.   0.   0.   0. ]\n",
      "feature._values.shape = (15,)\n",
      "feature._values = [ 0.   1.   0.   0.   0.   1.   1.1  1.   0.   4.   1.   7.   0.   0.   0. ]\n",
      "[Dense ]: [ 0.   1.   0.   0.   0.   1.   1.1  1.   0.   4.   1.   7.   0.   0.   0. ]\n",
      "[Sparse]:   (1, 0)\t1.0\n",
      "  (5, 0)\t1.0\n",
      "  (6, 0)\t1.1\n",
      "  (7, 0)\t1.0\n",
      "  (9, 0)\t4.0\n",
      "  (10, 0)\t1.0\n",
      "  (11, 0)\t7.0\n",
      "feature.shape = (15,), feature.name = f\n",
      "is_numeric =  True\n"
     ]
    }
   ],
   "source": [
    "for sparse in [True, False]:\n",
    "    values = [0, 1, 0, 0, 0, 1, 1.1, 1, 0, 4, 1, 7, 0, 0, 0]\n",
    "    values = np.array(values)\n",
    "    if sparse:\n",
    "        values = csc_matrix(values)\n",
    "        values.eliminate_zeros()\n",
    "    name = 'f'\n",
    "    feature = FeatureBase(values, name)\n",
    "\n",
    "    fvalues = feature.values\n",
    "    _fvalues = feature._values\n",
    "    if sparse:\n",
    "        print('SPARSE =', sparse)\n",
    "        print('str(feature) =', feature)\n",
    "        print('feature.values.shape = {}\\nfeature.values = {}'.format(fvalues.shape, fvalues.tocsr()))\n",
    "        print('feature._values.shape = {}\\nfeature._values = {}'.format(_fvalues.shape, _fvalues.tocsr()))\n",
    "        print('[Dense ]:', feature.get_values(sparse=False).flatten())\n",
    "        print('[Sparse]:', feature.get_values(sparse=True).tocsr())\n",
    "    else:\n",
    "        print('\\n\\n\\nSPARSE =', sparse)\n",
    "        print('str(feature) =', feature)\n",
    "        print('feature.values.shape = {}\\nfeature.values = {}'.format(fvalues.shape, fvalues.flatten()))\n",
    "        print('feature._values.shape = {}\\nfeature._values = {}'.format(_fvalues.shape, _fvalues.flatten()))\n",
    "        print('[Dense ]:', feature.get_values(sparse=False).flatten())\n",
    "        print('[Sparse]:', feature.get_values(sparse=True).tocsr())\n",
    "    print('feature.shape = {}, feature.name = {}'.format(feature.shape, feature.name))\n",
    "    print('is_numeric = ', feature.is_numeric())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='numerical_feature'></a>\n",
    "## 2. NumericalFeature<sup>[toc](#toc)</sup>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.021s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "%run test_numerical_feature.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='aggregated_feature'></a>\n",
    "## 3. AggregatedFeature<sup>[toc](#toc)</sup> <sup>[down](#categorical_feature)</sup>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AggregatedFeature[[NumericalFeature: F0, (10,)][NumericalFeature: F1, (10,)][NumericalFeature: F2, (10,)][NumericalFeature: F3, (10,)][NumericalFeature: F4, (10,)]]\n",
      "  (2, 0)\t1\n",
      "  (4, 0)\t1\n",
      "  (9, 0)\t1\n",
      "  (2, 1)\t1\n",
      "  (4, 1)\t1\n",
      "  (5, 1)\t1\n",
      "  (7, 1)\t1\n",
      "  (9, 1)\t1\n",
      "  (3, 2)\t1\n",
      "  (6, 2)\t1\n",
      "  (8, 2)\t1\n",
      "  (0, 3)\t1\n",
      "  (5, 3)\t1\n",
      "  (9, 3)\t1\n",
      "  (0, 4)\t1\n",
      "  (3, 4)\t1\n",
      "  (4, 4)\t1\n",
      "  (8, 4)\t1\n",
      "  (9, 4)\t1\n",
      "[[0 0 0 1 1]\n",
      " [0 0 0 0 0]\n",
      " [1 1 0 0 0]\n",
      " [0 0 1 0 1]\n",
      " [1 1 0 0 1]\n",
      " [0 1 0 1 0]\n",
      " [0 0 1 0 0]\n",
      " [0 1 0 0 0]\n",
      " [0 0 1 0 1]\n",
      " [1 1 0 1 1]]\n",
      "  (2, 0)\t1\n",
      "  (4, 0)\t1\n",
      "  (5, 0)\t1\n",
      "  (7, 0)\t1\n",
      "  (9, 0)\t1\n",
      "  (3, 1)\t1\n",
      "  (6, 1)\t1\n",
      "  (8, 1)\t1\n",
      "  (0, 2)\t1\n",
      "  (5, 2)\t1\n",
      "  (9, 2)\t1\n",
      "[[0 0 1]\n",
      " [0 0 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [1 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [1 0 1]]\n"
     ]
    }
   ],
   "source": [
    "class AggregatedFeature(Checker):\n",
    "    DELETE_FEATURE = 4\n",
    "    \"\"\"\n",
    "    Позволяет хранить значения нескольких признаков, например, OHE представления категориальных признаков.\n",
    "    \"\"\"\n",
    "    def __init__(self, features, name, copy=True, verbose=0, treat_const='none'):\n",
    "        \"\"\"\n",
    "        Аргументы:\n",
    "            :param features - список объектов FeatureBase\n",
    "            :param name     - имя агрегированного признака\n",
    "            :param exclude_const - исключить константные признаки из множества?\n",
    "            :param copy     - если True, то каждый каждый признак будет скопирован\n",
    "            :param verbose  - уровень печати (nonnegative int)\n",
    "        \"\"\"\n",
    "        self._set_treat_const(treat_const)\n",
    "        self._set_features(features, name, copy)\n",
    "        self._verbose = verbose\n",
    "        \n",
    "    def _set_treat_const(self, treat_const):\n",
    "        treat_vals = ['none', 'delete', 'assert']\n",
    "        if treat_const not in treat_vals:\n",
    "            raise ValueError('treat_const must be one of the following: {}.'.format(treat_vals))\n",
    "        self._treat_const = treat_const\n",
    "        \n",
    "    def _set_features(self, features, name, copy=True):\n",
    "        \"\"\"\n",
    "            :param features - список объектов FeatureBase\n",
    "            :param name - имя агрегированного признака\n",
    "            :param copy - если True, то сохраняются копии признаков\n",
    "        \"\"\"\n",
    "        self._check_features(features, name)\n",
    "        self._name = name\n",
    "        self._feature_names = [feature._name for feature in features]\n",
    "        if copy:\n",
    "            _features = {feature._name: feature.deepcopy() for feature in features}\n",
    "        else:\n",
    "            _features = {feature._name: feature for feature in features}\n",
    "        if self._treat_const == 'none':\n",
    "            self._features = _features\n",
    "        elif self._treat_const == 'delete':\n",
    "            self._features = {feature._name: features for feature in _features if not feature.is_constant()}\n",
    "        else:\n",
    "            for feature in _features:\n",
    "                if feature.is_constant():\n",
    "                    raise ValueError('Constant feature \"{}\" for treat_const=\"{}\"'.format(\n",
    "                        feature._name, self._treat_const))\n",
    "            self._features = _features\n",
    "        \n",
    "    def _check_features(self, features, name):\n",
    "        \"\"\"\n",
    "        Проверяет, что признаки хранятся в list или np.ndarray, все признаки имеют тип FeatureBase, размеры признаков равны.\n",
    "        \"\"\"\n",
    "        if not isinstance(features, (np.ndarray, list)):\n",
    "            raise TypeError('Wrong format of \"features\" with name \"{}\" for \"{}\".'.format(name, type(self).__name__))\n",
    "        if not all([isinstance(feature, FeatureBase) for feature in features]):\n",
    "            raise TypeError('One of subfeatures of feature \"{}\" is not an object of FeatureBase.'.format(name))\n",
    "        lengths = [len(feature) for feature in features]\n",
    "        if min(lengths) != max(lengths):\n",
    "            raise ValueError('Provided features with name \"{}\" have different lengths'.format(name))\n",
    "        if min(lengths) == 0:\n",
    "            raise ValueError('Features with name \"{}\" have zero length. Must have positive length.'.format(name))\n",
    "\n",
    "    def exclude_constant(self, verbose=False):\n",
    "        \"\"\"\n",
    "        Исключает константные подпризнаки из рассмотрения.\n",
    "        \"\"\"\n",
    "        to_delete = []\n",
    "        for feature_name in self._features:\n",
    "            if self._features[feature_name].is_constant():\n",
    "                to_delete.append(feature_name)\n",
    "        for feature_name in to_delete:\n",
    "            if verbose: print('Deleting constant feature \"{}\"'.format(feature_name))\n",
    "            del self._features[feature_name]\n",
    "        self._feature_names = [feature_name for feature_name in self._feature_names \n",
    "                               if feature_name in self._features]\n",
    "\n",
    "    def is_constant(self):\n",
    "        if len(self._features) == 0: # In case if all feature are excluded due to constant values\n",
    "            return True\n",
    "        return all([feature.is_constant() for feature in self._features.values()])\n",
    "            \n",
    "    def get_values(self, feature_names=None, sparse=False, as_dataframe=False, **kwargs):\n",
    "        if feature_names is None:\n",
    "            feature_names = self._feature_names\n",
    "        features = [self._features[feature_name] for feature_name in feature_names \n",
    "                    if feature_name in self._features.keys()]\n",
    "        # TODO проверки\n",
    "        X = []\n",
    "        for feature in features:\n",
    "            X.append(feature.get_values(sparse=sparse))\n",
    "        if len(X) == 0: # Если вдруг все пусто\n",
    "            raise ValueError(\"All values are constant. Senseless feature!\")\n",
    "        if sparse:\n",
    "            X = scipy.sparse.hstack(X)\n",
    "        else:\n",
    "            X = np.concatenate(X, axis=1)\n",
    "            if as_dataframe:\n",
    "                X = pd.DataFrame(X, columns=feature_names)\n",
    "        return X\n",
    "    \n",
    "    def __repr__(self):\n",
    "        s = 'AggregatedFeature['\n",
    "        for feature_name in [feature_name for feature_name in self._feature_names \n",
    "                             if feature_name in self._features]:\n",
    "            feature = self._features[feature_name]\n",
    "            s += str(feature)\n",
    "        s += ']'\n",
    "        return s\n",
    "    \n",
    "n_features = 5\n",
    "features = []\n",
    "feature_names = []\n",
    "size = 10\n",
    "sparse = True; as_dataframe=True\n",
    "for n_feature in range(n_features):\n",
    "    values = np.random.randint(low=0, high=2, size=size)\n",
    "    features.append(NumericalFeature(values, 'F' + str(n_feature), verbose=0))\n",
    "    feature_names.append(features[-1].get_name())\n",
    "aggr_feature = AggregatedFeature(features, 'AGGR', copy=False)\n",
    "print(aggr_feature)\n",
    "values = aggr_feature.get_values(sparse=sparse, as_dataframe=as_dataframe)\n",
    "print(values)\n",
    "if sparse:\n",
    "    print(values.todense())\n",
    "values = aggr_feature.get_values(feature_names=feature_names[1:4], sparse=sparse, as_dataframe=as_dataframe) \n",
    "print(values)\n",
    "if sparse:\n",
    "    print(values.todense())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='categorical_feature'></a>\n",
    "## 4. CategoricalFeature<sup>[toc](#toc)</sup>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import unittest\n",
    "import copy\n",
    "import numbers\n",
    "from collections import defaultdict\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, train_test_split\n",
    "from itertools import product, chain\n",
    "\n",
    "class CategoricalFeature(FeatureBase):\n",
    "    \"\"\"\n",
    "    Класс для хранения категориальных признаков. На данный момент доступна только реализация с \n",
    "    dense хранением данных. \n",
    "    \n",
    "    Список методов:\n",
    "        deepcopy\n",
    "        set_label2cat\n",
    "        set_cat2label\n",
    "        get_cat_values\n",
    "        get_filter_feature\n",
    "        get_counter_feature\n",
    "        get_loo_feature\n",
    "        get_le_feature\n",
    "        get_ohe_feature\n",
    "    \"\"\"\n",
    "    ################################################################################### \n",
    "\n",
    "    CAT_FEATURE_INIT = 8\n",
    "    OHE = 9\n",
    "    def _is_label_encoded(self, values, name=None):\n",
    "        \"\"\"\n",
    "        Возвращает True, если значения признака label encoded. Иначе возвращает False или вызывает исключение\n",
    "        (в зависимости от параметра throw).\n",
    "        Аргументы:\n",
    "            :param values - категориальные значения (np.ndarray)\n",
    "            :param name - имя категориального признака (str)\n",
    "        \"\"\"\n",
    "        if not self.is_numeric():\n",
    "            return False\n",
    "        labels = sorted(list(set(values)))\n",
    "        prev_value = labels[0]\n",
    "        if prev_value != 0:\n",
    "            return False\n",
    "        for value in labels[1:]:\n",
    "            if value != prev_value + 1:\n",
    "                return False\n",
    "            prev_value = value\n",
    "        return True\n",
    "    \n",
    "    def is_label_encoded(self):\n",
    "        return self._is_label_encoded(self._values, self._name)\n",
    "\n",
    "    def _check_label_encoded(self, values, name, throw=True):\n",
    "        \"\"\"\n",
    "        Возвращает True, если значения признака label encoded. Иначе возвращает False или вызывает исключение\n",
    "        (в зависимости от параметра throw).\n",
    "        Аргументы:\n",
    "            :param values - значения признака (np.ndarray)\n",
    "            :param name   - имя категориального признака (str)\n",
    "            :param throw  - вызывать исключение? (bool)\n",
    "        \"\"\"\n",
    "        if not self._is_label_encoded(values):\n",
    "            if throw: \n",
    "                raise ValueError(self._error_msg('Feature \"{}\" is not label-encoded'.format(name)))\n",
    "            return False\n",
    "        return True\n",
    "            \n",
    "    def _check_cat2label(self, values, name, cat2label, throw=True):\n",
    "        \"\"\"\n",
    "        Проверяет, что преобразование категорий в метки корректно. Возвращает True в случае корректности.\n",
    "        Иначе возвращает False или вызывает исключение (в зависимости от параметра throw).\n",
    "        Аргументы:\n",
    "            :param values    - значения признака (np.ndarray)\n",
    "            :param name      - имя признака (cat)\n",
    "            :param cat2label - преобразование в метки (dict)\n",
    "            :param throw     - вызывать исключение? (bool)\n",
    "        \"\"\"\n",
    "        if not set(values) == set(cat2label.values()):\n",
    "            if throw: \n",
    "                print(set(values), set(cat2label.values()))\n",
    "                raise ValueError(self._error_msg('Num of values != number of labels for feature \"{}\"'.format(name)))\n",
    "            else: \n",
    "                return False\n",
    "        if not len(set(cat2label.keys())) == len(set(cat2label.values())):\n",
    "            if throw: \n",
    "                raise ValueError(self._error_msg('There is no one-to-one correspondance in cat2label for feature \"{}\"'.format(name)))\n",
    "            else: \n",
    "                return False\n",
    "        return True\n",
    "    \n",
    "    ###################################################################################\n",
    "    def deepcopy(self):\n",
    "        new_feature = CategoricalFeature(copy.deepcopy(self._values), self._name, verbose=self._verbose)\n",
    "        new_feature.set_cat2label(self._cat2label)\n",
    "        return new_feature\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return type(self).__name__ + '({}; {})'.format(self.name, self.values.shape)\n",
    "    \n",
    "    def __init__(self, values, name, cat2label=None, verbose=0):\n",
    "        \"\"\"\n",
    "        По завершении работы конструктора признаки оказываются закодированы метками от 1 до N, где\n",
    "        N - число различных значений признака.\n",
    "        Аргументы:\n",
    "            :param values - значения категориальной переменной (np.ndarray, list)\n",
    "            :param name   - имя категориальной переменной (str)\n",
    "            :param cat2label - mapping для преобразования категорий в метки (dict)\n",
    "        \"\"\"\n",
    "        assert isinstance(values, (np.ndarray, list))\n",
    "        super().__init__(values, name, verbose)\n",
    "        self._name = self._get_categorical_name(name)\n",
    "        msg_init = self._info_msg('__init__({})'.format(name))\n",
    "        \n",
    "        self._cat2label = None\n",
    "        self._label2cat = None\n",
    "        if cat2label is not None:\n",
    "            self._printers[self.CAT_FEATURE_INIT](msg_init + ': applying mapping \"cat2label\" to values')\n",
    "            self._values = np.array(list(map(lambda cat: cat2label[cat], self._values)))\n",
    "            self._check_cat2label(self._values, self._name, cat2label)\n",
    "            self._cat2label = copy.deepcopy(cat2label)\n",
    "            self._label2cat = {label:cat for cat, label in cat2label.items()}\n",
    "            \n",
    "        self._properties = {}\n",
    "        self._properties['is_numeric'] = self.is_numeric()\n",
    "        self._properties['is_label_encoded'] = self.is_label_encoded()\n",
    "        self._properties['is_constant'] = self.is_constant()\n",
    "        if self._properties['is_label_encoded']:\n",
    "            self._printers[self.CAT_FEATURE_INIT](msg_init + ': feature \"{}\" is already label encoded'.format(name))\n",
    "        else:\n",
    "            self._printers[self.CAT_FEATURE_INIT](msg_init + ': label encoding feature \"{}\"'.format(name))\n",
    "        self._label_encode()\n",
    "  \n",
    "        # These values are used for filtering rare values\n",
    "        self._threshold = None\n",
    "        self._unique_label = None\n",
    "    \n",
    "        assert self._properties['is_label_encoded'], 'By the end of constructor feature \"{}\" is not label encoded. Something is wrong.'.format(self.name)\n",
    "        assert self._properties['is_numeric'], 'By the end of the constructor feature \"{}\" is not numeric. Something is wrong'.format(self.name)\n",
    "        \n",
    "    ##################################################################################\n",
    "    def set_label2cat(self, label2cat=None):\n",
    "        if label2cat is None:\n",
    "            self._label2cat = None\n",
    "            self._cat2label = None\n",
    "        else:\n",
    "            cat2label = {cat:label for label, cat in label2cat.items()}\n",
    "            self._check_cat2label(self._values, self._name, cat2label, True)\n",
    "            self._label2cat = copy.deepcopy(label2cat)\n",
    "            self._cat2label = cat2label\n",
    "            \n",
    "    def set_cat2label(self, cat2label=None):\n",
    "        \"\"\"\n",
    "        Подразумевает, что сейчас в self._values хранятся метки\n",
    "        \"\"\"\n",
    "        if cat2label is None:\n",
    "            self._cat2label = None\n",
    "            self._label2cat = None\n",
    "        else:\n",
    "            self._check_cat2label(self._values, self._name, cat2label, True)\n",
    "            self._cat2label = copy.deepcopy(cat2label)\n",
    "            self._label2cat = {label:cat for cat, label in cat2label.items()}\n",
    "        \n",
    "    def get_cat_values(self):\n",
    "        \"\"\"\n",
    "        Возвращает признаки в виде изначальных категорий, а не в LE-закодированном виде, в котором \n",
    "        они хранятся внутри класса CategoricalFeature.\n",
    "        \"\"\"\n",
    "        if self._label2cat is None:\n",
    "            # Такое возможно только если признак изначально был передан в закодированном виде\n",
    "            assert self._properties['is_label_encoded'], 'Expected encoded feature.'\n",
    "            return np.array(self._values)\n",
    "        return np.array(list(map(lambda label: self._label2cat[label], self._values)))\n",
    "        \n",
    "    ##################################################################################\n",
    "        \n",
    "    def _filter_feature(self, threshold):\n",
    "        \"\"\"\n",
    "        Отфильтровывает те категории, которые встречаются не более threshold раз. Заменяет их на новую \n",
    "        категорию. Данная категория будет иметь максимальное значение метки. Применение данной функции \n",
    "        ведет к преобразованию имени признака: добавляется приставка FIL_\n",
    "        \n",
    "        Аргументы:\n",
    "            :param threshold - если число появлений категории не превосходит threshold, \n",
    "                                то она отсеивается (int, float)\n",
    "        \"\"\"\n",
    "        \n",
    "        # Checking if the feature is label encoded\n",
    "        if not self._properties['is_label_encoded']:\n",
    "            raise ValueError('Cannot filter feature \"{}\" as it is not label encoded.'.format(self.name))\n",
    "        # Even if the filtration does not change feature values, we change its name and threshold parameters\n",
    "        self._name = self._get_filtered_name(self._name, threshold)\n",
    "        self._threshold = threshold\n",
    "        \n",
    "        # Checking if there are rare values present in the feature\n",
    "        counts = Counter(self._values)\n",
    "        for label, n_occurences in counts.items():\n",
    "            if n_occurences <= threshold:\n",
    "                self._unique_label = self._values.max() + 1\n",
    "                self._properties['is_label_encoded'] = False\n",
    "                break\n",
    "        if self._unique_label is None: \n",
    "            # There are no labels which occur less or equal to threshold times\n",
    "            return\n",
    "        \n",
    "        # Some features occur less or equal threshold times. Let us find them\n",
    "        rare_labels = set()\n",
    "        rare_categories = set()\n",
    "        # Changing rare labels to the chosen unique_label\n",
    "        for n, label in enumerate(self._values):\n",
    "            if counts[label] <= threshold:\n",
    "                if self._cat2label is not None:\n",
    "                    rare_labels.add(label)\n",
    "                    rare_categories.add(self._label2cat[label])\n",
    "                self._values[n] = self._unique_label # setting rare label to new value\n",
    "\n",
    "        # Forming new categories names\n",
    "        if self._cat2label is not None:    \n",
    "            if len(rare_categories) > 1:\n",
    "                new_cat = '(' + '|'.join(sorted(list(rare_categories))) + ')'\n",
    "            elif len(rare_categories) == 1:\n",
    "                new_cat = list(rare_categories)[0]\n",
    "            else:\n",
    "                assert False, '\"rare_categories\" must not be empty at this point. Something is wrong.'\n",
    "\n",
    "            for label in rare_labels:\n",
    "                del self._label2cat[label]\n",
    "            self._label2cat[self._unique_label] = new_cat\n",
    "            for cat in rare_categories:\n",
    "                del self._cat2label[cat]\n",
    "            self._cat2label[new_cat] = self._unique_label\n",
    "            \n",
    "        self._properties['is_constant'] = self.is_constant()\n",
    "        self._label_encode()\n",
    "        assert self._properties['is_label_encoded']\n",
    "        assert self._properties['is_numeric']\n",
    "        \n",
    "    def get_filtered_feature(self, threshold):\n",
    "        \"\"\" \n",
    "        Возвращает признак, полученный из данного фильтрацией категорий по порогу threshold: \n",
    "        все категории, встречающиеся не чаще чем threshold, отфильтровываются функцией _filter_feature.\n",
    "        Все отфильтрованные категории становятся новой категорией.\n",
    "       \n",
    "        Аргументы:\n",
    "            :param - если число появлений категории не превосходит threshold, то она отсеивается (int, float)\n",
    "        \"\"\"\n",
    "        new_feature = self.deepcopy()\n",
    "        new_feature._filter_feature(threshold)\n",
    "        return new_feature\n",
    "    \n",
    "    def get_counter_feature(self):\n",
    "        \"\"\"\n",
    "        Возвращает признак NumericalFeature, равный числу появления каждой из категорий.\n",
    "        \"\"\"\n",
    "        counts = Counter(self._values)\n",
    "        new_values = np.zeros_like(self._values)\n",
    "        for n, value in enumerate(self._values):\n",
    "            new_values[n] = counts[value]\n",
    "        new_name = self._get_counter_name(self._name)\n",
    "        return NumericalFeature(new_values, new_name)\n",
    "\n",
    "    def get_loo_feature(self, Y_train, cv, alpha=0.01, seed=1234, scale=0.01):\n",
    "        \"\"\"\n",
    "        Предполагает, что первые len(Y_train) примеров принадлежат обучающей выборке\n",
    "        \"\"\"\n",
    "        assert isinstance(Y_train, (np.ndarray, list))\n",
    "        assert len(Y_train) <= len(self._values)\n",
    "        train_size = len(Y_train)\n",
    "        test_size = len(self._values) - train_size\n",
    "        \n",
    "        np.random.seed(seed)\n",
    "        X_train = self._values[:train_size]\n",
    "        mean_y = np.mean(Y_train)\n",
    "        all_labels = set(self._values)\n",
    "        X_new_train = np.zeros(len(X_train))\n",
    "\n",
    "        for n_split, (train_indices, test_indices) in enumerate(cv.split(X_train, Y_train)):\n",
    "            x_train, y_train = X_train[train_indices], Y_train[train_indices]\n",
    "            x_test, y_test = X_train[test_indices], Y_train[test_indices]\n",
    "            for label in all_labels:\n",
    "                N_all = x_train.shape[0]\n",
    "                train_mask = x_train == label\n",
    "                N_label = np.sum(train_mask)\n",
    "                print('n_split = {}, label = {}, den = {}'.format(n_split, label, N_label + alpha * N_all))\n",
    "                X_new_train[test_indices[x_test == label]] = \\\n",
    "                    (np.sum(y_train[train_mask]) + alpha * mean_y * N_all) / (max(N_label, 1) + alpha * N_all)\n",
    "        if scale > 0:\n",
    "            multipliers = np.random.normal(loc=1.0, scale=scale, size=len(self._values))\n",
    "        else:\n",
    "            multipliers = np.ones(len(self._values))\n",
    "        if test_size > 0:\n",
    "            X_test = self._values[train_size:]\n",
    "            X_new_test = np.zeros(test_size)\n",
    "            for label in all_labels:\n",
    "                train_mask = X_train == label\n",
    "                N_all = train_size\n",
    "                N_label = np.sum(train_mask)\n",
    "                X_new_test[X_test == label] = (np.sum(Y_train[train_mask]) +\n",
    "                                               alpha * mean_y * train_size) / (max(N_label, 1) + alpha * N_all)\n",
    "\n",
    "            X_new = np.concatenate([X_new_train, X_new_test]) * multipliers\n",
    "        else:\n",
    "            X_new = X_new_train * multipliers\n",
    "        new_name = self._get_loo_name(self._name)\n",
    "        return NumericalFeature(X_new, new_name)\n",
    "        \n",
    "    ############################################################\n",
    "    ##                       Кодировщики                      ##\n",
    "    ############################################################\n",
    "    def _label_encode(self):\n",
    "        \"\"\"\n",
    "        Выполняет label-кодирование признака.\n",
    "        \"\"\"\n",
    "        if self._properties['is_label_encoded']:\n",
    "            if len(FEATURE_PREFIXES['LE']) > 0:\n",
    "                if not self._name.startswith(FEATURE_PREFIXES['LE']):\n",
    "                    self.name = self._get_label_encoded_name(self._name)\n",
    "            return\n",
    "        \n",
    "        label_encoder = LabelEncoder()\n",
    "        self._values = label_encoder.fit_transform(self._values)\n",
    "        classes = label_encoder.classes_\n",
    "        old_label2new_label = {old_label:new_label for new_label, old_label in enumerate(classes)}\n",
    "        new_label2old_label = {new_label:old_label for new_label, old_label in enumerate(classes)}\n",
    "\n",
    "        self._name = self._get_label_encoded_name(self.name)\n",
    "        self._properties['is_label_encoded'] = self.is_label_encoded()\n",
    "        self._properties['is_numeric'] = self.is_numeric()\n",
    "        self._properties['is_constant'] = self.is_constant()\n",
    "        \n",
    "        if self._unique_label is not None:\n",
    "            # This placed can be reached when _label_encode() is invoked from _filter_feature()\n",
    "            self._unique_label = old_label2new_label[self._unique_label]\n",
    "            assert self._unique_label == len(old_label2new_label) - 1\n",
    "            assert (FEATURE_PREFIXES['FIL'] + '{}_'.format(self._threshold)) in self._name\n",
    "            \n",
    "        if self._label2cat is None:\n",
    "            self._cat2label = old_label2new_label\n",
    "            self._label2cat = new_label2old_label\n",
    "        else:\n",
    "            new_label2cat = {}\n",
    "            for old_label in self._label2cat:\n",
    "                new_label = old_label2new_label[old_label]\n",
    "                new_label2cat[new_label] = self._label2cat[old_label]\n",
    "            cat2new_label = {cat:new_label for new_label, cat in new_label2cat.items()}\n",
    "            self._cat2label = cat2new_label\n",
    "            self._label2cat = new_label2cat\n",
    "            \n",
    "        assert self._properties['is_label_encoded']\n",
    "        assert self._properties['is_numeric']\n",
    "\n",
    "    def get_le_feature(self):\n",
    "        \"\"\"\n",
    "        Возвращает LE-закодированный признак, полученный на основе данного. В данной реализации CategoricalFeature\n",
    "        поддерживается инваринат: внутреннее состояние признака всегда LE-закодированное. Поэтому вызов\n",
    "        _label_encode() в реализации функции по сути бесполезен. Возможно что-то измениться в будущих версиях.\n",
    "        \"\"\"\n",
    "        new_feature = self.deepcopy()\n",
    "        new_feature._label_encode()\n",
    "        return new_feature\n",
    "    \n",
    "    def get_ohe_feature(self, sparse=True, omit_uniques=False):\n",
    "        \"\"\"\n",
    "        Аргументы:\n",
    "            :param sparse       - вернуть sparse или dense представление? (bool)\n",
    "            :param omit_uniques - если True, то отфильтрованная категория не войдет в состав OHE-признака (bool)\n",
    "        \"\"\"\n",
    "        assert self._properties['is_label_encoded']\n",
    "        assert self._properties['is_numeric']\n",
    "        msg_base = self._method_msg('get_ohe_feature(): ')\n",
    "        \n",
    "        if (not omit_uniques) or (self._unique_label is None):\n",
    "            unique_label = -1\n",
    "        else:\n",
    "            unique_label = self._unique_label\n",
    "        \n",
    "        ohe_name = self._get_ohe_name(self._name)\n",
    "        counter = Counter(self._values)\n",
    "        \n",
    "        if self._properties['is_constant']:\n",
    "            # No sense of OHE for constant feature\n",
    "            assert np.sum(self._values) == 0\n",
    "            assert len(self._cat2label) == 1\n",
    "            assert list(self._cat2label.values())[0] == 0\n",
    "            self._printers[self.OHE](msg_base + 'OHE of constant feature \"{}\".'.format(self._name))\n",
    "            return NumericalFeature(self._values, ohe_name)\n",
    "        \n",
    "        if (len(counter) == 2):\n",
    "            # In case of binary feature one column of OHE representation can be omitted\n",
    "            assert set(self._cat2label.values()) == set([0, 1])\n",
    "            self._printers[self.OHE](msg_base + 'OHE senseless for binary feature \"{}\".'.format(self._name))\n",
    "            return NumericalFeature(self._values, ohe_name)\n",
    "        \n",
    "            # На данный момент непонятно, почему при unique_label >= 0 возвращали константу\n",
    "            \"\"\"if unique_label >= 0:\n",
    "                assert unique_label == 1\n",
    "                self._printers[self.OHE](msg_base + 'omiting unique label for \"{}\" turns it constant.'.format(self._name))\n",
    "                return NumericalFeature(np.zeros(len(self._values)), ohe_name)\n",
    "            else:\n",
    "                self._printers[self.OHE](msg_base + 'OHE senseless for binary feature \"{}\".'.format(self._name))\n",
    "                return NumericalFeature(self._values, ohe_name)\"\"\"\n",
    "        \n",
    "        ohe_values = OneHotEncoder(sparse=sparse).fit_transform(self._values[:, np.newaxis])\n",
    "        if sparse:\n",
    "            ohe_values = ohe_values.tocsc()\n",
    "        if unique_label >= 0:\n",
    "            assert unique_label == len(counter) - 1\n",
    "            mask = (self._values == unique_label)\n",
    "            if sparse:\n",
    "                last_column = ohe_values[:, unique_label].toarray().flatten()\n",
    "            else:\n",
    "                last_column = ohe_values[:, unique_label]\n",
    "            assert np.all(last_column == mask), 'Last column of ohe feature must correspond to unique_label.'\n",
    "            ohe_values = ohe_values[:, :unique_label]       \n",
    "        \n",
    "        feature_names = []\n",
    "        feature_values = []\n",
    "        for label in sorted(self._label2cat.keys()):\n",
    "            if label != unique_label:\n",
    "                feature_names.append(self._label2cat[label])\n",
    "                feature_values.append(ohe_values[:, label])\n",
    "        features = [NumericalFeature(fvalues, fname) for fvalues, fname in zip(feature_values, feature_names)]\n",
    "        return AggregatedFeature(features, ohe_name, verbose=self._verbose, copy=False)\n",
    "        \n",
    "    def get_properties(self):\n",
    "        return copy.deepcopy(self._properties)\n",
    "\n",
    "\n",
    "name = 'f'\n",
    "cat_values = ['A', 'A', 'B', 'A', 'B', 'C', 'A', 'B', 'C', 'D', 'A', 'B', 'C', 'D', 'E']\n",
    "values     = [0,   0,    1,   0,   1,   2,   0,   1,   2,   3,   0,   1,   2,   3,   4]\n",
    "cat2label  = {'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4}\n",
    "f = CategoricalFeature(cat_values, name, cat2label, verbose=0)\n",
    "\n",
    "test_initial = False\n",
    "test_counter = False\n",
    "test_filtered = False\n",
    "test_ohe = False\n",
    "test_ohe_filtered = False\n",
    "test_loo = False\n",
    "\n",
    "if test_initial:\n",
    "    print('INITIAL FEATURE:')\n",
    "    print('True values    : ', values)\n",
    "    print('Obtained values: ', list(f.get_values().flatten()))\n",
    "    print('\\nTrue CAT values: ', cat_values)\n",
    "    print('Obtained CATs  : ', list(f.get_cat_values()))\n",
    "\n",
    "if test_counter:\n",
    "    print('\\n\\nCOUNTER FEATURE')\n",
    "    print('Initial feature: ', f)\n",
    "    counter_f = f.get_counter_feature()\n",
    "    print('Counter feature: ', counter_f)\n",
    "    print(counter_f.get_values().flatten())\n",
    "    print('Values of initial and counter features:')\n",
    "    args = [('initial', f.get_values().flatten()), ('counter', counter_f.get_values().flatten())]\n",
    "    print_columns(*args)\n",
    "\n",
    "if test_filtered:\n",
    "    print('\\n\\nFILTERED FEATURES')\n",
    "    ffs = {n:f.get_filtered_feature(n) for n in range(6)}\n",
    "    for n in range(6):\n",
    "        fil_feature = ffs[n].get_values().flatten()\n",
    "        cat_feature = ffs[n].get_cat_values().flatten()\n",
    "        ctr_feature = ffs[n].get_counter_feature().get_values().flatten()\n",
    "        print('fil_feature props: ', ffs[n].get_properties())\n",
    "        print('fil feature name: ', ffs[n])\n",
    "        print('ctr feature name: ', ffs[n].get_counter_feature())\n",
    "        args = [('fil_feature', fil_feature), ('cat_feature', cat_feature), ('ctr_feature', ctr_feature)]\n",
    "        print_columns(*args)\n",
    "        print('\\n\\n')\n",
    "\n",
    "if test_ohe:   \n",
    "    print('\\n\\nOHE FEATURES')\n",
    "    ohe_feature = f.get_ohe_feature()\n",
    "    a = f.get_ohe_feature(sparse=False).get_values(sparse=True).toarray()\n",
    "    b = f.get_ohe_feature(sparse=False).get_values(sparse=False)\n",
    "    c = f.get_ohe_feature(sparse=True).get_values(sparse=False)\n",
    "    d = f.get_ohe_feature(sparse=True).get_values(sparse=True).toarray()\n",
    "    assert np.allclose(a, b)\n",
    "    assert np.allclose(b, c)\n",
    "    assert np.allclose(c, d)\n",
    "    assert np.allclose(d, a)\n",
    "    print('Initial feature:', ohe_feature)\n",
    "    print('\\tvalues:\\n', f.get_values().flatten())\n",
    "    print('OHE feature:', ohe_feature)\n",
    "    print('\\tOHE values:\\n', a)\n",
    "\n",
    "if test_ohe_filtered:\n",
    "    print('\\n\\nOHE FEATURES + FILTRATION')\n",
    "    for threshold, omit_uniques in product([1, 2, 3, 4, 5], [False, True]):\n",
    "        ff = f.get_filtered_feature(threshold=threshold)\n",
    "        print('OHE feature with omit_uniques = {} and threshold = {}'.format(omit_uniques, threshold))\n",
    "        print('Initial  feature name:', f)\n",
    "        print('Filtered feature name:', ff)\n",
    "        print('Initial feature values:', f.get_values().flatten())\n",
    "        print('Filtered fature values:', ff.get_values().flatten())\n",
    "        print('threhold =', ff._threshold, '  unique_label =', ff._unique_label)\n",
    "        ff_ohe = ff.get_ohe_feature(omit_uniques=omit_uniques)\n",
    "        print('FilOHE feature name:  ', ff_ohe)\n",
    "        print('FilOHE feature values:\\n', ff_ohe.get_values(sparse=False))\n",
    "        print('FilOHE is constant:   ', ff_ohe.is_constant())\n",
    "        print('\\n\\n')\n",
    "\n",
    "if test_loo:\n",
    "    print('\\n\\nLEAVE ONE OUT')\n",
    "    X = np.array([0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0])\n",
    "    y = np.array([0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0])\n",
    "    cat_feature = CategoricalFeature(X, 'f')\n",
    "    random_state = 345\n",
    "    n_splits = 2\n",
    "    cv = StratifiedKFold(n_splits, shuffle=True, random_state=random_state)\n",
    "    print_columns(('ind', np.arange(len(X))), ('X', X), ('y', y))\n",
    "    for n_split, (train_indices, test_indices) in enumerate(cv.split(X, y)):\n",
    "        print('\\n\\nn_split =', n_split)\n",
    "        X_tr, y_tr = X[train_indices], y[train_indices]\n",
    "        X_ts, y_ts = X[test_indices],  y[test_indices]\n",
    "        X_loo_true = np.array([1/4., 2/3., 0, 2/3., 0, 2/3., 2/3., 2/3., 2/3., 0, 0, 1/4.])\n",
    "        print()\n",
    "        print_columns(('ind', train_indices), ('X_tr', X_tr), ('y_tr', y_tr))\n",
    "        print()\n",
    "        print_columns(('ind', test_indices), ('X_ts', X_ts), ('y_ts', y_ts))\n",
    "        \n",
    "    loo_feature = cat_feature.get_loo_feature(y, cv, alpha=0, scale=0.0)\n",
    "    X_loo_found = loo_feature.get_values(sparse=False).flatten()\n",
    "    print('LOO:\\n')\n",
    "    print_columns(('True', X_loo_true), ('Found', X_loo_found))\n",
    "    np.allclose(X_loo_found, X_loo_true)\n",
    "    #print(cat_feature, cat_feature)\n",
    "    #print(loo_feature, loo_feature.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='categorical_combiner'></a>\n",
    "# 5. CategoricalCombiner<sup>[toc](#toc)</sup>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comb_feature: [CategoricalFeature: f1+f2+f3, (12,)]\n",
      "name = f1+f2+f3, values = [0 2 6 1 4 7 7 1 3 5 6 0]\n",
      "fil_feature:  [CategoricalFeature: Fil1_f1+f2+f3, (12,)]\n",
      "name = Fil1_f1+f2+f3, values = [0 4 2 1 4 3 3 1 4 4 2 0]\n",
      "\n",
      "degree = 1\n",
      "new_features: {'f3': CategoricalFeature(f3; (12, 1)), 'f2': CategoricalFeature(f2; (12, 1)), 'f1': CategoricalFeature(f1; (12, 1))}\n",
      "  f1: 0 1 2 0 1 2 2 0 1 2 2 0\n",
      "  f2: 0 1 0 1 0 1 1 1 1 0 0 0\n",
      "  f3: 1 0 1 1 1 1 1 1 1 0 1 1\n",
      "\n",
      "degree = 2\n",
      "new_features: {'f1+f3': CategoricalFeature(f1+f3; (12, 1)), 'f2+f3': CategoricalFeature(f2+f3; (12, 1)), 'f1+f2': CategoricalFeature(f1+f2; (12, 1))}\n",
      "  f1+f2: 0 2 4 1 3 5 5 1 2 4 4 0\n",
      "  f1+f3: 0 2 4 0 1 4 4 0 1 3 4 0\n",
      "  f2+f3: 1 3 1 2 1 2 2 2 2 0 1 1\n",
      "\n",
      "degree = 3\n",
      "new_features: {'f1+f2+f3': CategoricalFeature(f1+f2+f3; (12, 1))}\n",
      "  f1+f2+f3: 0 2 6 1 4 7 7 1 3 5 6 0\n",
      "\n",
      "degree = None\n",
      "new_features: {'f1+f3': CategoricalFeature(f1+f3; (12, 1)), 'f2+f3': CategoricalFeature(f2+f3; (12, 1)), 'f3': CategoricalFeature(f3; (12, 1)), 'f1+f2+f3': CategoricalFeature(f1+f2+f3; (12, 1)), 'f1+f2': CategoricalFeature(f1+f2; (12, 1)), 'f2': CategoricalFeature(f2; (12, 1)), 'f1': CategoricalFeature(f1; (12, 1))}\n",
      "  f1      : 0 1 2 0 1 2 2 0 1 2 2 0\n",
      "  f1+f2   : 0 2 4 1 3 5 5 1 2 4 4 0\n",
      "  f1+f2+f3: 0 2 6 1 4 7 7 1 3 5 6 0\n",
      "  f1+f3   : 0 2 4 0 1 4 4 0 1 3 4 0\n",
      "  f2      : 0 1 0 1 0 1 1 1 1 0 0 0\n",
      "  f2+f3   : 1 3 1 2 1 2 2 2 2 0 1 1\n",
      "  f3      : 1 0 1 1 1 1 1 1 1 0 1 1\n"
     ]
    }
   ],
   "source": [
    "from itertools import product, chain, combinations\n",
    "\n",
    "class CategoricalCombiner(Checker):\n",
    "    \"\"\"\n",
    "    get_all_combinations\n",
    "    get_combined_feature\n",
    "    \"\"\"\n",
    "    METHOD = 4\n",
    "    def __init__(self, verbose=0):\n",
    "        super().__init__()\n",
    "        self._verbose = verbose\n",
    "\n",
    "    \n",
    "        \n",
    "    def get_all_combinations(self, features, degree=None, hash=hash):\n",
    "        \"\"\"\n",
    "        Возвращает всевозможные комбинации степени degree из признаков \n",
    "        Аргументы:\n",
    "            :param features - признаки для комбинирования; все должны быть CategoricalFeature\n",
    "            :param degree   - степень комбинаций; каждый новый признак - это комбинация degree признаков\n",
    "            :param hash     - функция превращения комбинации признаков в значение нового признака\n",
    "        \"\"\"\n",
    "        feature_names = [feature.name for feature in features]\n",
    "        \n",
    "        method_msg = self._method_msg('get_all_combinations')\n",
    "        methdo_msg = method_msg + '({}, degree={})'.format(feature_names, degree)\n",
    "        self._printers[self.METHOD](method_msg)\n",
    "        \n",
    "        combined_features = {}\n",
    "        if degree is None:\n",
    "            degree_range = range(1, len(feature_names) + 1)\n",
    "        else:\n",
    "            degree_range = [degree]\n",
    "        for degree in degree_range:\n",
    "            for some_features in combinations(features, degree):\n",
    "                new_feature = self.get_combined_feature(some_features, hash) \n",
    "                combined_features[new_feature.get_name()] = new_feature\n",
    "        return combined_features\n",
    "\n",
    "    def get_combined_feature(self, features, hash=hash):\n",
    "        self.check_sizes_(features)\n",
    "        if len(features) < 1:\n",
    "            raise ValueError('At least one feature name must be given')\n",
    "        if len(features) == 1:\n",
    "            return features[0].deepcopy()\n",
    "                             \n",
    "        feature_values = []\n",
    "        feature_names = []\n",
    "        for feature in features:\n",
    "            values = feature.get_values(False).flatten()\n",
    "            feature_values.append(values)\n",
    "            feature_names.append(feature.get_name())\n",
    "            \n",
    "        new_values = []\n",
    "        for hyper_value in zip(*feature_values):\n",
    "            new_values.append(hash(hyper_value))\n",
    "        new_values = LabelEncoder().fit_transform((new_values))\n",
    "        new_name = '+'.join(feature_names)\n",
    "        return CategoricalFeature(new_values, new_name)\n",
    "\n",
    "    def check_sizes_(self, features):\n",
    "        if len(Counter([len(feature) for feature in features])) != 1:\n",
    "            raise ValueError('Features must have equal sizes!')\n",
    "\n",
    "            \n",
    "test = True\n",
    "if test:\n",
    "    features = {'f1': [0, 1, 2, 0, 1, 2, 2, 0, 1, 2, 2, 0],\n",
    "                'f2': [0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0],\n",
    "                'f3': [1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1]}\n",
    "    cat_features = [CategoricalFeature(features[name], name) for name in sorted(features.keys())]\n",
    "    cat_combiner = CategoricalCombiner()\n",
    "    new_feature = cat_combiner.get_combined_feature(cat_features)\n",
    "    print('comb_feature:', new_feature)\n",
    "    print('name = {}, values = {}'.format(new_feature._name, new_feature._values))\n",
    "    fil_feature = new_feature.get_filtered_feature(1)\n",
    "    print('fil_feature: ', fil_feature)\n",
    "    print('name = {}, values = {}'.format(fil_feature.name, fil_feature._values))\n",
    "    for degree in [1, 2, 3, None]:\n",
    "        print('\\ndegree = {}'.format(degree))\n",
    "        new_features = cat_combiner.get_all_combinations(cat_features, degree=degree)\n",
    "        print('new_features:', new_features)\n",
    "        args = []\n",
    "        for f_name, feature in new_features.items():\n",
    "            args.append(('  ' + f_name, feature.get_values(False).flatten()))\n",
    "        args = sorted(args, key=lambda x: x[0])\n",
    "        print_columns(*args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='features_storage'></a>\n",
    "# 6. CategoricalFeaturesManager<sup>[toc](#toc)</sup>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SET UP: ['f1', 'f2', 'f3']\n",
      "\n",
      "\tf1 in manager = True\n",
      "\tf2 in manager = True\n",
      "\tf3 in manager = True\n",
      "\n",
      "    f1  f2  f3\n",
      "0    0   1   0\n",
      "1    1   1   1\n",
      "2    0   0   0\n",
      "3    1   1   1\n",
      "4    2   1   0\n",
      "5    0   0   1\n",
      "6    1   1   0\n",
      "7    2   1   1\n",
      "8    3   0   0\n",
      "9    0   1   1\n",
      "10   1   1   0\n",
      "11   2   0   1\n",
      "12   3   1   0\n",
      "13   4   1   1\n",
      "\n",
      "DELETING AND SETTING FEATURES:\n",
      "del f1: ['f2', 'f3']\n",
      "del f2: ['f3']\n",
      "del f3: []\n",
      "set f1: ['f1']\n",
      "set f2: ['f1', 'f2']\n",
      "set f3: ['f1', 'f2', 'f3']\n",
      "\n",
      "COMBINING FEATURES:\n",
      "[CategoricalFeature: f1, (14,)] [0 1 0 1 2 0 1 2 3 0 1 2 3 4]\n",
      "[CategoricalFeature: f2, (14,)] [1 1 0 1 1 0 1 1 0 1 1 0 1 1]\n",
      "[CategoricalFeature: f3, (14,)] [0 1 0 1 0 1 0 1 0 1 0 1 0 1]\n",
      "[CategoricalFeature: f1+f2, (14,)] [1 2 0 2 4 0 2 4 6 1 2 3 5 7]\n",
      "[CategoricalFeature: f1+f3, (14,)] [0 2 0 2 4 1 3 5 6 1 3 5 6 7]\n",
      "[CategoricalFeature: f2+f3, (14,)] [3 2 0 2 3 1 3 2 0 2 3 1 3 2]\n",
      "[CategoricalFeature: f1+f2+f3, (14,)] [ 3  5  0  5  8  1  4  7 10  2  4  6  9 11]\n",
      "all: ['f1', 'f2', 'f3', 'f1+f2', 'f1+f3', 'f2+f3', 'f1+f2+f3']\n",
      "\n",
      "FILTERED FEATURES:\n",
      "\tbefore filtration\n",
      "feature names: ['f1', 'f2', 'f3', 'f1+f2', 'f1+f3', 'f2+f3', 'f1+f2+f3']\n",
      "    f1  f2  f3  f1+f2  f1+f3  f2+f3  f1+f2+f3\n",
      "0    0   1   0      1      0      3         3\n",
      "1    1   1   1      2      2      2         5\n",
      "2    0   0   0      0      0      0         0\n",
      "3    1   1   1      2      2      2         5\n",
      "4    2   1   0      4      4      3         8\n",
      "5    0   0   1      0      1      1         1\n",
      "6    1   1   0      2      3      3         4\n",
      "7    2   1   1      4      5      2         7\n",
      "8    3   0   0      6      6      0        10\n",
      "9    0   1   1      1      1      2         2\n",
      "10   1   1   0      2      3      3         4\n",
      "11   2   0   1      3      5      1         6\n",
      "12   3   1   0      5      6      3         9\n",
      "13   4   1   1      7      7      2        11\n",
      "\tafter filtration\n",
      "feature names: ['Fil2_f1', 'Fil2_f2', 'Fil2_f3', 'Fil2_f1+f2', 'Fil2_f1+f3', 'Fil2_f2+f3', 'Fil2_f1+f2+f3']\n",
      "    Fil2_f1  Fil2_f2  Fil2_f3  Fil2_f1+f2  Fil2_f1+f3  Fil2_f2+f3  \\\n",
      "0         0        1        0           1           0           1   \n",
      "1         1        1        1           0           0           0   \n",
      "2         0        0        0           1           0           2   \n",
      "3         1        1        1           0           0           0   \n",
      "4         2        1        0           1           0           1   \n",
      "5         0        0        1           1           0           2   \n",
      "6         1        1        0           0           0           1   \n",
      "7         2        1        1           1           0           0   \n",
      "8         3        0        0           1           0           2   \n",
      "9         0        1        1           1           0           0   \n",
      "10        1        1        0           0           0           1   \n",
      "11        2        0        1           1           0           2   \n",
      "12        3        1        0           1           0           1   \n",
      "13        3        1        1           1           0           0   \n",
      "\n",
      "    Fil2_f1+f2+f3  \n",
      "0               0  \n",
      "1               0  \n",
      "2               0  \n",
      "3               0  \n",
      "4               0  \n",
      "5               0  \n",
      "6               0  \n",
      "7               0  \n",
      "8               0  \n",
      "9               0  \n",
      "10              0  \n",
      "11              0  \n",
      "12              0  \n",
      "13              0  \n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "class CategoricalFeaturesManager(Checker):\n",
    "    \"\"\"\n",
    "    Данный класс отвечает за хранение категориальных признаков. Предоставляет пользователю \n",
    "    следующие возможности:\n",
    "        is_present\n",
    "        add_feature\n",
    "        set_feature\n",
    "        del_feature\n",
    "        get_feature\n",
    "        get_list_of_features\n",
    "    \"\"\"\n",
    "    METHOD = 4\n",
    "    def __init__(self, features=None, verbose=0):\n",
    "        \"\"\"\n",
    "            :param verbose - уровень печати сообщений\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self._features = collections.OrderedDict()\n",
    "        self._n_samples = None\n",
    "        self._verbose = verbose\n",
    "        self._categorical_combiner = CategoricalCombiner(verbose)\n",
    "        if features is not None:\n",
    "            self.set_features(features)\n",
    "        \n",
    "    def __contains__(self, feature_name):\n",
    "        return feature_name in self._features\n",
    " \n",
    "    ###################################################################\n",
    "    def is_present(self, name):\n",
    "        \"\"\"\n",
    "        Возвращает True, если признак с таким именем содержится в хранилище. Иначе - False.\n",
    "        \"\"\"\n",
    "        return (name in self._features)\n",
    "    def _check_if_present(self, *args):\n",
    "        for name in args:\n",
    "            if not self.is_present(name):\n",
    "                raise ValueError(self._error_msg(\"unknown feature \\\"{}\\\"\".format(name)))  \n",
    "    def _is_binary(self, values):\n",
    "        if len(Counter(values)) == 2:\n",
    "            return True\n",
    "        return False\n",
    "    def _check_feature(self, feature):\n",
    "        self._check_type(feature, str(feature), CategoricalFeature)\n",
    "        if (self._n_samples is not None) & (len(feature) != self._n_samples):\n",
    "            raise ValueError(\"Given feature vector has size {} while must have size {}.\".format(\n",
    "                        len(feature), self._n_samples))\n",
    "\n",
    "    ###################################################################\n",
    "    def add_feature(self, feature, copy=True, replace=False):\n",
    "        self.set_feature(feature, copy, replace)\n",
    "    def set_feature(self, feature, copy=True, replace=False):\n",
    "        \"\"\"\n",
    "        Помещает признак в хранилище. По умолчанию всегда вызывает исключение, если признак с таким\n",
    "        именем уже есть в хранилище. По умолчанию всегда сохраняет в хранилище копию признака.\n",
    "        Аргументы:\n",
    "            :param feature - словарь из {имя_признака: признак}. (dict)\n",
    "            :param copy    - если True, то в хранилище будет помещена копия признака. (bool)\n",
    "            :parma replace - если True, то признак с таким же именем будет заменен;\n",
    "                             если False, то наличине признака с таким же именем вызывает исключение. (bool)\n",
    "        \"\"\"\n",
    "        \n",
    "        self._check_feature(feature) # новый признак имеет правильный размер и категориальный тип\n",
    "        if not replace:              # если замена признака запрещена ...\n",
    "            if self.is_present(feature.get_name()): # и уже есть признак с таким именем, то ...\n",
    "                error_msg = self._method_msg('set_feature: ') +\\\n",
    "                    'feature \"{}\" cannot be replaced. Check \"replace\" parameter'.format(feature.get_name())\n",
    "                raise ValueError(error_msg)\n",
    "\n",
    "        self._n_samples = len(feature)\n",
    "        self.del_feature(feature, throw=False)\n",
    "        if copy:\n",
    "            self._features[feature.get_name()] = feature.deepcopy()\n",
    "        else:\n",
    "            self._features[feature.get_name()] = feature\n",
    "    def set_features(self, features, copy=True, replace=False):\n",
    "        for feature in features:\n",
    "            self.set_feature(feature, copy=copy, replace=replace)\n",
    "    def del_feature(self, feature_name, throw=True):\n",
    "        \"\"\"\n",
    "        Аргументы:\n",
    "            :param feature_name\n",
    "            :param throw\n",
    "        \"\"\"\n",
    "        if not self.is_present(feature_name):\n",
    "            if throw:\n",
    "                error_msg = self._method_msg('del_feature') +\\\n",
    "                    'feature \"{}\" is not present in storage. Cannot be deleted.'.format(feature_name)\n",
    "                raise KeyError(error_msg)\n",
    "            return False\n",
    "        else:\n",
    "            del self._features[feature_name]\n",
    "            if len(self._features) == 0:\n",
    "                self._n_samples = None\n",
    "            return True\n",
    "    \n",
    "    def get_feature(self, feature_name, copy=True):\n",
    "        self._check_if_present(feature_name)\n",
    "        if copy:\n",
    "            return self._features[feature_name].deepcopy()\n",
    "        return self._features[feature_name]\n",
    "    \n",
    "    def get_list_of_features(self):\n",
    "        return list(self._features.keys())\n",
    "\n",
    "\n",
    "    ###################################################################\n",
    "    #    Функции комбинирования категориальных признаков              #\n",
    "    ###################################################################\n",
    "    def add_all_combinations(self, feature_names, degree, hash=hash):\n",
    "        self.get_all_combinations(feature_names, degree, hash=hash, store=True, copy=False)\n",
    "        \n",
    "    def get_all_combinations(self, feature_names, degree, hash=hash, store=True, copy=True):\n",
    "        method_msg = self._method_msg('get_all_combinations')\n",
    "        self._printers[self.METHOD](method_msg + '(names={}, degree={}, store={})'.format(feature_names, degree, store))\n",
    "        self._check_if_present(feature_names)\n",
    "        \n",
    "        features = {name: self._features[name] for name in feature_names}\n",
    "        combined_features = self._categorical_combiner.get_all_combinartions(features, degree=degree, hash=hash)\n",
    "        if store:\n",
    "            if degree > 1:\n",
    "                for name, combined_feature in combined_features:\n",
    "                    self.set_feature(combined_feature, copy=copy, replace=False)\n",
    "        return combined_features\n",
    "\n",
    "    def add_combined_feature(self, feature_names, hash=hash):\n",
    "        self.get_combined_feature(feature_names, hash=hash, store=True, copy=False)\n",
    "        \n",
    "    def get_combined_feature(self, feature_names, hash=hash, store=True, copy=True):\n",
    "        method_msg = self._method_msg('get_combined_feature')\n",
    "        self._printers[self.METHOD](method_msg + '(names={}, store={})'.format(feature_names, store))\n",
    "        self._check_if_present(*feature_names)\n",
    "        \n",
    "        features = [self._features[name] for name in feature_names]\n",
    "        combined_feature = CategoricalCombiner().get_combined_feature(features, hash=hash)\n",
    "        if store:\n",
    "            if len(feature_names) > 1:\n",
    "                self.set_feature(combined_feature, copy=copy, replace=False)\n",
    "        return combined_feature\n",
    "\n",
    "\n",
    "    ############################################################\n",
    "    ##       Сборка итогового признакового представления      ##\n",
    "    ############################################################\n",
    "    def assemble_data_frame(self, feature_names=None):\n",
    "        \"\"\"\n",
    "        Возвращает dense матрицу\n",
    "        \"\"\"\n",
    "        if feature_names is None:\n",
    "            feature_names = list(self._features.keys())\n",
    "        self._check_if_present(*feature_names)\n",
    "        feature_values = []\n",
    "        for feature_name in feature_names:\n",
    "            feature_values.append(self._features[feature_name].get_values(sparse=False))\n",
    "        return pd.DataFrame(np.hstack(feature_values), columns=feature_names)\n",
    "    \n",
    "    def assemble(self, feature_names, sparse=False):\n",
    "        \"\"\"\n",
    "        Аргументы:\n",
    "            :param feature_names\n",
    "            :param sparse\n",
    "        \"\"\"\n",
    "        self._check_if_present(feature_names)\n",
    "        X = []\n",
    "        feature_map = copy.deepcopy(feature_map)\n",
    "        for feature_name in feature_names:\n",
    "            feature = self._features[feature_name]\n",
    "            X.append(feature.get_values(sparse=sparse))\n",
    "        if sparse:\n",
    "            return scipy.sparse.hstack(X)\n",
    "        return np.hstack(X)\n",
    "\n",
    "    def filter_features(self, names=None, threshold=1):\n",
    "        if names is None:\n",
    "            names = list(self._features.keys())\n",
    "        for name in names:\n",
    "            self._features[name]._filter_feature(threshold)\n",
    "        self._update_dict()\n",
    "        \n",
    "    def _update_dict(self):\n",
    "        new_features = collections.OrderedDict()\n",
    "        for name in self._features:\n",
    "            feature = self._features[name]\n",
    "            new_name = feature.get_name()\n",
    "            new_features[new_name] = feature\n",
    "        self._features = new_features\n",
    "        \n",
    "    def add_filtered(self, name, threshold):\n",
    "        self.get_filtered(name, threshold, store=True, copy=False)\n",
    "    def get_filtered(self, name, threshold, store=True, copy=True):\n",
    "        self._check_if_present(name)\n",
    "        new_feature = self._features[name].get_filtered_feature(threshold)\n",
    "        if store:\n",
    "            self.set_feature(new_feature, copy=copy, replace=False)\n",
    "        return new_feature\n",
    "\n",
    "    def add_counter(self, name):\n",
    "        self.get_filtered(name, store=True, copy=False)\n",
    "    def get_counter(self, name, store=True, copy=True):\n",
    "        self._check_if_present(name)\n",
    "        new_feature = self._features[name].get_counter_feature(threshold)\n",
    "        if store:\n",
    "            self.set_feature(new_feature, copy=copy, replace=False)\n",
    "        return new_feature\n",
    "    def get_loo(self, name, y_train, cv, seed=1234):\n",
    "        self._check_if_present(name)\n",
    "        new_feature = self._features[name].get_loo_feature(y_train, cv=cv, seed=seed)\n",
    "        return new_feature\n",
    "        \n",
    "    \n",
    "\n",
    "test = True\n",
    "if test:      \n",
    "    manager = CategoricalFeaturesManager(verbose=0)\n",
    "    features = [CategoricalFeature(np.array([0, 1, 0, 1, 2, 0, 1, 2, 3, 0, 1, 2, 3, 4]), 'f1'),\n",
    "                CategoricalFeature(np.array([1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1]), 'f2'),\n",
    "                CategoricalFeature(np.array([0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1]), 'f3')]\n",
    "    for feature in features:\n",
    "        manager.set_feature(feature)\n",
    "        assert feature.shape == (14, )\n",
    "        assert len(feature) == 14\n",
    "    fnames = manager.get_list_of_features()\n",
    "    print('SET UP: {}\\n'.format(fnames))\n",
    "    \n",
    "    for fname in fnames:\n",
    "        print('\\t{} in manager = {}'.format(fname, fname in manager))\n",
    "    \n",
    "    print()\n",
    "    df = manager.assemble_data_frame(fnames)\n",
    "    print(df)\n",
    "    \n",
    "    print('\\nDELETING AND SETTING FEATURES:')\n",
    "    manager.del_feature('f1')\n",
    "    print('del f1:', manager.get_list_of_features()) \n",
    "    manager.del_feature('f2')\n",
    "    print('del f2:', manager.get_list_of_features())\n",
    "    manager.del_feature('f3')\n",
    "    print('del f3:', manager.get_list_of_features())\n",
    "\n",
    "    for feature in features:\n",
    "        manager.set_feature(feature)    \n",
    "        print('set {}:'.format(feature.get_name()), manager.get_list_of_features())\n",
    "    \n",
    "\n",
    "    print('\\nCOMBINING FEATURES:')\n",
    "    new_feature = manager.get_combined_feature(['f1'])\n",
    "    print(new_feature, new_feature.values.flatten())\n",
    "    new_feature = manager.get_combined_feature(['f2'])\n",
    "    print(new_feature, new_feature.values.flatten())\n",
    "    new_feature = manager.get_combined_feature(['f3'])\n",
    "    print(new_feature, new_feature.values.flatten())\n",
    "    new_feature = manager.get_combined_feature(['f1', 'f2'])\n",
    "    print(new_feature, new_feature.values.flatten())\n",
    "    new_feature = manager.get_combined_feature(['f1', 'f3'])\n",
    "    print(new_feature, new_feature.values.flatten())\n",
    "    new_feature = manager.get_combined_feature(['f2', 'f3'])\n",
    "    print(new_feature, new_feature.values.flatten())\n",
    "    new_feature = manager.get_combined_feature(['f1', 'f2', 'f3'])\n",
    "    print(new_feature, new_feature.values.flatten())\n",
    "    print('all:', manager.get_list_of_features())\n",
    "    \n",
    "    print('\\nFILTERED FEATURES:')\n",
    "    print('\\tbefore filtration')\n",
    "    print('feature names:', manager.get_list_of_features())\n",
    "    df = manager.assemble_data_frame()\n",
    "    print(df)\n",
    "    thr = 2\n",
    "    manager.filter_features(threshold=2)\n",
    "    #manager.add_filtered('f1', thr)\n",
    "    #manager.add_filtered('f2', thr)\n",
    "    #manager.add_filtered('f3', thr)\n",
    "    print('\\tafter filtration')\n",
    "    print('feature names:', manager.get_list_of_features())\n",
    "    df = manager.assemble_data_frame()\n",
    "    print(df)\n",
    "    \n",
    "    manager = CategoricalFeaturesManager(features)\n",
    "\n",
    "    \"\"\"print('\\nObtaining counters:')\n",
    "    for name in ['f1', 'f2', 'f3']:\n",
    "        FStest.add_counter(name)\n",
    "        feature = FStest.get_feature('CTR_' + name)\n",
    "        print(feature.name, feature.values)\n",
    "    print('all:', FStest.get_list_of_features())\n",
    "    print('cat:', FStest.get_list_of_features('CAT'))\n",
    "    print('num:', FStest.get_list_of_features('NUM'))\n",
    "    print('\\nAssembling features')\n",
    "    print(FStest.assemble(['f1', 'f2', 'f3', 'CTR_f3', 'f1+f2', 'f1+f3', 'f2+f3', 'f1+f2+f3', 'f4'], sparse=False))\n",
    "    print(FStest.assemble(['FA2_f1', 'f2', 'f3', 'f1+f2', 'f1+f3', 'f2+f3'], \n",
    "                          {'FA2_f1': ['def', 'ohe'],\n",
    "                           'f2': ['def', 'ohe'],\n",
    "                           'f3': ['def', 'ohe']},\n",
    "                          sparse=False))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Fil2_f1',\n",
       " 'Fil2_f2',\n",
       " 'Fil2_f3',\n",
       " 'Fil2_f1+f2',\n",
       " 'Fil2_f1+f3',\n",
       " 'Fil2_f2+f3',\n",
       " 'Fil2_f1+f2+f3']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(manager._features.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \"\"\"def add_categorized(self, name, bins, right=True):\n",
    "        self.check_if_present_(name)\n",
    "        self.check_type_(name, 'NUM')\n",
    "        new_feature = self.features[name].get_categorized_feature(bins, right)\n",
    "        self.features[new_feature.name] = new_feature\n",
    "        self.types[new_feature.name] = 'CAT'\n",
    "        return new_feature.name\"\"\"\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
