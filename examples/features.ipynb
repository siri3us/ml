{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='toc'></a>\n",
    "* [1. FeatureBase](#feature_base)\n",
    "    * [1.2 Tests](#fb_tests)\n",
    "* [2. NumericalFeature](#numerical_feature)\n",
    "* [3. AggregatedFeature](#aggregated_feature)\n",
    "* [4. CategoricalFeature](#categorical_feature)\n",
    "* [5. CategoricalCombiner](#categorical_combiner)\n",
    "* [6. FeaturesStorage](#features_storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.021s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "%run feature_base.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_PREFIXES = \\\n",
    "{'CAT': '',\n",
    " 'NUM': '',\n",
    " 'LE' : '',    # LabelEncoded feature\n",
    " 'OHE': 'Ohe', # OneHotEncoded feature\n",
    " 'CTR': 'Ctr', # Counter feature\n",
    " 'LOO': 'Loo', # LeaveOneOut feature\n",
    " 'FIL': 'Fil'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='feature_base'></a>\n",
    "## 1. FeatureBase<sup>[toc](#toc)</sup> <sup>[up](#toc)</sup> <sup>[down](#fb_tests)</sup>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E\n",
      "======================================================================\n",
      "ERROR: /run/user/1000/jupyter/kernel-9c4ca024-daee-4b4b-bb3e-43a3ab305ed1 (unittest.loader._FailedTest)\n",
      "----------------------------------------------------------------------\n",
      "AttributeError: module '__main__' has no attribute '/run/user/1000/jupyter/kernel-9c4ca024-daee-4b4b-bb3e-43a3ab305ed1'\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.001s\n",
      "\n",
      "FAILED (errors=1)\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "True",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexander/anaconda3/envs/tensorflow/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2889: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# %load feature_base.py\n",
    "import numpy as np\n",
    "import unittest\n",
    "import numbers\n",
    "import copy\n",
    "from scipy.sparse import csr_matrix, csc_matrix\n",
    "from collections import Counter\n",
    "from helpers import Checker, Printer\n",
    "      \n",
    "class FeatureKernel:\n",
    "    \"\"\"\n",
    "    FeatureKernel - класс, реализующий базовые операции, класса FeatureBase. \n",
    "    Данные операции включают в себя: \n",
    "        1) проверку корректности значений признака \n",
    "        2) вывод сообщений о некорректности значений\n",
    "        3) предобработку и постобработку признаков\n",
    "        4) получение характеристик признаков (размера, формата и т.п.)\n",
    "    \"\"\"\n",
    "    def __init__(self, owner):\n",
    "        self._owner = owner\n",
    "        self._printers = owner._printers\n",
    "        self._info_msg = owner._info_msg\n",
    "        self._error_msg = owner._error_msg\n",
    "        self._warning_msg = owner._warning_msg\n",
    "        self._method_msg = owner._method_msg\n",
    "        \n",
    "    def _is_numeric(self, values, name=None):\n",
    "        \"\"\"\n",
    "        Возвращает True, если тип признак числовой. Используется только в конструкторе NumericalFeature.\n",
    "        Аргументы:\n",
    "            :param values - значения признака (np.ndarray, csr_matrix, csc_matrix)\n",
    "            :param name   - имя признака (str)\n",
    "        \"\"\"\n",
    "        return isinstance(values.dtype.type(), numbers.Number)\n",
    "    \n",
    "    def _check_numeric(self, values, name=None, throw=True):\n",
    "        \"\"\"\n",
    "        Возвращает True, если тип признак числовой. Иначе возвращает False или вызывает исключение\n",
    "        (в зависимости от параметра throw) .\n",
    "        Аргументы:\n",
    "            :param values - значения признака (np.ndarray, csr_matrix, csc_matrix)\n",
    "            :param name   - имя признака (str)\n",
    "            :param throw  - если True, то вызывает исключение, если признак не числовой (bool)\n",
    "        \"\"\"\n",
    "        if not self._is_numeric(values):\n",
    "            if throw:\n",
    "                error_msg = 'Feature values are not numerical! Their type is {}'.format(values.dtype)\n",
    "                raise TypeError(self._error_msg(error_msg))\n",
    "            return False\n",
    "        return True\n",
    "    \n",
    "    def _is_constant(self, values, name=None):\n",
    "        \"\"\"\n",
    "        Проверяет значения признака на константность. \n",
    "        Аргументы:\n",
    "            :param values - значения признака в виде np.ndarray\n",
    "            :param name   - имя признака (str)\n",
    "        \"\"\"\n",
    "        assert isinstance(values, np.ndarray)\n",
    "        counter = Counter()\n",
    "        for v in values:\n",
    "            counter[v] += 1\n",
    "            if len(counter) != 1:\n",
    "                return False  \n",
    "        return True\n",
    "    \n",
    "    def _check_constant(self, values, name=None, throw=True):\n",
    "        \"\"\"\n",
    "        Возвращает True, если значения признака идентичны для всех объетов. Иначе возращает False или \n",
    "        вызывает исключение (в зависимости от параметра throw)\n",
    "        Аргументы:\n",
    "            :param values - значения признака (np.ndarray, csr_matrix, csc_matrix)\n",
    "            :param name   - имя признака (str)\n",
    "            :param throw  - если True, то вызывает исключение, если признак не константный (bool)\n",
    "        \"\"\"\n",
    "        if self._is_constant(values):\n",
    "            if throw:\n",
    "                raise ValueError(self._error_msg(\"Given feature {} is constant\".format(name)))\n",
    "            return False\n",
    "        return True\n",
    "    \n",
    "    def _is_shaped(self, values, name=None):\n",
    "        self._undefined_method('_is_shapd')\n",
    "    def _check_shaped(self, values, name=None, throw=True):\n",
    "        self._undefined_method('_check_shaped')\n",
    "    \n",
    "    def _get_length(self):\n",
    "        self._undefined_method('_get_length')\n",
    "    def _get_values(self):\n",
    "        self._undefined_method('_get_values')\n",
    "    def _get_dense(self):\n",
    "        self._undefined_method('_get_dense')\n",
    "    def _get_sparse(self):\n",
    "        self._undefined_method('_get_sparse')\n",
    "        \n",
    "    def _preprocess(self, values, name):\n",
    "        self._undefined_method('_preprocess')\n",
    "        \n",
    "    def _undefined_method(self, method_name):\n",
    "        error_msg = 'Method \"{}\" of the abstract class \"{}\"'\\\n",
    "            'must be redefined in derivative classes.'.format(method_name, type(self).__name__)\n",
    "        assert False, error_msg\n",
    "\n",
    "class SparseFeatureKernel(FeatureKernel):\n",
    "    def __init__(self, owner):\n",
    "        super().__init__(owner)\n",
    "\n",
    "    ########################################################################\n",
    "    def _is_shaped(self, values, name=None):\n",
    "        return (len(values.shape) == 2) & (values.shape[0] == 1) & (values.shape[1] > 1)\n",
    "    def _check_shaped(self, values, name=None, throw=True):\n",
    "        if not self._is_shaped(values, name):\n",
    "            if throw:\n",
    "                error_msg = \"Given sparse feature vector must have shape of type (1, size), but has {}\".format(\n",
    "                    values.shape)\n",
    "                raise ValueError(self._error_msg(error_msg))\n",
    "            return False\n",
    "        return True\n",
    "    \n",
    "    ################\n",
    "    def _is_constant(self, values, name=None):\n",
    "        values = values.toarray().flatten()\n",
    "        return super()._is_constant(values, name)\n",
    "    \n",
    "    ########################################################################\n",
    "    def _preprocess(self, values, name):\n",
    "        self._printers[self._owner.METHODS](self._method_msg('_preprocess'))\n",
    "        assert isinstance(values, (csr_matrix, csc_matrix))\n",
    "        init_shape = values.shape\n",
    "        if len(init_shape) != 2:\n",
    "            error_msg = \"Feature \\\"{}\\\" has shape {} but must have a shape of length 2.\".format(\n",
    "                name, init_shape)\n",
    "            raise ValueError(self._error_msg(error_msg))\n",
    "        if (init_shape[0] == 1) & (init_shape[1] > 1):\n",
    "            new_values = values.tocsr() \n",
    "        elif (init_shape[0] > 1) & (init_shape[1] == 1):\n",
    "            new_values = values.transpose().tocsr()\n",
    "        else:\n",
    "            error_msg = \"Feature \\\"{}\\\" has incorrect shape {}. Must be either (1, n) or (n, 1)\".format(\n",
    "                name, shape, tuple(reversed(shape)))\n",
    "            raise ValueError(self._error_msg(error_msg))\n",
    "        info_msg = \"Feature \\\"{}\\\" is transformed from shape {} to csr_matrix of shape {}\".format(\n",
    "            name, init_shape, new_values.shape)\n",
    "        self._printers[self._owner.FORMAT_CHANGE_LEVEL](self._info_msg(info_msg))\n",
    "        info_msg = '_preprocess returns {}'.format(type(new_values))\n",
    "        self._printers[self._owner.METHODS](self._info_msg(info_msg))\n",
    "        return new_values\n",
    "    \n",
    "    ########################################################################\n",
    "    def _get_length(self):\n",
    "        return self._owner._values.shape[1]\n",
    "    def _get_values(self, sparse=True, *args, **kwargs):\n",
    "        if sparse:\n",
    "            return self._owner._values.transpose().tocsc()\n",
    "        else:\n",
    "            return self._owner._values.todense().T\n",
    "    def _get_dense(self):\n",
    "        values = self._owner._values\n",
    "        name = self._owner._name\n",
    "        verbose = self._owner._verbose\n",
    "        return DenseFeatureBase(values.toarray().flatten(), name, verbose)\n",
    "    def _get_sparse(self):\n",
    "        values = self._owner._values\n",
    "        name = self._owner._name\n",
    "        verbose = self._owner._verbose\n",
    "        return SparseFeatureBase(values, name, verbose)\n",
    "\n",
    "\n",
    "class DenseFeatureKernel(FeatureKernel):\n",
    "    def __init__(self, owner):\n",
    "        super().__init__(owner)\n",
    "        \n",
    "    ########################################################################\n",
    "    def _is_shaped(self, values, name=None):\n",
    "        return len(values.shape) == 1\n",
    "    def _check_shaped(self, values, name=None, throw=True):\n",
    "        if not self._is_shaped(values, name):\n",
    "            if throw:\n",
    "                raise ValueError(self._error_msg(\"Given dense feature vector must have shape of type (size, ), but has {}\".format(values.shape)))\n",
    "            return False\n",
    "        return True\n",
    "    \n",
    "    ########################################################################\n",
    "    def _preprocess(self, values, name):\n",
    "        self._printers[self._owner.METHODS](type(self).__name__ + '._preprocess')\n",
    "        assert isinstance(values, (np.ndarray, list))\n",
    "        values = np.array(values)\n",
    "        init_shape = values.shape\n",
    "        if len(init_shape) not in [1, 2]:\n",
    "            error_msg = \"Feature \\\"{}\\\" has shape {} but must have a shape of length either 1 or 2.\".format(\n",
    "                name, init_shape)\n",
    "            raise ValueError(self._error_msg(error_msg))\n",
    "        if len(init_shape) == 1:\n",
    "            new_values = values\n",
    "        elif (init_shape[0] == 1) & (init_shape[1] > 1):\n",
    "            new_values = values[0]\n",
    "        elif (init_shape[0] > 1) & (init_shape[1] == 1):\n",
    "            new_values = values[:, 0]\n",
    "        else:\n",
    "            error_msg = \"Feature \\\"{}\\\" has incorrect shape {}. Must be either (n, ) or (1, n) or (n, 1)\".format(\n",
    "                name, shape, tuple(reversed(shape)))\n",
    "            raise ValueError(self._error_msg(error_msg))\n",
    "        info_msg = \"Feature \\\"{}\\\" is transformed from shape {} to shape {}\".format(\n",
    "            name, init_shape, new_values.shape)\n",
    "        self._printers[self._owner.FORMAT_CHANGE_LEVEL](self._info_msg(info_msg))\n",
    "        return new_values\n",
    "    \n",
    "    ########################################################################\n",
    "    def _get_length(self):\n",
    "        return self._owner._values.shape[0]\n",
    "    def _get_values(self, sparse=False, *args, **kwargs):\n",
    "        if sparse:\n",
    "            return csc_matrix(self._owner._values[:, np.newaxis])\n",
    "        else:\n",
    "            return self._owner._values[:, np.newaxis]\n",
    "    def _get_dense(self):\n",
    "        values = self._owner._values\n",
    "        name = self._owner._name\n",
    "        verbose = self._owner._verbose\n",
    "        return DenseFeatureBase(values, name, verbose)\n",
    "    def _get_sparse(self):\n",
    "        values = csr_matrix(self._owner._values[np.newaxis, :])\n",
    "        values.eliminate_zeros()\n",
    "        name = self._owner._name\n",
    "        verbose = self._owner._verbose\n",
    "        return SparseFeatureBase(values, name, verbose)\n",
    "    \n",
    "    \n",
    "class FeatureBase(Checker):\n",
    "    \"\"\"\n",
    "    FeatureBase - базовый класс, контейнер для одного признака. \n",
    "    Признак хранится в виде либо разряженном, либо в плотном формате.\n",
    "    Признак обладает своим именем. При проведении преобразований признака, его имя преобразуется.\n",
    "    \n",
    "    Уровни печати (значение verbose):\n",
    "    * FORMAT_CHANGE_LEVEL - уровень, выше которого выводятся в печать сообщения о преобразованиях формата признака при инициализации\n",
    "    \"\"\"\n",
    "\n",
    "    FORMAT_CHANGE_LEVEL = 10\n",
    "    METHODS = 11\n",
    "    \n",
    "    def is_constant(self):\n",
    "        \"\"\"\n",
    "        Возвращает True, если значения признака идентичны для всех объетов. Иначе - False.\n",
    "        \"\"\"\n",
    "        return self._kernel._is_constant(self._values, self._name)\n",
    "\n",
    "    def is_numeric(self):\n",
    "        \"\"\"\n",
    "        Возвращает True, если признак числовой. Иначе - False.\n",
    "        \"\"\"\n",
    "        return self._kernel._is_numeric(self._values, self._name)\n",
    "    \n",
    "    ########################################################################\n",
    "    def __init__(self, values, name, verbose=0):\n",
    "        attributes = ['name', 'values', 'shape']\n",
    "        setters = {}; getters = {}\n",
    "        for attr in attributes:\n",
    "            setters[attr] = self.__getattribute__('set_' + attr)\n",
    "            getters[attr] = self.__getattribute__('get_' + attr)\n",
    "        super().__setattr__('_setters', setters)\n",
    "        super().__setattr__('_getters', getters)\n",
    "        super().__init__()\n",
    "        self._verbose = verbose\n",
    "        if isinstance(values, (csr_matrix, csc_matrix)):\n",
    "            self._sparse = True\n",
    "            self._kernel = SparseFeatureKernel(self)\n",
    "        elif isinstance(values, (np.ndarray, list)):\n",
    "            self._sparse = False\n",
    "            self._kernel = DenseFeatureKernel(self)\n",
    "        else:\n",
    "            raise TypeError('Type of \"values\" is unacceptable!')\n",
    "        self.set_name(name)\n",
    "        self.set_values(values)\n",
    "\n",
    "    def __str__(self):\n",
    "        return '[{}: {}, {}]'.format(type(self).__name__, self._name, self._shape)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return str(self)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self._kernel._get_length()\n",
    "        \n",
    "    ########################################################################\n",
    "    def __getattr__(self, name):\n",
    "        if name in self._getters:\n",
    "            return self._getters[name]()\n",
    "        raise AttributeError('Attribute \"{}\" not found!'.format(name))\n",
    "    def __setattr__(self, name, value):\n",
    "        if name in self._setters:\n",
    "            return self._setters[name](value)\n",
    "        return super().__setattr__(name, value)\n",
    "    \n",
    "    def set_name(self, name):\n",
    "        self._check_type(name, 'feature_name', str)\n",
    "        self._name = name\n",
    "    def set_values(self, values):\n",
    "        \"\"\"\n",
    "        Всегда сохраняется копия values.\n",
    "        \"\"\"\n",
    "        self._printers[self.METHODS](self._method_msg('set_values({})'.format(type(values))))\n",
    "        _values = self._kernel._preprocess(values, self._name)\n",
    "        self._kernel._check_shaped(_values, self._name, throw=True)\n",
    "        self._values = _values\n",
    "        self._shape  = _values.shape\n",
    "        self._printers[self.METHODS](self._info_msg('set_values setted {}'.format(type(self._values))))\n",
    "    def set_shape(self, shape):\n",
    "        assert False, 'Setting \"shape\" is not allowed'\n",
    "    def get_name(self):\n",
    "        return self._name\n",
    "    def get_values(self, *args, **kwargs):\n",
    "        return self._kernel._get_values(*args, **kwargs)\n",
    "    def get_shape(self):\n",
    "        return self._shape\n",
    "    \n",
    "    ########################################################################\n",
    "    def _get_categorical_name(self, name):\n",
    "        return FEATURE_PREFIXES['CAT'] + name\n",
    "    def _get_numerical_name(self, name):\n",
    "        return FEATURE_PREFIXES['NUM'] + name\n",
    "    def _get_counter_name(self, name):\n",
    "        return FEATURE_PREFIXES['CTR'] + name\n",
    "    def _get_loo_name(self, name):\n",
    "        return FEATURE_PREFIXES['LOO'] + name\n",
    "    def _get_filtered_name(self, name, threshold):\n",
    "        return FEATURE_PREFIXES['FIL'] + '{}_'.format(threshold) + name\n",
    "    def _get_label_encoded_name(self, name):\n",
    "        return FEATURE_PREFIXES['LE'] + name\n",
    "    def _get_ohe_name(self, name):\n",
    "        return FEATURE_PREFIXES['OHE'] + name\n",
    "\n",
    "    ########################################################################\n",
    "    def to_dense(self):\n",
    "        if self._sparse:\n",
    "            self._values = self._kernel._get_dense()._values\n",
    "            self._kernel = DenseFeatureKernel(self)\n",
    "        assert isinstance(self._values, np.ndarray)\n",
    "        assert isinstance(self._kernel, DenseFeatureKernel)\n",
    "    def to_sparse(self):\n",
    "        if not self._sparse:\n",
    "            self._values = self._kernel._get_sparse()._values\n",
    "            self._kernel = SparseFeatureKernel(self)\n",
    "        assert isinstance(self._values, csr_matrix)\n",
    "        assert isinstance(self._kernel, SparseFeatureKernel)\n",
    "    ########################################################################\n",
    "    def deepcopy(self):\n",
    "        \"\"\"\n",
    "        Функция глубокого копирования объекта. При необходимости копирования должна вызываться ТОЛЬКО она.\n",
    "        Функция copy.deepcopy выполняет некорректное копирование из-за переопределения операции работы с атрибутами\n",
    "        в классе FeatureBase/\n",
    "        \"\"\"\n",
    "        return FeatureBase(copy.deepcopy(self._values), self._name, self._verbose)    \n",
    "    \n",
    "        \n",
    "class TestFeatureBase(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        self.values1 = [0, 1, 0, 0, 0, 1, 1.1, 1, 0, 4, 1, 7, 0, 0, 0]\n",
    "        \n",
    "    def test_init(self):\n",
    "        self.dense_values = np.array(self.values1)     # (L, )\n",
    "        \n",
    "        self.sparse_values1 = csc_matrix(self.values1) # (1, L)\n",
    "        self.sparse_values1.eliminate_zeros()          # (1, L)\n",
    "        \n",
    "        self.sparse_values2 = csc_matrix(np.array(self.values1)[:, np.newaxis]) # (L, 1)\n",
    "        self.sparse_values2.eliminate_zeros()          # (L, 1)\n",
    "        \n",
    "        self.sparse_values3 = csr_matrix(self.values1) # (1, L)\n",
    "        self.sparse_values3.eliminate_zeros()          # (1, L)\n",
    "        \n",
    "        self.sparse_values4 = csr_matrix(np.array(self.values1)[:, np.newaxis]) # (1, L)\n",
    "        self.sparse_values4.eliminate_zeros()          # (1, L)\n",
    "        \n",
    "        feature  = FeatureBase(self.dense_values, name='f')\n",
    "        feature1 = FeatureBase(self.sparse_values1, name='f1')\n",
    "        feature2 = FeatureBase(self.sparse_values2, name='f2')\n",
    "        feature3 = FeatureBase(self.sparse_values3, name='f3')\n",
    "        feature4 = FeatureBase(self.sparse_values4, name='f4')\n",
    "        \n",
    "        self.assertTrue(feature.shape == (15,))\n",
    "        self.assertTrue(feature1.shape == (1, 15))\n",
    "        self.assertTrue(feature2.shape == (1, 15))\n",
    "        self.assertTrue(feature3.shape == (1, 15))\n",
    "        self.assertTrue(feature4.shape == (1, 15))\n",
    "        \n",
    "        self.assertTrue(isinstance(feature._values, np.ndarray))\n",
    "        self.assertTrue(isinstance(feature1._values, csr_matrix))\n",
    "        self.assertTrue(isinstance(feature2._values, csr_matrix))\n",
    "        self.assertTrue(isinstance(feature3._values, csr_matrix))\n",
    "        self.assertTrue(isinstance(feature4._values, csr_matrix))\n",
    "        \n",
    "        self.assertTrue(isinstance(feature.values, np.ndarray))\n",
    "        self.assertTrue(isinstance(feature1.values, csc_matrix))\n",
    "        self.assertTrue(isinstance(feature2.values, csc_matrix))\n",
    "        self.assertTrue(isinstance(feature3.values, csc_matrix))\n",
    "        self.assertTrue(isinstance(feature4.values, csc_matrix))\n",
    "        \n",
    "        self.assertEqual(feature.name, 'f')\n",
    "        self.assertEqual(feature1.name, 'f1')\n",
    "        self.assertEqual(feature2.name, 'f2')\n",
    "        self.assertEqual(feature3.name, 'f3')\n",
    "        self.assertEqual(feature4.name, 'f4')\n",
    "        \n",
    "        \n",
    "        self.assertEqual(len(feature), 15)\n",
    "        self.assertEqual(len(feature1), 15)\n",
    "        self.assertEqual(len(feature2), 15)\n",
    "        self.assertEqual(len(feature3), 15)\n",
    "        self.assertEqual(len(feature4), 15)\n",
    "\n",
    "    def test_get_values(self):\n",
    "        self.dense_values = np.array(self.values1)\n",
    "        self.sparse_values1 = csc_matrix(self.values1)\n",
    "        self.sparse_values1.eliminate_zeros()\n",
    "        self.sparse_values2 = csc_matrix(np.array(self.values1)[:, np.newaxis])\n",
    "        self.sparse_values2.eliminate_zeros()\n",
    "        self.sparse_values3 = csr_matrix(self.values1)\n",
    "        self.sparse_values3.eliminate_zeros()\n",
    "        self.sparse_values4 = csr_matrix(np.array(self.values1)[:, np.newaxis])\n",
    "        self.sparse_values4.eliminate_zeros()\n",
    "        \n",
    "        feature = FeatureBase(self.dense_values, name='f')\n",
    "        feature1 = FeatureBase(self.sparse_values1, name='f1')\n",
    "        feature2 = FeatureBase(self.sparse_values2, name='f2')\n",
    "        feature3 = FeatureBase(self.sparse_values3, name='f3')\n",
    "        feature4 = FeatureBase(self.sparse_values4, name='f4')\n",
    "        \n",
    "        features = [feature, feature1, feature2, feature3, feature4]\n",
    "        for sparse in [False, True]:\n",
    "            for feature in features:\n",
    "                returned_values = feature.get_values(sparse=sparse)\n",
    "                if sparse:\n",
    "                    self.assertTrue(isinstance(returned_values, csc_matrix))\n",
    "                    self.assertTrue((returned_values.shape[0] > 1) & (returned_values.shape[1] == 1))\n",
    "                    returned_values = returned_values.toarray()\n",
    "                self.assertTrue(np.allclose(self.dense_values[:, np.newaxis], returned_values))\n",
    "                \n",
    "    def test_check_shaped(self):\n",
    "        with self.assertRaises(ValueError):\n",
    "            feature = FeatureBase(np.array(self.values1)[:, np.newaxis, np.newaxis], name='f', verbose=1)\n",
    "      \n",
    "    def test_check_constant(self):\n",
    "        values = np.array([1, 1, 1, 1, 1, 1])\n",
    "        with self.assertRaises(ValueError):\n",
    "            feature = FeatureBase(values, name='feature')\n",
    "            feature._kernel._check_constant(feature._values)\n",
    "             \n",
    "        values = csc_matrix(np.array([2, 2, 2, 2, 2, 2])) \n",
    "        with self.assertRaises(ValueError):\n",
    "            feature = FeatureBase(values, name='feature')\n",
    "            feature._kernel._check_constant(feature._values)      \n",
    "        \n",
    "\n",
    "    def test_check_numeric(self):\n",
    "        f_values = np.array([1, 'sd', 34, True, -1])\n",
    "        with self.assertRaises(TypeError):\n",
    "            feature_base = FeatureBase(f_values, name='feature')\n",
    "            feature_base._check_numeric(feature_base._values)\n",
    "            \n",
    "if __name__ == '__main__':\n",
    "    unittest.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='fb_tests'></a>\n",
    "### 1.2 Tests<sup>[toc](#toc)</sup>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPARSE = True\n",
      "str(feature) = [FeatureBase: f, (1, 15)]\n",
      "feature.values.shape = (15, 1)\n",
      "feature.values =   (1, 0)\t1.0\n",
      "  (5, 0)\t1.0\n",
      "  (6, 0)\t1.1\n",
      "  (7, 0)\t1.0\n",
      "  (9, 0)\t4.0\n",
      "  (10, 0)\t1.0\n",
      "  (11, 0)\t7.0\n",
      "feature._values.shape = (1, 15)\n",
      "feature._values =   (0, 1)\t1.0\n",
      "  (0, 5)\t1.0\n",
      "  (0, 6)\t1.1\n",
      "  (0, 7)\t1.0\n",
      "  (0, 9)\t4.0\n",
      "  (0, 10)\t1.0\n",
      "  (0, 11)\t7.0\n",
      "[Dense ]: [[ 0.   1.   0.   0.   0.   1.   1.1  1.   0.   4.   1.   7.   0.   0.   0. ]]\n",
      "[Sparse]:   (1, 0)\t1.0\n",
      "  (5, 0)\t1.0\n",
      "  (6, 0)\t1.1\n",
      "  (7, 0)\t1.0\n",
      "  (9, 0)\t4.0\n",
      "  (10, 0)\t1.0\n",
      "  (11, 0)\t7.0\n",
      "feature.shape = (1, 15), feature.name = f\n",
      "is_numeric =  True\n",
      "\n",
      "\n",
      "\n",
      "SPARSE = False\n",
      "str(feature) = [FeatureBase: f, (15,)]\n",
      "feature.values.shape = (15, 1)\n",
      "feature.values = [ 0.   1.   0.   0.   0.   1.   1.1  1.   0.   4.   1.   7.   0.   0.   0. ]\n",
      "feature._values.shape = (15,)\n",
      "feature._values = [ 0.   1.   0.   0.   0.   1.   1.1  1.   0.   4.   1.   7.   0.   0.   0. ]\n",
      "[Dense ]: [ 0.   1.   0.   0.   0.   1.   1.1  1.   0.   4.   1.   7.   0.   0.   0. ]\n",
      "[Sparse]:   (1, 0)\t1.0\n",
      "  (5, 0)\t1.0\n",
      "  (6, 0)\t1.1\n",
      "  (7, 0)\t1.0\n",
      "  (9, 0)\t4.0\n",
      "  (10, 0)\t1.0\n",
      "  (11, 0)\t7.0\n",
      "feature.shape = (15,), feature.name = f\n",
      "is_numeric =  True\n"
     ]
    }
   ],
   "source": [
    "for sparse in [True, False]:\n",
    "    values = [0, 1, 0, 0, 0, 1, 1.1, 1, 0, 4, 1, 7, 0, 0, 0]\n",
    "    values = np.array(values)\n",
    "    if sparse:\n",
    "        values = csc_matrix(values)\n",
    "        values.eliminate_zeros()\n",
    "    name = 'f'\n",
    "    feature = FeatureBase(values, name)\n",
    "\n",
    "    fvalues = feature.values\n",
    "    _fvalues = feature._values\n",
    "    if sparse:\n",
    "        print('SPARSE =', sparse)\n",
    "        print('str(feature) =', feature)\n",
    "        print('feature.values.shape = {}\\nfeature.values = {}'.format(fvalues.shape, fvalues.tocsr()))\n",
    "        print('feature._values.shape = {}\\nfeature._values = {}'.format(_fvalues.shape, _fvalues.tocsr()))\n",
    "        print('[Dense ]:', feature.get_values(sparse=False).flatten())\n",
    "        print('[Sparse]:', feature.get_values(sparse=True).tocsr())\n",
    "    else:\n",
    "        print('\\n\\n\\nSPARSE =', sparse)\n",
    "        print('str(feature) =', feature)\n",
    "        print('feature.values.shape = {}\\nfeature.values = {}'.format(fvalues.shape, fvalues.flatten()))\n",
    "        print('feature._values.shape = {}\\nfeature._values = {}'.format(_fvalues.shape, _fvalues.flatten()))\n",
    "        print('[Dense ]:', feature.get_values(sparse=False).flatten())\n",
    "        print('[Sparse]:', feature.get_values(sparse=True).tocsr())\n",
    "    print('feature.shape = {}, feature.name = {}'.format(feature.shape, feature.name))\n",
    "    print('is_numeric = ', feature.is_numeric())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='numerical_feature'></a>\n",
    "## 2. NumericalFeature<sup>[toc](#toc)</sup>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E\n",
      "======================================================================\n",
      "ERROR: /run/user/1000/jupyter/kernel-9c4ca024-daee-4b4b-bb3e-43a3ab305ed1 (unittest.loader._FailedTest)\n",
      "----------------------------------------------------------------------\n",
      "AttributeError: module '__main__' has no attribute '/run/user/1000/jupyter/kernel-9c4ca024-daee-4b4b-bb3e-43a3ab305ed1'\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.001s\n",
      "\n",
      "FAILED (errors=1)\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "True",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexander/anaconda3/envs/tensorflow/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2889: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# %load numerical_feature.py\n",
    "# from feature_base import *\n",
    "import numpy as np\n",
    "import unittest\n",
    "import copy\n",
    "import numbers\n",
    "from scipy.sparse import csc_matrix, csr_matrix\n",
    "\n",
    "class NumericalFeature(FeatureBase):\n",
    "    def __init__(self, values, name, verbose=0):\n",
    "        super().__init__(values, name, verbose)\n",
    "        self._name = self._get_numerical_name(name)\n",
    "        self._kernel._check_numeric(self._values, self._name, True)\n",
    "\n",
    "    def get_categorical_feature(self, bins, right=True, include_lowest=False):\n",
    "        \"\"\"\n",
    "        Создает категориальный признак из числового.\n",
    "        TODO include_lowest\n",
    "        Аргументы:\n",
    "            :param bins - \n",
    "            :param right -  \n",
    "            :param include_lowest - на данный момент не используется\n",
    "        \"\"\"\n",
    "        if self._sparse:\n",
    "            values = self._values.toarray().flatten()\n",
    "        else:\n",
    "            values = self._values\n",
    "        cat_values = np.array(pd.cut(values, bins, right=right))\n",
    "        cat_name = self._get_categorical_name(self._name)\n",
    "        return CategorialFeature(cat_values, cat_name)\n",
    "\n",
    "\n",
    "class TestNumericalFeature(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        self.dense_values1 = [0, 4, 5.5, 9, 3.7, 0, 1, 0, 0, 0, 0]\n",
    "        self.df1 = NumericalFeature(self.dense_values1, name='df1')\n",
    "        self.sparse_values1 = csc_matrix(self.dense_values1)\n",
    "        self.sparse_values1.eliminate_zeros()\n",
    "        self.sf1 = NumericalFeature(self.sparse_values1, name='sf1')\n",
    "        \n",
    "        self.dense_values2 = np.array([1, 2, 3, 4, 5, 6, 7]).reshape((-1, 1))\n",
    "        self.df2 = NumericalFeature(self.dense_values2, name='df2')\n",
    "        self.sparse_values2 = csc_matrix(self.dense_values2)\n",
    "        self.sparse_values2.eliminate_zeros()\n",
    "        self.sf2 = NumericalFeature(self.sparse_values2, name='sf2')\n",
    "\n",
    "    def test_init_shape(self):\n",
    "        self.assertTrue(self.df1.shape == (len(self.dense_values1),))\n",
    "        self.assertTrue(self.df2.shape == (self.dense_values2.shape[0],))\n",
    "        self.assertTrue(self.sf1.shape == (1, len(self.dense_values1)))\n",
    "        self.assertTrue(self.sf2.shape == (1, self.dense_values2.shape[0]))\n",
    "        \n",
    "    def test_init_array(self):\n",
    "        self.assertTrue(isinstance(self.df1._values, np.ndarray))\n",
    "        self.assertTrue(isinstance(self.df2._values, np.ndarray))\n",
    "        self.assertTrue(isinstance(self.sf1._values, csr_matrix))\n",
    "        self.assertTrue(isinstance(self.sf2._values, csr_matrix))\n",
    "      \n",
    "    def test_init_shape_error(self):\n",
    "        with self.assertRaises(ValueError):\n",
    "            feature = NumericalFeature(np.array(self.dense_values1)[:, None, None], name='f2')\n",
    "            \n",
    "    def test_init_numeric_error(self):\n",
    "        feature = NumericalFeature(np.array([1, 2, 3, 4, 5, 6, 7, 8, 9]), name='feature2')\n",
    "        feature = NumericalFeature(np.array([1.4, 8.2, 82.2]), name='feature3')\n",
    "        with self.assertRaises(TypeError):\n",
    "            feature = NumericalFeature(np.array(list('jskdfjdskfjsd')), name='feature4')\n",
    "            \n",
    "    def test_categorical(self): # TODO\n",
    "        values = [0.3, 0.5, 0.8, 0.2, 0.6, 0.1]\n",
    "        name = 'feature2'\n",
    "        feature = NumericalFeature(values, name)\n",
    "        # bins = \n",
    "        #cat_feature = \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    unittest.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='aggregated_feature'></a>\n",
    "## 3. AggregatedFeature<sup>[toc](#toc)</sup> <sup>[down](#categorical_feature)</sup>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AggregatedFeature[[FeatureBase: F0, (10,)][FeatureBase: F1, (10,)][FeatureBase: F2, (10,)][FeatureBase: F3, (10,)][FeatureBase: F4, (10,)]]\n",
      "  (0, 0)\t1\n",
      "  (1, 0)\t1\n",
      "  (3, 0)\t1\n",
      "  (5, 0)\t1\n",
      "  (6, 0)\t1\n",
      "  (8, 0)\t1\n",
      "  (9, 0)\t1\n",
      "  (0, 1)\t1\n",
      "  (1, 1)\t1\n",
      "  (2, 1)\t1\n",
      "  (3, 1)\t1\n",
      "  (4, 1)\t1\n",
      "  (8, 1)\t1\n",
      "  (2, 2)\t1\n",
      "  (3, 2)\t1\n",
      "  (8, 2)\t1\n",
      "  (5, 3)\t1\n",
      "  (7, 3)\t1\n",
      "  (8, 3)\t1\n",
      "  (9, 3)\t1\n",
      "  (2, 4)\t1\n",
      "  (3, 4)\t1\n",
      "  (6, 4)\t1\n",
      "  (7, 4)\t1\n",
      "  (8, 4)\t1\n",
      "[[1 1 0 0 0]\n",
      " [1 1 0 0 0]\n",
      " [0 1 1 0 1]\n",
      " [1 1 1 0 1]\n",
      " [0 1 0 0 0]\n",
      " [1 0 0 1 0]\n",
      " [1 0 0 0 1]\n",
      " [0 0 0 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 0 0 1 0]]\n",
      "  (0, 0)\t1\n",
      "  (1, 0)\t1\n",
      "  (2, 0)\t1\n",
      "  (3, 0)\t1\n",
      "  (4, 0)\t1\n",
      "  (8, 0)\t1\n",
      "  (2, 1)\t1\n",
      "  (3, 1)\t1\n",
      "  (8, 1)\t1\n",
      "  (5, 2)\t1\n",
      "  (7, 2)\t1\n",
      "  (8, 2)\t1\n",
      "  (9, 2)\t1\n",
      "[[1 0 0]\n",
      " [1 0 0]\n",
      " [1 1 0]\n",
      " [1 1 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 0 0]\n",
      " [0 0 1]\n",
      " [1 1 1]\n",
      " [0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "class AggregatedFeature(Checker):\n",
    "    DELETE_FEATURE = 4\n",
    "    \"\"\"\n",
    "    Позволяет хранить значения нескольких признаков, например, OHE представления категориальных признаков.\n",
    "    \"\"\"\n",
    "    def __init__(self, features, name, copy=True, verbose=0):\n",
    "        \"\"\"\n",
    "        Аргументы:\n",
    "            :param features - список объектов FeatureBase\n",
    "            :param name     - имя агрегированного признака\n",
    "            :param exclude_const - исключить константные признаки из множества?\n",
    "            :param copy     - если True, то каждый каждый признак будет скопирован\n",
    "            :param verbose  - уровень печати (nonnegative int)\n",
    "        \"\"\"\n",
    "        \n",
    "        self.set_features(features, name)\n",
    "        self._verbose = verbose\n",
    "        \n",
    "    def set_features(self, features, name, copy=True):\n",
    "        self._check_features(features, name)\n",
    "        self._name = name\n",
    "        self._feature_names = [feature._name for feature in features]\n",
    "        if copy:\n",
    "            self._features = {feature._name: feature.deepcopy() for feature in features}\n",
    "        else:\n",
    "            self._features = {feature._name: feature for feature in features}\n",
    "        \n",
    "    def _check_features(self, features, name):\n",
    "        if not isinstance(features, (np.ndarray, list)):\n",
    "            raise TypeError('Wrong format of \"features\" with name \"{}\" for \"{}\".'.format(name, type(self).__name__))\n",
    "        if not all([isinstance(feature, FeatureBase) for feature in features]):\n",
    "            raise TypeError('One of subfeatures of feature \"{}\" is not an object of FeatureBase.'.format(name))\n",
    "        lengths = [len(feature) for feature in features]\n",
    "        if min(lengths) != max(lengths):\n",
    "            raise ValueError('Provided features with name \"{}\" have different lengths'.format(name))\n",
    "        if min(lengths) == 0:\n",
    "            raise ValueError('Features with name \"{}\" have zero length. Must have positive length.'.format(name))\n",
    "\n",
    "    def exclude_constant(self):\n",
    "        \"\"\"\n",
    "        Исключает константные подпризнаки из рассмотрения.\n",
    "        \"\"\"\n",
    "        to_delete = []\n",
    "        for feature_name in self._features:\n",
    "            if self._features[feature_name].is_constant():\n",
    "                to_delete.append(feature_name)\n",
    "        for feature_name in to_delete:\n",
    "            self._printers[self.DELETE_FEATURE]('Deleting constant feature \"{}\"'.format(feature_name))\n",
    "            del self._features[feature_name]\n",
    "        self._feature_names = [feature_name for feature_name in self._feature_names \n",
    "                               if feature_name in self._features]\n",
    "\n",
    "    def is_constant(self):\n",
    "        if len(self._features) == 0: # In case if all feature are excluded due to constant values\n",
    "            return True\n",
    "        return all([feature.is_constant() for feature in self._features.values()])\n",
    "            \n",
    "    def get_values(self, feature_names=None, sparse=False, as_dataframe=False, **kwargs):\n",
    "        if feature_names is None:\n",
    "            feature_names = self._feature_names\n",
    "        features = [self._features[feature_name] for feature_name in feature_names \n",
    "                    if feature_name in self._features.keys()]\n",
    "        # TODO проверки\n",
    "        X = []\n",
    "        for feature in features:\n",
    "            X.append(feature.get_values(sparse=sparse))\n",
    "        if len(X) == 0: # Если вдруг все пусто\n",
    "            raise ValueError(\"All values are constant. Senseless feature!\")\n",
    "        if sparse:\n",
    "            X = scipy.sparse.hstack(X)\n",
    "        else:\n",
    "            X = np.concatenate(X, axis=1)\n",
    "            if as_dataframe:\n",
    "                X = pd.DataFrame(X, columns=feature_names)\n",
    "        return X\n",
    "    \n",
    "    def __repr__(self):\n",
    "        s = 'AggregatedFeature['\n",
    "        for feature_name in [feature_name for feature_name in self._feature_names \n",
    "                             if feature_name in self._features]:\n",
    "            feature = self._features[feature_name]\n",
    "            s += str(feature)\n",
    "        s += ']'\n",
    "        return s\n",
    "    \n",
    "n_features = 5\n",
    "features = []\n",
    "feature_names = []\n",
    "size = 10\n",
    "sparse = True; as_dataframe=True\n",
    "for n_feature in range(n_features):\n",
    "    values = np.random.randint(low=0, high=2, size=size)\n",
    "    features.append(NumericalFeature(values, 'F' + str(n_feature), verbose=0))\n",
    "    feature_names.append(features[-1].get_name())\n",
    "aggr_feature = AggregatedFeature(features, 'AGGR', copy=False)\n",
    "print(aggr_feature)\n",
    "values = aggr_feature.get_values(sparse=sparse, as_dataframe=as_dataframe)\n",
    "print(values)\n",
    "if sparse:\n",
    "    print(values.todense())\n",
    "values = aggr_feature.get_values(feature_names=feature_names[1:4], sparse=sparse, as_dataframe=as_dataframe) \n",
    "print(values)\n",
    "if sparse:\n",
    "    print(values.todense())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='categorical_feature'></a>\n",
    "## 4. CategoricalFeature<sup>[toc](#toc)</sup>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# %load categorical_feature.py\n",
    "# from feature_base import *\n",
    "import numpy as np\n",
    "import unittest\n",
    "import copy\n",
    "import numbers\n",
    "from collections import defaultdict\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, train_test_split\n",
    "from itertools import product, chain\n",
    "\n",
    "class CategoricalFeature(FeatureBase):\n",
    "    \"\"\"\n",
    "    Класс для хранения категориальных признаков. На данный момент доступна только реализация с \n",
    "    dense хранением данных. \n",
    "    \"\"\"\n",
    "    ################################################################################### \n",
    "\n",
    "    CAT_FEATURE_INIT = 8\n",
    "    OHE = 9\n",
    "    def _is_label_encoded(self, values, name=None):\n",
    "        \"\"\"\n",
    "        Возвращает True, если значения признака label encoded. Иначе возвращает False или вызывает исключение\n",
    "        (в зависимости от параметра throw).\n",
    "        Аргументы:\n",
    "            :param values - категориальные значения (np.ndarray)\n",
    "            :param name - имя категориального признака (str)\n",
    "        \"\"\"\n",
    "        if not self.is_numeric():\n",
    "            return False\n",
    "        labels = sorted(list(set(values)))\n",
    "        prev_value = labels[0]\n",
    "        if prev_value != 0:\n",
    "            return False\n",
    "        for value in labels[1:]:\n",
    "            if value != prev_value + 1:\n",
    "                return False\n",
    "            prev_value = value\n",
    "        return True\n",
    "    \n",
    "    def is_label_encoded(self):\n",
    "        return self._is_label_encoded(self._values, self._name)\n",
    "\n",
    "    def _check_label_encoded(self, values, name, throw=True):\n",
    "        \"\"\"\n",
    "        Возвращает True, если значения признака label encoded. Иначе возвращает False или вызывает исключение\n",
    "        (в зависимости от параметра throw).\n",
    "        Аргументы:\n",
    "            :param values - значения признака (np.ndarray)\n",
    "            :param name   - имя категориального признака (str)\n",
    "            :param throw  - вызывать исключение? (bool)\n",
    "        \"\"\"\n",
    "        if not self._is_label_encoded(values):\n",
    "            if throw: \n",
    "                raise ValueError(self._error_msg('Feature \"{}\" is not label-encoded'.format(name)))\n",
    "            return False\n",
    "        return True\n",
    "            \n",
    "    def _check_cat2label(self, values, name, cat2label, throw=True):\n",
    "        \"\"\"\n",
    "        Проверяет, что преобразование категорий в метки корректно. Возвращает True в случае корректности.\n",
    "        Иначе возвращает False или вызывает исключение (в зависимости от параметра throw).\n",
    "        Аргументы:\n",
    "            :param values    - значения признака (np.ndarray)\n",
    "            :param name      - имя признака (cat)\n",
    "            :param cat2label - преобразование в метки (dict)\n",
    "            :param throw     - вызывать исключение? (bool)\n",
    "        \"\"\"\n",
    "        if not set(values) == set(cat2label.values()):\n",
    "            if throw: \n",
    "                print(set(values), set(cat2label.values()))\n",
    "                raise ValueError(self._error_msg('Num of values != number of labels for feature \"{}\"'.format(name)))\n",
    "            else: \n",
    "                return False\n",
    "        if not len(set(cat2label.keys())) == len(set(cat2label.values())):\n",
    "            if throw: \n",
    "                raise ValueError(self._error_msg('There is no one-to-one correspondance in cat2label for feature \"{}\"'.format(name)))\n",
    "            else: \n",
    "                return False\n",
    "        return True\n",
    "    \n",
    "    ###################################################################################\n",
    "    def deepcopy(self):\n",
    "        new_feature = CategoricalFeature(copy.deepcopy(self._values), self._name, verbose=self._verbose)\n",
    "        new_feature.set_cat2label(self._cat2label)\n",
    "        return new_feature\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return type(self).__name__ + '({}; {})'.format(self.name, self.values.shape)\n",
    "    \n",
    "    def __init__(self, values, name, cat2label=None, verbose=0):\n",
    "        \"\"\"\n",
    "        По завершении работы конструктора признаки оказываются закодированы метками от 1 до N, где\n",
    "        N - число различных значений признака.\n",
    "        Аргументы:\n",
    "            :param values - значения категориальной переменной (np.ndarray, list)\n",
    "            :param name   - имя категориальной переменной (str)\n",
    "            :param cat2label - mapping для преобразования категорий в метки (dict)\n",
    "        \"\"\"\n",
    "        assert isinstance(values, (np.ndarray, list))\n",
    "        super().__init__(values, name, verbose)\n",
    "        self._name = self._get_categorical_name(name)\n",
    "        msg_init = self._info_msg('__init__({})'.format(name))\n",
    "        \n",
    "        self._cat2label = None\n",
    "        self._label2cat = None\n",
    "        if cat2label is not None:\n",
    "            self._printers[self.CAT_FEATURE_INIT](msg_init + ': applying mapping \"cat2label\" to values')\n",
    "            self._values = np.array(list(map(lambda cat: cat2label[cat], self._values)))\n",
    "            self._check_cat2label(self._values, self._name, cat2label)\n",
    "            self._cat2label = copy.deepcopy(cat2label)\n",
    "            self._label2cat = {label:cat for cat, label in cat2label.items()}\n",
    "            \n",
    "        self._properties = {}\n",
    "        self._properties['is_numeric'] = self.is_numeric()\n",
    "        self._properties['is_label_encoded'] = self.is_label_encoded()\n",
    "        self._properties['is_constant'] = self.is_constant()\n",
    "        if self._properties['is_label_encoded']:\n",
    "            self._printers[self.CAT_FEATURE_INIT](msg_init + ': feature \"{}\" is already label encoded'.format(name))\n",
    "        else:\n",
    "            self._printers[self.CAT_FEATURE_INIT](msg_init + ': label encoding feature \"{}\"'.format(name))\n",
    "        self._label_encode()\n",
    "  \n",
    "        # These values are used for filtering rare values\n",
    "        self._threshold = None\n",
    "        self._unique_label = None\n",
    "    \n",
    "        assert self._properties['is_label_encoded'], 'By the end of constructor feature \"{}\" is not label encoded. Something is wrong.'.format(self.name)\n",
    "        assert self._properties['is_numeric'], 'By the end of the constructor feature \"{}\" is not numeric. Something is wrong'.format(self.name)\n",
    "        \n",
    "    ##################################################################################\n",
    "    def set_label2cat(self, label2cat=None):\n",
    "        if label2cat is None:\n",
    "            self._label2cat = None\n",
    "            self._cat2label = None\n",
    "        else:\n",
    "            cat2label = {cat:label for label, cat in label2cat.items()}\n",
    "            self._check_cat2label(self._values, self._name, cat2label, True)\n",
    "            self._label2cat = copy.deepcopy(label2cat)\n",
    "            self._cat2label = cat2label\n",
    "            \n",
    "    def set_cat2label(self, cat2label=None):\n",
    "        \"\"\"\n",
    "        Подразумевает, что сейчас в self._values хранятся метки\n",
    "        \"\"\"\n",
    "        if cat2label is None:\n",
    "            self._cat2label = None\n",
    "            self._label2cat = None\n",
    "        else:\n",
    "            self._check_cat2label(self._values, self._name, cat2label, True)\n",
    "            self._cat2label = copy.deepcopy(cat2label)\n",
    "            self._label2cat = {label:cat for cat, label in cat2label.items()}\n",
    "        \n",
    "    def get_cat_values(self):\n",
    "        \"\"\"\n",
    "        Возвращает признаки в виде изначальных категорий, а не в LE-закодированном виде, в котором \n",
    "        они хранятся внутри класса CategoricalFeature.\n",
    "        \"\"\"\n",
    "        if self._label2cat is None:\n",
    "            # Такое возможно только если признак изначально был передан в закодированном виде\n",
    "            assert self._properties['is_label_encoded'], 'Expected encoded feature.'\n",
    "            return np.array(self._values)\n",
    "        return np.array(list(map(lambda label: self._label2cat[label], self._values)))\n",
    "        \n",
    "    ##################################################################################\n",
    "        \n",
    "    def _filter_feature(self, threshold):\n",
    "        \"\"\"\n",
    "        Отфильтровывает те категории, которые встречаются не более threshold раз. Заменяет их на новую \n",
    "        категорию. Данная категория будет иметь максимальное значение метки. Применение данной функции \n",
    "        ведет к преобразованию имени признака: добавляется приставка FIL_\n",
    "        \n",
    "        Аргументы:\n",
    "            :param threshold - если число появлений категории не превосходит threshold, \n",
    "                                то она отсеивается (int, float)\n",
    "        \"\"\"\n",
    "        \n",
    "        # Checking if the feature is label encoded\n",
    "        if not self._properties['is_label_encoded']:\n",
    "            raise ValueError('Cannot filter feature \"{}\" as it is not label encoded.'.format(self.name))\n",
    "        # Even if the filtration does not change feature values, we change its name and threshold parameters\n",
    "        self._name = self._get_filtered_name(self._name, threshold)\n",
    "        self._threshold = threshold\n",
    "        \n",
    "        # Checking if there are rare values present in the feature\n",
    "        counts = Counter(self._values)\n",
    "        for label, n_occurences in counts.items():\n",
    "            if n_occurences <= threshold:\n",
    "                self._unique_label = self._values.max() + 1\n",
    "                self._properties['is_label_encoded'] = False\n",
    "                break\n",
    "        if self._unique_label is None: \n",
    "            # There are no labels which occur less or equal to threshold times\n",
    "            return\n",
    "        \n",
    "        # Some features occur less or equal threshold times. Let us find them\n",
    "        rare_labels = set()\n",
    "        rare_categories = set()\n",
    "        # Changing rare labels to the chosen unique_label\n",
    "        for n, label in enumerate(self._values):\n",
    "            if counts[label] <= threshold:\n",
    "                if self._cat2label is not None:\n",
    "                    rare_labels.add(label)\n",
    "                    rare_categories.add(self._label2cat[label])\n",
    "                self._values[n] = self._unique_label # setting rare label to new value\n",
    "\n",
    "        # Forming new categories names\n",
    "        if self._cat2label is not None:    \n",
    "            if len(rare_categories) > 1:\n",
    "                new_cat = '(' + '|'.join(sorted(list(rare_categories))) + ')'\n",
    "            elif len(rare_categories) == 1:\n",
    "                new_cat = list(rare_categories)[0]\n",
    "            else:\n",
    "                assert False, '\"rare_categories\" must not be empty at this point. Something is wrong.'\n",
    "\n",
    "            for label in rare_labels:\n",
    "                del self._label2cat[label]\n",
    "            self._label2cat[self._unique_label] = new_cat\n",
    "            for cat in rare_categories:\n",
    "                del self._cat2label[cat]\n",
    "            self._cat2label[new_cat] = self._unique_label\n",
    "            \n",
    "        self._properties['is_constant'] = self.is_constant()\n",
    "        self._label_encode()\n",
    "        assert self._properties['is_label_encoded']\n",
    "        assert self._properties['is_numeric']\n",
    "        \n",
    "    def get_filtered_feature(self, threshold):\n",
    "        \"\"\" \n",
    "        Возвращает признак, полученный из данного фильтрацией категорий по порогу threshold: \n",
    "        все категории, встречающиеся не чаще чем threshold, отфильтровываются функцией _filter_feature.\n",
    "        Все отфильтрованные категории становятся новой категорией.\n",
    "       \n",
    "        Аргументы:\n",
    "            :param - если число появлений категории не превосходит threshold, то она отсеивается (int, float)\n",
    "        \"\"\"\n",
    "        new_feature = self.deepcopy()\n",
    "        new_feature._filter_feature(threshold)\n",
    "        return new_feature\n",
    "    \n",
    "    def get_counter_feature(self):\n",
    "        \"\"\"\n",
    "        Возвращает признак NumericalFeature, равный числу появления каждой из категорий.\n",
    "        \"\"\"\n",
    "        counts = Counter(self._values)\n",
    "        new_values = np.zeros_like(self._values)\n",
    "        for n, value in enumerate(self._values):\n",
    "            new_values[n] = counts[value]\n",
    "        new_name = self._get_counter_name(self._name)\n",
    "        return NumericalFeature(new_values, new_name)\n",
    "\n",
    "    def get_loo_feature(self, Y_train, cv, alpha=0.01, seed=1234, scale=0.01):\n",
    "        \"\"\"\n",
    "        Предполагает, что первые len(Y_train) примеров принадлежат обучающей выборке\n",
    "        \"\"\"\n",
    "        assert isinstance(Y_train, (np.ndarray, list))\n",
    "        assert len(Y_train) <= len(self._values)\n",
    "        train_size = len(Y_train)\n",
    "        test_size = len(self._values) - train_size\n",
    "        \n",
    "        np.random.seed(seed)\n",
    "        X_train = self._values[:train_size]\n",
    "        mean_y = np.mean(Y_train)\n",
    "        all_labels = set(self._values)\n",
    "        X_new_train = np.zeros(len(X_train))\n",
    "\n",
    "        for n_split, (train_indices, test_indices) in enumerate(cv.split(X_train, Y_train)):\n",
    "            x_train, y_train = X_train[train_indices], Y_train[train_indices]\n",
    "            x_test, y_test = X_train[test_indices], Y_train[test_indices]\n",
    "            for label in all_labels:\n",
    "                N_all = x_train.shape[0]\n",
    "                train_mask = x_train == label\n",
    "                N_label = np.sum(train_mask)\n",
    "                print('n_split = {}, label = {}, den = {}'.format(n_split, label, N_label + alpha * N_all))\n",
    "                X_new_train[test_indices[x_test == label]] = \\\n",
    "                    (np.sum(y_train[train_mask]) + alpha * mean_y * N_all) / (max(N_label, 1) + alpha * N_all)\n",
    "        if scale > 0:\n",
    "            multipliers = np.random.normal(loc=1.0, scale=scale, size=len(self._values))\n",
    "        else:\n",
    "            multipliers = np.ones(len(self._values))\n",
    "        if test_size > 0:\n",
    "            X_test = self._values[train_size:]\n",
    "            X_new_test = np.zeros(test_size)\n",
    "            for label in all_labels:\n",
    "                train_mask = X_train == label\n",
    "                N_all = train_size\n",
    "                N_label = np.sum(train_mask)\n",
    "                X_new_test[X_test == label] = (np.sum(Y_train[train_mask]) +\n",
    "                                               alpha * mean_y * train_size) / (max(N_label, 1) + alpha * N_all)\n",
    "\n",
    "            X_new = np.concatenate([X_new_train, X_new_test]) * multipliers\n",
    "        else:\n",
    "            X_new = X_new_train * multipliers\n",
    "        new_name = self._get_loo_name(self._name)\n",
    "        return NumericalFeature(X_new, new_name)\n",
    "        \n",
    "    ############################################################\n",
    "    ##                       Кодировщики                      ##\n",
    "    ############################################################\n",
    "    def _label_encode(self):\n",
    "        \"\"\"\n",
    "        Выполняет label-кодирование признака.\n",
    "        \"\"\"\n",
    "        if self._properties['is_label_encoded']:\n",
    "            if len(FEATURE_PREFIXES['LE']) > 0:\n",
    "                if not self._name.startswith(FEATURE_PREFIXES['LE']):\n",
    "                    self.name = self._get_label_encoded_name(self._name)\n",
    "            return\n",
    "        \n",
    "        label_encoder = LabelEncoder()\n",
    "        self._values = label_encoder.fit_transform(self._values)\n",
    "        classes = label_encoder.classes_\n",
    "        old_label2new_label = {old_label:new_label for new_label, old_label in enumerate(classes)}\n",
    "        new_label2old_label = {new_label:old_label for new_label, old_label in enumerate(classes)}\n",
    "\n",
    "        self._name = self._get_label_encoded_name(self.name)\n",
    "        self._properties['is_label_encoded'] = self.is_label_encoded()\n",
    "        self._properties['is_numeric'] = self.is_numeric()\n",
    "        self._properties['is_constant'] = self.is_constant()\n",
    "        \n",
    "        if self._unique_label is not None:\n",
    "            # This placed can be reached when _label_encode() is invoked from _filter_feature()\n",
    "            self._unique_label = old_label2new_label[self._unique_label]\n",
    "            assert self._unique_label == len(old_label2new_label) - 1\n",
    "            assert (FEATURE_PREFIXES['FIL'] + '{}_'.format(self._threshold)) in self._name\n",
    "            \n",
    "        if self._label2cat is None:\n",
    "            self._cat2label = old_label2new_label\n",
    "            self._label2cat = new_label2old_label\n",
    "        else:\n",
    "            new_label2cat = {}\n",
    "            for old_label in self._label2cat:\n",
    "                new_label = old_label2new_label[old_label]\n",
    "                new_label2cat[new_label] = self._label2cat[old_label]\n",
    "            cat2new_label = {cat:new_label for new_label, cat in new_label2cat.items()}\n",
    "            self._cat2label = cat2new_label\n",
    "            self._label2cat = new_label2cat\n",
    "            \n",
    "        assert self._properties['is_label_encoded']\n",
    "        assert self._properties['is_numeric']\n",
    "\n",
    "    def get_le_feature(self):\n",
    "        \"\"\"\n",
    "        Возвращает LE-закодированный признак, полученный на основе данного. В данной реализации CategoricalFeature\n",
    "        поддерживается инваринат: внутреннее состояние признака всегда LE-закодированное. Поэтому вызов\n",
    "        _label_encode() в реализации функции по сути бесполезен. Возможно что-то измениться в будущих версиях.\n",
    "        \"\"\"\n",
    "        new_feature = self.deepcopy()\n",
    "        new_feature._label_encode()\n",
    "        return new_feature\n",
    "    \n",
    "    def get_ohe_feature(self, sparse=True, omit_uniques=False):\n",
    "        \"\"\"\n",
    "        Аргументы:\n",
    "            :param sparse       - вернуть sparse или dense представление? (bool)\n",
    "            :param omit_uniques - если True, то отфильтрованная категория не войдет в состав OHE-признака (bool)\n",
    "        \"\"\"\n",
    "        assert self._properties['is_label_encoded']\n",
    "        assert self._properties['is_numeric']\n",
    "        msg_base = self._method_msg('get_ohe_feature(): ')\n",
    "        \n",
    "        if (not omit_uniques) or (self._unique_label is None):\n",
    "            unique_label = -1\n",
    "        else:\n",
    "            unique_label = self._unique_label\n",
    "        \n",
    "        ohe_name = self._get_ohe_name(self._name)\n",
    "        counter = Counter(self._values)\n",
    "        \n",
    "        if self._properties['is_constant']:\n",
    "            # No sense of OHE for constant feature\n",
    "            assert np.sum(self._values) == 0\n",
    "            assert len(self._cat2label) == 1\n",
    "            assert list(self._cat2label.values())[0] == 0\n",
    "            self._printers[self.OHE](msg_base + 'OHE of constant feature \"{}\".'.format(self._name))\n",
    "            return NumericalFeature(self._values, ohe_name)\n",
    "        \n",
    "        if (len(counter) == 2):\n",
    "            # In case of binary feature one column of OHE representation can be omitted\n",
    "            assert set(self._cat2label.values()) == set([0, 1])\n",
    "            self._printers[self.OHE](msg_base + 'OHE senseless for binary feature \"{}\".'.format(self._name))\n",
    "            return NumericalFeature(self._values, ohe_name)\n",
    "        \n",
    "            # На данный момент непонятно, почему при unique_label >= 0 возвращали константу\n",
    "            \"\"\"if unique_label >= 0:\n",
    "                assert unique_label == 1\n",
    "                self._printers[self.OHE](msg_base + 'omiting unique label for \"{}\" turns it constant.'.format(self._name))\n",
    "                return NumericalFeature(np.zeros(len(self._values)), ohe_name)\n",
    "            else:\n",
    "                self._printers[self.OHE](msg_base + 'OHE senseless for binary feature \"{}\".'.format(self._name))\n",
    "                return NumericalFeature(self._values, ohe_name)\"\"\"\n",
    "        \n",
    "        ohe_values = OneHotEncoder(sparse=sparse).fit_transform(self._values[:, np.newaxis])\n",
    "        if sparse:\n",
    "            ohe_values = ohe_values.tocsc()\n",
    "        if unique_label >= 0:\n",
    "            assert unique_label == len(counter) - 1\n",
    "            mask = (self._values == unique_label)\n",
    "            if sparse:\n",
    "                last_column = ohe_values[:, unique_label].toarray().flatten()\n",
    "            else:\n",
    "                last_column = ohe_values[:, unique_label]\n",
    "            assert np.all(last_column == mask), 'Last column of ohe feature must correspond to unique_label.'\n",
    "            ohe_values = ohe_values[:, :unique_label]       \n",
    "        \n",
    "        feature_names = []\n",
    "        feature_values = []\n",
    "        for label in sorted(self._label2cat.keys()):\n",
    "            if label != unique_label:\n",
    "                feature_names.append(self._label2cat[label])\n",
    "                feature_values.append(ohe_values[:, label])\n",
    "        features = [NumericalFeature(fvalues, fname) for fvalues, fname in zip(feature_values, feature_names)]\n",
    "        return AggregatedFeature(features, ohe_name, verbose=self._verbose, copy=False)\n",
    "        \n",
    "    def get_properties(self):\n",
    "        return copy.deepcopy(self._properties)\n",
    "        \n",
    "def print_columns(*args):\n",
    "    all_labels = []\n",
    "    all_values = []\n",
    "    v_length = 0\n",
    "    m_length = 0\n",
    "    for label, values in args:\n",
    "        m_length = max(m_length, len(label))\n",
    "        all_labels.append(label)\n",
    "        all_values.append(values)\n",
    "        v_length = max(v_length, max([len(str(v)) for v in values]))\n",
    "    for label, values in args:\n",
    "        s = []\n",
    "        if m_length > 0:\n",
    "            s.append(label.ljust(m_length) + ':')\n",
    "        for v in values:\n",
    "            s.append(str(v).ljust(v_length))\n",
    "        print(' '.join(s))\n",
    "    \n",
    "        \n",
    "name = 'f'\n",
    "cat_values = ['A', 'A', 'B', 'A', 'B', 'C', 'A', 'B', 'C', 'D', 'A', 'B', 'C', 'D', 'E']\n",
    "values     = [0,   0,    1,   0,   1,   2,   0,   1,   2,   3,   0,   1,   2,   3,   4]\n",
    "cat2label  = {'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4}\n",
    "f = CategoricalFeature(cat_values, name, cat2label, verbose=0)\n",
    "\n",
    "test_initial = False\n",
    "test_counter = False\n",
    "test_filtered = False\n",
    "test_ohe = False\n",
    "test_ohe_filtered = False\n",
    "test_loo = False\n",
    "\n",
    "if test_initial:\n",
    "    print('INITIAL FEATURE:')\n",
    "    print('True values    : ', values)\n",
    "    print('Obtained values: ', list(f.get_values().flatten()))\n",
    "    print('\\nTrue CAT values: ', cat_values)\n",
    "    print('Obtained CATs  : ', list(f.get_cat_values()))\n",
    "\n",
    "if test_counter:\n",
    "    print('\\n\\nCOUNTER FEATURE')\n",
    "    print('Initial feature: ', f)\n",
    "    counter_f = f.get_counter_feature()\n",
    "    print('Counter feature: ', counter_f)\n",
    "    print(counter_f.get_values().flatten())\n",
    "    print('Values of initial and counter features:')\n",
    "    args = [('initial', f.get_values().flatten()), ('counter', counter_f.get_values().flatten())]\n",
    "    print_columns(*args)\n",
    "\n",
    "if test_filtered:\n",
    "    print('\\n\\nFILTERED FEATURES')\n",
    "    ffs = {n:f.get_filtered_feature(n) for n in range(6)}\n",
    "    for n in range(6):\n",
    "        fil_feature = ffs[n].get_values().flatten()\n",
    "        cat_feature = ffs[n].get_cat_values().flatten()\n",
    "        ctr_feature = ffs[n].get_counter_feature().get_values().flatten()\n",
    "        print('fil_feature props: ', ffs[n].get_properties())\n",
    "        print('fil feature name: ', ffs[n])\n",
    "        print('ctr feature name: ', ffs[n].get_counter_feature())\n",
    "        args = [('fil_feature', fil_feature), ('cat_feature', cat_feature), ('ctr_feature', ctr_feature)]\n",
    "        print_columns(*args)\n",
    "        print('\\n\\n')\n",
    "\n",
    "if test_ohe:   \n",
    "    print('\\n\\nOHE FEATURES')\n",
    "    ohe_feature = f.get_ohe_feature()\n",
    "    a = f.get_ohe_feature(sparse=False).get_values(sparse=True).toarray()\n",
    "    b = f.get_ohe_feature(sparse=False).get_values(sparse=False)\n",
    "    c = f.get_ohe_feature(sparse=True).get_values(sparse=False)\n",
    "    d = f.get_ohe_feature(sparse=True).get_values(sparse=True).toarray()\n",
    "    assert np.allclose(a, b)\n",
    "    assert np.allclose(b, c)\n",
    "    assert np.allclose(c, d)\n",
    "    assert np.allclose(d, a)\n",
    "    print('Initial feature:', ohe_feature)\n",
    "    print('\\tvalues:\\n', f.get_values().flatten())\n",
    "    print('OHE feature:', ohe_feature)\n",
    "    print('\\tOHE values:\\n', a)\n",
    "\n",
    "if test_ohe_filtered:\n",
    "    print('\\n\\nOHE FEATURES + FILTRATION')\n",
    "    for threshold, omit_uniques in product([1, 2, 3, 4, 5], [False, True]):\n",
    "        ff = f.get_filtered_feature(threshold=threshold)\n",
    "        print('OHE feature with omit_uniques = {} and threshold = {}'.format(omit_uniques, threshold))\n",
    "        print('Initial  feature name:', f)\n",
    "        print('Filtered feature name:', ff)\n",
    "        print('Initial feature values:', f.get_values().flatten())\n",
    "        print('Filtered fature values:', ff.get_values().flatten())\n",
    "        print('threhold =', ff._threshold, '  unique_label =', ff._unique_label)\n",
    "        ff_ohe = ff.get_ohe_feature(omit_uniques=omit_uniques)\n",
    "        print('FilOHE feature name:  ', ff_ohe)\n",
    "        print('FilOHE feature values:\\n', ff_ohe.get_values(sparse=False))\n",
    "        print('FilOHE is constant:   ', ff_ohe.is_constant())\n",
    "        print('\\n\\n')\n",
    "\n",
    "if test_loo:\n",
    "    print('\\n\\nLEAVE ONE OUT')\n",
    "    X = np.array([0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0])\n",
    "    y = np.array([0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0])\n",
    "    cat_feature = CategoricalFeature(X, 'f')\n",
    "    random_state = 345\n",
    "    n_splits = 2\n",
    "    cv = StratifiedKFold(n_splits, shuffle=True, random_state=random_state)\n",
    "    print_columns(('ind', np.arange(len(X))), ('X', X), ('y', y))\n",
    "    for n_split, (train_indices, test_indices) in enumerate(cv.split(X, y)):\n",
    "        print('\\n\\nn_split =', n_split)\n",
    "        X_tr, y_tr = X[train_indices], y[train_indices]\n",
    "        X_ts, y_ts = X[test_indices],  y[test_indices]\n",
    "        X_loo_true = np.array([1/4., 2/3., 0, 2/3., 0, 2/3., 2/3., 2/3., 2/3., 0, 0, 1/4.])\n",
    "        print()\n",
    "        print_columns(('ind', train_indices), ('X_tr', X_tr), ('y_tr', y_tr))\n",
    "        print()\n",
    "        print_columns(('ind', test_indices), ('X_ts', X_ts), ('y_ts', y_ts))\n",
    "        \n",
    "    loo_feature = cat_feature.get_loo_feature(y, cv, alpha=0, scale=0.0)\n",
    "    X_loo_found = loo_feature.get_values(sparse=False).flatten()\n",
    "    print('LOO:\\n')\n",
    "    print_columns(('True', X_loo_true), ('Found', X_loo_found))\n",
    "    np.allclose(X_loo_found, X_loo_true)\n",
    "    #print(cat_feature, cat_feature)\n",
    "    #print(loo_feature, loo_feature.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='categorical_combiner'></a>\n",
    "# 5. CategoricalCombiner<sup>[toc](#toc)</sup>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comb_feature: [CategoricalFeature: f1+f2+f3, (12,)]\n",
      "name = f1+f2+f3, values = [0 2 6 1 4 7 7 1 3 5 6 0]\n",
      "fil_feature:  [CategoricalFeature: Fil1_f1+f2+f3, (12,)]\n",
      "name = Fil1_f1+f2+f3, values = [0 4 2 1 4 3 3 1 4 4 2 0]\n",
      "\n",
      "degree = 1\n",
      "new_features: {'f1': CategoricalFeature(f1; (12, 1)), 'f3': CategoricalFeature(f3; (12, 1)), 'f2': CategoricalFeature(f2; (12, 1))}\n",
      "  f1: 0 1 2 0 1 2 2 0 1 2 2 0\n",
      "  f2: 0 1 0 1 0 1 1 1 1 0 0 0\n",
      "  f3: 1 0 1 1 1 1 1 1 1 0 1 1\n",
      "\n",
      "degree = 2\n",
      "new_features: {'f1+f3': CategoricalFeature(f1+f3; (12, 1)), 'f2+f3': CategoricalFeature(f2+f3; (12, 1)), 'f1+f2': CategoricalFeature(f1+f2; (12, 1))}\n",
      "  f1+f2: 0 2 4 1 3 5 5 1 2 4 4 0\n",
      "  f1+f3: 0 2 4 0 1 4 4 0 1 3 4 0\n",
      "  f2+f3: 1 3 1 2 1 2 2 2 2 0 1 1\n",
      "\n",
      "degree = 3\n",
      "new_features: {'f1+f2+f3': CategoricalFeature(f1+f2+f3; (12, 1))}\n",
      "  f1+f2+f3: 0 2 6 1 4 7 7 1 3 5 6 0\n"
     ]
    }
   ],
   "source": [
    "from itertools import product, chain, combinations\n",
    "\n",
    "class CategoricalCombiner(Checker):\n",
    "    METHOD = 4\n",
    "    def __init__(self, verbose=0):\n",
    "        super().__init__()\n",
    "        self._verbose = verbose\n",
    "\n",
    "    def get_all_combinations(self, features, degree, hash=hash):\n",
    "        \"\"\"\n",
    "        Аргументы:\n",
    "            :param degree\n",
    "            :param features\n",
    "            :param hash\n",
    "        \"\"\"\n",
    "        feature_names = [feature.name for feature in features]\n",
    "        method_msg = self._method_msg('get_all_combinations')\n",
    "        methdo_msg = method_msg + '({}, degree={})'.format(feature_names, degree)\n",
    "        self._printers[self.METHOD](method_msg)\n",
    "        combined_features = {}\n",
    "        for some_features in combinations(features, degree):\n",
    "            new_feature = self.get_combined_feature(some_features, hash) \n",
    "            combined_features[new_feature.get_name()] = new_feature\n",
    "        return combined_features\n",
    "\n",
    "    def get_combined_feature(self, features, hash=hash):\n",
    "        self.check_sizes_(features)\n",
    "        if len(features) < 1:\n",
    "            raise ValueError('At least one feature name must be given')\n",
    "        if len(features) == 1:\n",
    "            return features[0].deepcopy()\n",
    "                             \n",
    "        feature_values = []\n",
    "        feature_names = []\n",
    "        for feature in features:\n",
    "            values = feature.get_values(False).flatten()\n",
    "            feature_values.append(values)\n",
    "            feature_names.append(feature.get_name())\n",
    "            \n",
    "        new_values = []\n",
    "        for hyper_value in zip(*feature_values):\n",
    "            new_values.append(hash(hyper_value))\n",
    "        new_values = LabelEncoder().fit_transform((new_values))\n",
    "        new_name = '+'.join(feature_names)\n",
    "        return CategoricalFeature(new_values, new_name)\n",
    "\n",
    "    def check_sizes_(self, features):\n",
    "        if len(Counter([len(feature) for feature in features])) != 1:\n",
    "            raise ValueError('Features must have equal sizes!')\n",
    "            \n",
    "test = True\n",
    "if test:\n",
    "    features = {'f1': [0, 1, 2, 0, 1, 2, 2, 0, 1, 2, 2, 0],\n",
    "                'f2': [0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0],\n",
    "                'f3': [1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1]}\n",
    "    cat_features = [CategoricalFeature(features[name], name) for name in sorted(features.keys())]\n",
    "    cat_combiner = CategoricalCombiner()\n",
    "    new_feature = cat_combiner.get_combined_feature(cat_features)\n",
    "    print('comb_feature:', new_feature)\n",
    "    print('name = {}, values = {}'.format(new_feature._name, new_feature._values))\n",
    "    fil_feature = new_feature.get_filtered_feature(1)\n",
    "    print('fil_feature: ', fil_feature)\n",
    "    print('name = {}, values = {}'.format(fil_feature.name, fil_feature._values))\n",
    "    for degree in range(1, 4):\n",
    "        print('\\ndegree = {}'.format(degree))\n",
    "        new_features = cat_combiner.get_all_combinations(cat_features, degree=degree)\n",
    "        print('new_features:', new_features)\n",
    "        args = []\n",
    "        for f_name, feature in new_features.items():\n",
    "            args.append(('  ' + f_name, feature.get_values(False).flatten()))\n",
    "        args = sorted(args, key=lambda x: x[0])\n",
    "        print_columns(*args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='features_storage'></a>\n",
    "# 6. FeaturesStorage<sup>[toc](#toc)</sup>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CategoricalFeaturesManager(Checker):\n",
    "    def __init__(self, verbose):\n",
    "        super().__init__()\n",
    "        self._features = {}\n",
    "        self._n_samples = None\n",
    "        self._verbose = verbose\n",
    "        self._categorical_combiner = CategoricalCombiner(verbose)\n",
    "        \n",
    "    def __contains__(self, feature_name):\n",
    "        return feature_name in self._features\n",
    " \n",
    "    ###################################################################\n",
    "    def is_present(self, name):\n",
    "        return name in self._features\n",
    "    def _check_if_present(self, *args):\n",
    "        for name in args:\n",
    "            if not self.is_present(name):\n",
    "                raise ValueError(self._error_msg(\"unknown feature \\\"{}\\\"\".format(name)))  \n",
    "    def _is_binary(self, values):\n",
    "        if len(Counter(values)) == 2:\n",
    "            return True\n",
    "        return False\n",
    "    def _check_feature(self, feature):\n",
    "        self._check_type(feature, str(feature), CategoricalFeature)\n",
    "        if (self._n_samples is not None) & (len(feature) != self._n_samples):\n",
    "            raise ValueError(\"Given feature vector has size {} while must have size {}.\".format(\n",
    "                        len(feature), self._n_samples))\n",
    "\n",
    "    ################################################################### \n",
    "    def set_feature(self, feature, copy=True, replace=True):\n",
    "        \"\"\"\n",
    "        Помещает признак в хранилище.\n",
    "        Аргументы:\n",
    "            :param feature - словарь из {имя_признака: признак}. (dict)\n",
    "            :param copy    - если True, то в хранилище будет помещена копия признака. (bool)\n",
    "            :parma replace - если True, то признак с таким же именем будет заменен;\n",
    "                             если False, то наличине признака с таким же именем вызывает исключение. (bool)\n",
    "        \"\"\"\n",
    "        \n",
    "        self._check_feature(feature) # новый признак имеет правильный размер и категориальный тип\n",
    "        if not replace:              # если замена признака запрещена ...\n",
    "            if self.is_present(feature.get_name()): # и уже есть признак с таким именем, то ...\n",
    "                error_msg = self._method_msg('set_feature') +\\\n",
    "                    'feature \"{}\" cannot be replaced. Check \"replace\" parameter'.format(feature.get_name())\n",
    "                raise ValueError(error_msg)\n",
    "\n",
    "        self._n_samples = len(feature)\n",
    "        self.del_feature(feature, throw=False)\n",
    "        if copy:\n",
    "            self._features[feature.get_name()] = feature.deepcopy()\n",
    "        else:\n",
    "            self._features[feature.get_name()] = feature\n",
    "            \n",
    "    def del_feature(self, feature_name, throw=True):\n",
    "        \"\"\"\n",
    "        Аргументы:\n",
    "            :param feature_name\n",
    "            :param throw\n",
    "        \"\"\"\n",
    "        if not self.is_present(feature_name):\n",
    "            if throw:\n",
    "                error_msg = self._method_msg('del_feature') +\\\n",
    "                    'feature \"{}\" is not present in storage. Cannot be deleted.'.format(feature_name)\n",
    "                raise KeyError(error_msg)\n",
    "            return False\n",
    "        else:\n",
    "            del self._features[feature_name]\n",
    "            if len(self._features) == 0:\n",
    "                self._n_samples = None\n",
    "            return True\n",
    "    \n",
    "    def get_feature(self, feature_name, copy=True):\n",
    "        self._check_if_present(feature_name)\n",
    "        if copy:\n",
    "            return self._features[feature_name].deepcopy()\n",
    "        return self._features[feature_name]\n",
    "    \n",
    "    def get_list_of_features(self):\n",
    "        return sorted(list(self._features.keys()))\n",
    "\n",
    "\n",
    "    ###################################################################\n",
    "    #    Функции комбинирования категориальных признаков              #\n",
    "    ###################################################################\n",
    "    def add_all_combinations(self, feature_names, degree, hash=hash):\n",
    "        self.get_all_combinations(feature_names, degree, hash=hash, store=True, copy=False)\n",
    "        \n",
    "    def get_all_combinations(self, feature_names, degree, hash=hash, store=True, copy=True):\n",
    "        method_msg = self._method_msg('get_all_combinations')\n",
    "        self._printers[self.METHOD](method_msg + '(names={}, degree={}, store={})'.format(feature_names, degree, store))\n",
    "        self._check_if_present(feature_names)\n",
    "        \n",
    "        features = {name: self._features[name] for name in feature_names}\n",
    "        combined_features = self._categorical_combiner.get_all_combinartions(features, degree=degree, hash=hash)\n",
    "        if store:\n",
    "            if degree > 1:\n",
    "                for name, combined_feature in combined_features:\n",
    "                    self.set_feature(combined_feature, copy=copy, replace=False)\n",
    "        return combined_features\n",
    "\n",
    "    def add_combined_feature(self, feature_names, hash=hash):\n",
    "        self.get_combined_feature(feature_names, hash=hash, store=True, copy=False)\n",
    "        \n",
    "    def get_combined_feature(self, feature_names, hash=hash, store=True, copy=True):\n",
    "        method_msg = self._method_msg('get_combined_feature')\n",
    "        self._printers[self.METHOD](method_msg + '(names={}, store={})'.format(feature_names, store))\n",
    "        self._check_if_present(feature_names)\n",
    "        \n",
    "        features = [self.features[name] for name in feature_names]\n",
    "        combined_feature = CategorialCombiner().get_combined_feature(features, hash=hash)\n",
    "        if store:\n",
    "            if len(feature_names) > 1:\n",
    "                self.set_feature(combined_feature, copy=copy, replace=False)\n",
    "        return combined_feature\n",
    "\n",
    "\n",
    "    ############################################################\n",
    "    ##       Сборка итогового признакового представления      ##\n",
    "    ############################################################\n",
    "    def assemble_data_frame(self, feature_names):\n",
    "        self._check_if_present(feature_names)\n",
    "        feature_values = []\n",
    "        for feature_name in feature_names:\n",
    "            feature_values.append(self._features[feature_name].get_values())\n",
    "        return pd.DataFrame(np.hstack(feature_values), columns=feature_names)\n",
    "    \n",
    "    def assemble(self, feature_names, sparse=False):\n",
    "        \"\"\"\n",
    "        Аргументы:\n",
    "            :param feature_names\n",
    "            :param sparse\n",
    "        \"\"\"\n",
    "        self._check_if_present(feature_names)\n",
    "        X = []\n",
    "        feature_map = copy.deepcopy(feature_map)\n",
    "        for feature_name in feature_names:\n",
    "            feature = self._features[feature_name]\n",
    "            X.append(feature.get_values(sparse=sparse))\n",
    "        if sparse:\n",
    "            return scipy.sparse.hstack(X)\n",
    "        return np.hstack(X)\n",
    "\n",
    "    def add_filtered(self, name, threshold):\n",
    "        self.get_filtered(name, threshold, store=True, copy=False)\n",
    "    def get_filtered(self, name, threshold, store=True, copy=True):\n",
    "        self._check_if_present(name)\n",
    "        new_feature = self._features[name].get_filtered_feature(threshold)\n",
    "        if store:\n",
    "            self.set_feature(new_feature, copy=copy, replace=False)\n",
    "        return new_feature\n",
    "    \n",
    "    def add_counter(self, name):\n",
    "        self.get_filtered(name, store=True, copy=False)\n",
    "    def get_counter(self, name, store=True, copy=True):\n",
    "        self._check_if_present(name)\n",
    "        new_feature = self._features[name].get_counter_feature(threshold)\n",
    "        if store:\n",
    "            self.set_feature(new_feature, copy=copy, replace=False)\n",
    "        return new_feature\n",
    "    def get_loo(self, name, y_train, cv, seed=1234):\n",
    "        self._check_if_present(name)\n",
    "        new_feature = self._features[name].get_loo_feature(y_train, cv=cv, seed=seed)\n",
    "        return new_feature\n",
    "        \n",
    "    \n",
    "\n",
    "test = False\n",
    "if test:      \n",
    "    FStest = FeaturesStorage(verbose=0)\n",
    "    features = [CategorialFeature(np.array([0, 1, 0, 1, 2, 0, 1, 2, 3, 0, 1, 2, 3, 4]), 'f1'),\n",
    "                CategorialFeature(np.array([1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1]), 'f2'),\n",
    "                CategorialFeature(np.array([0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1]), 'f3'),\n",
    "                NumericFeature(np.array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 1.1, 1.2, 1.3, 1.4]), 'f4')]\n",
    "    for feature in features:\n",
    "        FStest.set_feature(feature)\n",
    "        assert feature.shape == (14, )\n",
    "        assert len(feature) == 14\n",
    "\n",
    "    #temp = features_storage.get_feature('f5')\n",
    "    print('\\nLists of features:')\n",
    "    names = FStest.get_list_of_features()\n",
    "    print('all:', names)\n",
    "    print(FStest.assemble_data_frame(names))\n",
    "    print('f1' in features_storage)\n",
    "    print('f5' in features_storage)\n",
    "    \n",
    "    print('\\nDeleting and setting features:')\n",
    "    FStest.del_feature('f1')\n",
    "    print('del f1:', FStest.get_list_of_features()) \n",
    "    FStest.del_feature('f4')\n",
    "    print('del f4:', FStest.get_list_of_features())\n",
    "    FStest.del_feature('f3')\n",
    "    print('del f3:', FStest.get_list_of_features())\n",
    "    FStest.del_feature('f2')\n",
    "    print('del f2:', FStest.get_list_of_features())\n",
    "    \n",
    "    for feature in features:\n",
    "        FStest.set_feature(feature)    \n",
    "    \n",
    "    num_feature = FStest.get_feature('f4')\n",
    "    new_feature = num_feature.get_categorized_feature(np.linspace(0, 2, 3), right=False)\n",
    "    FStest.set_feature(new_feature)\n",
    "    print(new_feature, new_feature.values)\n",
    "    \n",
    "    print('\\nCombining features:')\n",
    "    new_feature = FStest.get_combined_feature(['f1'])\n",
    "    print(new_feature, new_feature.values)\n",
    "    new_feature = FStest.get_combined_feature(['f2'])\n",
    "    print(new_feature, new_feature.values)\n",
    "    new_feature = FStest.get_combined_feature(['f3'])\n",
    "    print(new_feature, new_feature.values)\n",
    "    new_feature = FStest.get_combined_feature(['f1', 'f2'])\n",
    "    print(new_feature, new_feature.values)\n",
    "    new_feature = FStest.get_combined_feature(['f1', 'f3'])\n",
    "    print(new_feature, new_feature.values)\n",
    "    new_feature = FStest.get_combined_feature(['f2', 'f3'])\n",
    "    print(new_feature, new_feature.values)\n",
    "    new_feature = FStest.get_combined_feature(['f1', 'f2', 'f3'])\n",
    "    print(new_feature, new_feature.values)\n",
    "    print('all:', FStest.get_list_of_features())\n",
    "    \n",
    "    print('\\nFiltering values:')\n",
    "    thr = 2\n",
    "    FStest.add_filtered('f1', thr, True)\n",
    "    FStest.add_filtered('f2', thr, False)\n",
    "    FStest.add_filtered('f3', thr, False)\n",
    "    print('all:', FStest.get_list_of_features())\n",
    "    feature = FStest.get_feature('FA{}_f1'.format(thr))\n",
    "    print(feature.name, feature.values)\n",
    "    feature = FStest.get_feature('FN{}_f2'.format(thr))\n",
    "    print(feature.name, feature.values)\n",
    "    feature = FStest.get_feature('FN{}_f3'.format(thr))\n",
    "    print(feature.name, feature.values)\n",
    "    \n",
    "    print('\\nObtaining counters:')\n",
    "    for name in ['f1', 'f2', 'f3']:\n",
    "        FStest.add_counter(name)\n",
    "        feature = FStest.get_feature('CTR_' + name)\n",
    "        print(feature.name, feature.values)\n",
    "    print('all:', FStest.get_list_of_features())\n",
    "    print('cat:', FStest.get_list_of_features('CAT'))\n",
    "    print('num:', FStest.get_list_of_features('NUM'))\n",
    "    print('\\nAssembling features')\n",
    "    print(FStest.assemble(['f1', 'f2', 'f3', 'CTR_f3', 'f1+f2', 'f1+f3', 'f2+f3', 'f1+f2+f3', 'f4'], sparse=False))\n",
    "    print(FStest.assemble(['FA2_f1', 'f2', 'f3', 'f1+f2', 'f1+f3', 'f2+f3'], \n",
    "                          {'FA2_f1': ['def', 'ohe'],\n",
    "                           'f2': ['def', 'ohe'],\n",
    "                           'f3': ['def', 'ohe']},\n",
    "                          sparse=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \"\"\"def add_categorized(self, name, bins, right=True):\n",
    "        self.check_if_present_(name)\n",
    "        self.check_type_(name, 'NUM')\n",
    "        new_feature = self.features[name].get_categorized_feature(bins, right)\n",
    "        self.features[new_feature.name] = new_feature\n",
    "        self.types[new_feature.name] = 'CAT'\n",
    "        return new_feature.name\"\"\"\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
